I1109 12:49:59.139097   878 caffe.cpp:99] Use GPU with device ID 0
I1109 12:50:00.553560   878 caffe.cpp:107] Starting Optimization
I1109 12:50:00.553707   878 solver.cpp:32] Initializing solver from parameters: 
test_iter: 29
test_interval: 1
base_lr: 0
display: 10
max_iter: 0
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 200
solver_mode: GPU
test_compute_loss: true
net: "task/inadcl_o/train_val.prototxt"
I1109 12:50:00.553745   878 solver.cpp:67] Creating training net from net file: task/inadcl_o/train_val.prototxt
I1109 12:50:00.555167   878 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 12:50:00.555223   878 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 12:50:00.555583   878 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/inadcl_o/train.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1109 12:50:00.555794   878 layer_factory.hpp:78] Creating layer data
I1109 12:50:00.555824   878 net.cpp:67] Creating Layer data
I1109 12:50:00.555835   878 net.cpp:356] data -> data
I1109 12:50:00.555857   878 net.cpp:356] data -> label
I1109 12:50:00.555878   878 net.cpp:96] Setting up data
I1109 12:50:00.555889   878 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/inadcl_o/train.txt
I1109 12:50:00.569327   878 image_data_layer.cpp:49] A total of 20637 images.
I1109 12:50:00.580026   878 image_data_layer.cpp:78] output data size: 8,3,224,224
I1109 12:50:00.581948   878 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1109 12:50:00.581969   878 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:50:00.581979   878 layer_factory.hpp:78] Creating layer conv1_1
I1109 12:50:00.581997   878 net.cpp:67] Creating Layer conv1_1
I1109 12:50:00.582005   878 net.cpp:394] conv1_1 <- data
I1109 12:50:00.582049   878 net.cpp:356] conv1_1 -> conv1_1
I1109 12:50:00.582069   878 net.cpp:96] Setting up conv1_1
I1109 12:50:00.611404   878 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:00.611454   878 layer_factory.hpp:78] Creating layer relu1_1
I1109 12:50:00.611474   878 net.cpp:67] Creating Layer relu1_1
I1109 12:50:00.611481   878 net.cpp:394] relu1_1 <- conv1_1
I1109 12:50:00.611491   878 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1109 12:50:00.611505   878 net.cpp:96] Setting up relu1_1
I1109 12:50:00.611521   878 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:00.611527   878 layer_factory.hpp:78] Creating layer conv1_2
I1109 12:50:00.611541   878 net.cpp:67] Creating Layer conv1_2
I1109 12:50:00.611556   878 net.cpp:394] conv1_2 <- conv1_1
I1109 12:50:00.611565   878 net.cpp:356] conv1_2 -> conv1_2
I1109 12:50:00.611575   878 net.cpp:96] Setting up conv1_2
I1109 12:50:00.613652   878 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:00.613678   878 layer_factory.hpp:78] Creating layer relu1_2
I1109 12:50:00.613689   878 net.cpp:67] Creating Layer relu1_2
I1109 12:50:00.613695   878 net.cpp:394] relu1_2 <- conv1_2
I1109 12:50:00.613703   878 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1109 12:50:00.613711   878 net.cpp:96] Setting up relu1_2
I1109 12:50:00.613723   878 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:00.613729   878 layer_factory.hpp:78] Creating layer pool1
I1109 12:50:00.613744   878 net.cpp:67] Creating Layer pool1
I1109 12:50:00.613751   878 net.cpp:394] pool1 <- conv1_2
I1109 12:50:00.613759   878 net.cpp:356] pool1 -> pool1
I1109 12:50:00.613770   878 net.cpp:96] Setting up pool1
I1109 12:50:00.613795   878 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1109 12:50:00.613803   878 layer_factory.hpp:78] Creating layer conv2_1
I1109 12:50:00.613816   878 net.cpp:67] Creating Layer conv2_1
I1109 12:50:00.613822   878 net.cpp:394] conv2_1 <- pool1
I1109 12:50:00.613831   878 net.cpp:356] conv2_1 -> conv2_1
I1109 12:50:00.613840   878 net.cpp:96] Setting up conv2_1
I1109 12:50:00.617579   878 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:00.617609   878 layer_factory.hpp:78] Creating layer relu2_1
I1109 12:50:00.617619   878 net.cpp:67] Creating Layer relu2_1
I1109 12:50:00.617624   878 net.cpp:394] relu2_1 <- conv2_1
I1109 12:50:00.617632   878 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1109 12:50:00.617641   878 net.cpp:96] Setting up relu2_1
I1109 12:50:00.617650   878 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:00.617657   878 layer_factory.hpp:78] Creating layer conv2_2
I1109 12:50:00.617671   878 net.cpp:67] Creating Layer conv2_2
I1109 12:50:00.617676   878 net.cpp:394] conv2_2 <- conv2_1
I1109 12:50:00.617686   878 net.cpp:356] conv2_2 -> conv2_2
I1109 12:50:00.617694   878 net.cpp:96] Setting up conv2_2
I1109 12:50:00.625033   878 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:00.625061   878 layer_factory.hpp:78] Creating layer relu2_2
I1109 12:50:00.625072   878 net.cpp:67] Creating Layer relu2_2
I1109 12:50:00.625077   878 net.cpp:394] relu2_2 <- conv2_2
I1109 12:50:00.625085   878 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1109 12:50:00.625094   878 net.cpp:96] Setting up relu2_2
I1109 12:50:00.625104   878 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:00.625110   878 layer_factory.hpp:78] Creating layer pool2
I1109 12:50:00.625145   878 net.cpp:67] Creating Layer pool2
I1109 12:50:00.625154   878 net.cpp:394] pool2 <- conv2_2
I1109 12:50:00.625166   878 net.cpp:356] pool2 -> pool2
I1109 12:50:00.625176   878 net.cpp:96] Setting up pool2
I1109 12:50:00.625190   878 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1109 12:50:00.625195   878 layer_factory.hpp:78] Creating layer conv3_1
I1109 12:50:00.625206   878 net.cpp:67] Creating Layer conv3_1
I1109 12:50:00.625212   878 net.cpp:394] conv3_1 <- pool2
I1109 12:50:00.625221   878 net.cpp:356] conv3_1 -> conv3_1
I1109 12:50:00.625232   878 net.cpp:96] Setting up conv3_1
I1109 12:50:00.639660   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:00.639696   878 layer_factory.hpp:78] Creating layer relu3_1
I1109 12:50:00.639708   878 net.cpp:67] Creating Layer relu3_1
I1109 12:50:00.639714   878 net.cpp:394] relu3_1 <- conv3_1
I1109 12:50:00.639724   878 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1109 12:50:00.639734   878 net.cpp:96] Setting up relu3_1
I1109 12:50:00.639744   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:00.639750   878 layer_factory.hpp:78] Creating layer conv3_2
I1109 12:50:00.639758   878 net.cpp:67] Creating Layer conv3_2
I1109 12:50:00.639763   878 net.cpp:394] conv3_2 <- conv3_1
I1109 12:50:00.639775   878 net.cpp:356] conv3_2 -> conv3_2
I1109 12:50:00.639786   878 net.cpp:96] Setting up conv3_2
I1109 12:50:00.668728   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:00.668764   878 layer_factory.hpp:78] Creating layer relu3_2
I1109 12:50:00.668781   878 net.cpp:67] Creating Layer relu3_2
I1109 12:50:00.668788   878 net.cpp:394] relu3_2 <- conv3_2
I1109 12:50:00.668798   878 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1109 12:50:00.668809   878 net.cpp:96] Setting up relu3_2
I1109 12:50:00.668819   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:00.668825   878 layer_factory.hpp:78] Creating layer conv3_3
I1109 12:50:00.668838   878 net.cpp:67] Creating Layer conv3_3
I1109 12:50:00.668844   878 net.cpp:394] conv3_3 <- conv3_2
I1109 12:50:00.668853   878 net.cpp:356] conv3_3 -> conv3_3
I1109 12:50:00.668862   878 net.cpp:96] Setting up conv3_3
I1109 12:50:00.697818   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:00.697854   878 layer_factory.hpp:78] Creating layer relu3_3
I1109 12:50:00.697870   878 net.cpp:67] Creating Layer relu3_3
I1109 12:50:00.697877   878 net.cpp:394] relu3_3 <- conv3_3
I1109 12:50:00.697888   878 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1109 12:50:00.697897   878 net.cpp:96] Setting up relu3_3
I1109 12:50:00.697908   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:00.697914   878 layer_factory.hpp:78] Creating layer pool3
I1109 12:50:00.697926   878 net.cpp:67] Creating Layer pool3
I1109 12:50:00.697932   878 net.cpp:394] pool3 <- conv3_3
I1109 12:50:00.697940   878 net.cpp:356] pool3 -> pool3
I1109 12:50:00.697949   878 net.cpp:96] Setting up pool3
I1109 12:50:00.697962   878 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1109 12:50:00.697968   878 layer_factory.hpp:78] Creating layer conv4_1
I1109 12:50:00.697979   878 net.cpp:67] Creating Layer conv4_1
I1109 12:50:00.697985   878 net.cpp:394] conv4_1 <- pool3
I1109 12:50:00.697994   878 net.cpp:356] conv4_1 -> conv4_1
I1109 12:50:00.698004   878 net.cpp:96] Setting up conv4_1
I1109 12:50:00.754784   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:00.754812   878 layer_factory.hpp:78] Creating layer relu4_1
I1109 12:50:00.754822   878 net.cpp:67] Creating Layer relu4_1
I1109 12:50:00.754827   878 net.cpp:394] relu4_1 <- conv4_1
I1109 12:50:00.754837   878 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1109 12:50:00.754845   878 net.cpp:96] Setting up relu4_1
I1109 12:50:00.754855   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:00.754861   878 layer_factory.hpp:78] Creating layer conv4_2
I1109 12:50:00.754873   878 net.cpp:67] Creating Layer conv4_2
I1109 12:50:00.754879   878 net.cpp:394] conv4_2 <- conv4_1
I1109 12:50:00.754889   878 net.cpp:356] conv4_2 -> conv4_2
I1109 12:50:00.754899   878 net.cpp:96] Setting up conv4_2
I1109 12:50:00.867835   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:00.867882   878 layer_factory.hpp:78] Creating layer relu4_2
I1109 12:50:00.867898   878 net.cpp:67] Creating Layer relu4_2
I1109 12:50:00.867907   878 net.cpp:394] relu4_2 <- conv4_2
I1109 12:50:00.867916   878 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1109 12:50:00.867928   878 net.cpp:96] Setting up relu4_2
I1109 12:50:00.867938   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:00.867944   878 layer_factory.hpp:78] Creating layer conv4_3
I1109 12:50:00.867956   878 net.cpp:67] Creating Layer conv4_3
I1109 12:50:00.867962   878 net.cpp:394] conv4_3 <- conv4_2
I1109 12:50:00.867970   878 net.cpp:356] conv4_3 -> conv4_3
I1109 12:50:00.867980   878 net.cpp:96] Setting up conv4_3
I1109 12:50:00.981326   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:00.981369   878 layer_factory.hpp:78] Creating layer relu4_3
I1109 12:50:00.981382   878 net.cpp:67] Creating Layer relu4_3
I1109 12:50:00.981389   878 net.cpp:394] relu4_3 <- conv4_3
I1109 12:50:00.981403   878 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1109 12:50:00.981415   878 net.cpp:96] Setting up relu4_3
I1109 12:50:00.981426   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:00.981432   878 layer_factory.hpp:78] Creating layer pool4
I1109 12:50:00.981441   878 net.cpp:67] Creating Layer pool4
I1109 12:50:00.981447   878 net.cpp:394] pool4 <- conv4_3
I1109 12:50:00.981456   878 net.cpp:356] pool4 -> pool4
I1109 12:50:00.981466   878 net.cpp:96] Setting up pool4
I1109 12:50:00.981478   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:00.981484   878 layer_factory.hpp:78] Creating layer conv5_1
I1109 12:50:00.981498   878 net.cpp:67] Creating Layer conv5_1
I1109 12:50:00.981503   878 net.cpp:394] conv5_1 <- pool4
I1109 12:50:00.981518   878 net.cpp:356] conv5_1 -> conv5_1
I1109 12:50:00.981533   878 net.cpp:96] Setting up conv5_1
I1109 12:50:01.094698   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:01.094741   878 layer_factory.hpp:78] Creating layer relu5_1
I1109 12:50:01.094755   878 net.cpp:67] Creating Layer relu5_1
I1109 12:50:01.094763   878 net.cpp:394] relu5_1 <- conv5_1
I1109 12:50:01.094782   878 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1109 12:50:01.094795   878 net.cpp:96] Setting up relu5_1
I1109 12:50:01.094805   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:01.094812   878 layer_factory.hpp:78] Creating layer conv5_2
I1109 12:50:01.094822   878 net.cpp:67] Creating Layer conv5_2
I1109 12:50:01.094828   878 net.cpp:394] conv5_2 <- conv5_1
I1109 12:50:01.094840   878 net.cpp:356] conv5_2 -> conv5_2
I1109 12:50:01.094851   878 net.cpp:96] Setting up conv5_2
I1109 12:50:01.208222   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:01.208266   878 layer_factory.hpp:78] Creating layer relu5_2
I1109 12:50:01.208279   878 net.cpp:67] Creating Layer relu5_2
I1109 12:50:01.208287   878 net.cpp:394] relu5_2 <- conv5_2
I1109 12:50:01.208297   878 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1109 12:50:01.208307   878 net.cpp:96] Setting up relu5_2
I1109 12:50:01.208318   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:01.208324   878 layer_factory.hpp:78] Creating layer conv5_3
I1109 12:50:01.208336   878 net.cpp:67] Creating Layer conv5_3
I1109 12:50:01.208343   878 net.cpp:394] conv5_3 <- conv5_2
I1109 12:50:01.208351   878 net.cpp:356] conv5_3 -> conv5_3
I1109 12:50:01.208361   878 net.cpp:96] Setting up conv5_3
I1109 12:50:01.321156   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:01.321200   878 layer_factory.hpp:78] Creating layer relu5_3
I1109 12:50:01.321214   878 net.cpp:67] Creating Layer relu5_3
I1109 12:50:01.321221   878 net.cpp:394] relu5_3 <- conv5_3
I1109 12:50:01.321234   878 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1109 12:50:01.321245   878 net.cpp:96] Setting up relu5_3
I1109 12:50:01.321257   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:01.321264   878 layer_factory.hpp:78] Creating layer pool5
I1109 12:50:01.321287   878 net.cpp:67] Creating Layer pool5
I1109 12:50:01.321295   878 net.cpp:394] pool5 <- conv5_3
I1109 12:50:01.321303   878 net.cpp:356] pool5 -> pool5
I1109 12:50:01.321313   878 net.cpp:96] Setting up pool5
I1109 12:50:01.321329   878 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1109 12:50:01.321336   878 layer_factory.hpp:78] Creating layer fc6
I1109 12:50:01.321354   878 net.cpp:67] Creating Layer fc6
I1109 12:50:01.321360   878 net.cpp:394] fc6 <- pool5
I1109 12:50:01.321372   878 net.cpp:356] fc6 -> fc6
I1109 12:50:01.321382   878 net.cpp:96] Setting up fc6
I1109 12:50:06.211477   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:06.211521   878 layer_factory.hpp:78] Creating layer relu6
I1109 12:50:06.211534   878 net.cpp:67] Creating Layer relu6
I1109 12:50:06.211541   878 net.cpp:394] relu6 <- fc6
I1109 12:50:06.211555   878 net.cpp:345] relu6 -> fc6 (in-place)
I1109 12:50:06.211567   878 net.cpp:96] Setting up relu6
I1109 12:50:06.211587   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:06.211594   878 layer_factory.hpp:78] Creating layer drop6
I1109 12:50:06.211607   878 net.cpp:67] Creating Layer drop6
I1109 12:50:06.211612   878 net.cpp:394] drop6 <- fc6
I1109 12:50:06.211621   878 net.cpp:345] drop6 -> fc6 (in-place)
I1109 12:50:06.211628   878 net.cpp:96] Setting up drop6
I1109 12:50:06.211637   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:06.211643   878 layer_factory.hpp:78] Creating layer fc7
I1109 12:50:06.211654   878 net.cpp:67] Creating Layer fc7
I1109 12:50:06.211660   878 net.cpp:394] fc7 <- fc6
I1109 12:50:06.211669   878 net.cpp:356] fc7 -> fc7
I1109 12:50:06.211680   878 net.cpp:96] Setting up fc7
I1109 12:50:07.012435   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:07.012486   878 layer_factory.hpp:78] Creating layer relu7
I1109 12:50:07.012500   878 net.cpp:67] Creating Layer relu7
I1109 12:50:07.012507   878 net.cpp:394] relu7 <- fc7
I1109 12:50:07.012518   878 net.cpp:345] relu7 -> fc7 (in-place)
I1109 12:50:07.012528   878 net.cpp:96] Setting up relu7
I1109 12:50:07.012549   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:07.012555   878 layer_factory.hpp:78] Creating layer drop7
I1109 12:50:07.012563   878 net.cpp:67] Creating Layer drop7
I1109 12:50:07.012569   878 net.cpp:394] drop7 <- fc7
I1109 12:50:07.012579   878 net.cpp:345] drop7 -> fc7 (in-place)
I1109 12:50:07.012588   878 net.cpp:96] Setting up drop7
I1109 12:50:07.012594   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:07.012600   878 layer_factory.hpp:78] Creating layer fc8_2
I1109 12:50:07.012610   878 net.cpp:67] Creating Layer fc8_2
I1109 12:50:07.012615   878 net.cpp:394] fc8_2 <- fc7
I1109 12:50:07.012627   878 net.cpp:356] fc8_2 -> fc8_2
I1109 12:50:07.012637   878 net.cpp:96] Setting up fc8_2
I1109 12:50:07.013051   878 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:50:07.013067   878 layer_factory.hpp:78] Creating layer loss
I1109 12:50:07.013083   878 net.cpp:67] Creating Layer loss
I1109 12:50:07.013090   878 net.cpp:394] loss <- fc8_2
I1109 12:50:07.013098   878 net.cpp:394] loss <- label
I1109 12:50:07.013109   878 net.cpp:356] loss -> (automatic)
I1109 12:50:07.013118   878 net.cpp:96] Setting up loss
I1109 12:50:07.013146   878 net.cpp:103] Top shape: 1 1 1 1 (1)
I1109 12:50:07.013154   878 net.cpp:109]     with loss weight 1
I1109 12:50:07.013196   878 net.cpp:170] loss needs backward computation.
I1109 12:50:07.013202   878 net.cpp:170] fc8_2 needs backward computation.
I1109 12:50:07.013208   878 net.cpp:170] drop7 needs backward computation.
I1109 12:50:07.013213   878 net.cpp:170] relu7 needs backward computation.
I1109 12:50:07.013218   878 net.cpp:170] fc7 needs backward computation.
I1109 12:50:07.013223   878 net.cpp:170] drop6 needs backward computation.
I1109 12:50:07.013228   878 net.cpp:170] relu6 needs backward computation.
I1109 12:50:07.013233   878 net.cpp:170] fc6 needs backward computation.
I1109 12:50:07.013239   878 net.cpp:170] pool5 needs backward computation.
I1109 12:50:07.013245   878 net.cpp:170] relu5_3 needs backward computation.
I1109 12:50:07.013263   878 net.cpp:170] conv5_3 needs backward computation.
I1109 12:50:07.013270   878 net.cpp:170] relu5_2 needs backward computation.
I1109 12:50:07.013275   878 net.cpp:170] conv5_2 needs backward computation.
I1109 12:50:07.013281   878 net.cpp:170] relu5_1 needs backward computation.
I1109 12:50:07.013286   878 net.cpp:170] conv5_1 needs backward computation.
I1109 12:50:07.013293   878 net.cpp:170] pool4 needs backward computation.
I1109 12:50:07.013298   878 net.cpp:170] relu4_3 needs backward computation.
I1109 12:50:07.013303   878 net.cpp:170] conv4_3 needs backward computation.
I1109 12:50:07.013309   878 net.cpp:170] relu4_2 needs backward computation.
I1109 12:50:07.013314   878 net.cpp:170] conv4_2 needs backward computation.
I1109 12:50:07.013320   878 net.cpp:170] relu4_1 needs backward computation.
I1109 12:50:07.013329   878 net.cpp:170] conv4_1 needs backward computation.
I1109 12:50:07.013334   878 net.cpp:170] pool3 needs backward computation.
I1109 12:50:07.013340   878 net.cpp:170] relu3_3 needs backward computation.
I1109 12:50:07.013346   878 net.cpp:170] conv3_3 needs backward computation.
I1109 12:50:07.013352   878 net.cpp:170] relu3_2 needs backward computation.
I1109 12:50:07.013357   878 net.cpp:170] conv3_2 needs backward computation.
I1109 12:50:07.013363   878 net.cpp:170] relu3_1 needs backward computation.
I1109 12:50:07.013368   878 net.cpp:170] conv3_1 needs backward computation.
I1109 12:50:07.013375   878 net.cpp:170] pool2 needs backward computation.
I1109 12:50:07.013380   878 net.cpp:170] relu2_2 needs backward computation.
I1109 12:50:07.013386   878 net.cpp:170] conv2_2 needs backward computation.
I1109 12:50:07.013391   878 net.cpp:170] relu2_1 needs backward computation.
I1109 12:50:07.013396   878 net.cpp:170] conv2_1 needs backward computation.
I1109 12:50:07.013401   878 net.cpp:170] pool1 needs backward computation.
I1109 12:50:07.013407   878 net.cpp:170] relu1_2 needs backward computation.
I1109 12:50:07.013413   878 net.cpp:170] conv1_2 needs backward computation.
I1109 12:50:07.013418   878 net.cpp:170] relu1_1 needs backward computation.
I1109 12:50:07.013424   878 net.cpp:170] conv1_1 needs backward computation.
I1109 12:50:07.013430   878 net.cpp:172] data does not need backward computation.
I1109 12:50:07.013460   878 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1109 12:50:07.013479   878 net.cpp:219] Network initialization done.
I1109 12:50:07.013484   878 net.cpp:220] Memory required for data: 921616484
I1109 12:50:07.014953   878 solver.cpp:151] Creating test net (#0) specified by net file: task/inadcl_o/train_val.prototxt
I1109 12:50:07.015043   878 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1109 12:50:07.015427   878 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/inadcl_o/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1109 12:50:07.015663   878 layer_factory.hpp:78] Creating layer data
I1109 12:50:07.015682   878 net.cpp:67] Creating Layer data
I1109 12:50:07.015691   878 net.cpp:356] data -> data
I1109 12:50:07.015702   878 net.cpp:356] data -> label
I1109 12:50:07.015713   878 net.cpp:96] Setting up data
I1109 12:50:07.015719   878 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/inadcl_o/val.txt
I1109 12:50:07.015964   878 image_data_layer.cpp:49] A total of 315 images.
I1109 12:50:07.030625   878 image_data_layer.cpp:78] output data size: 8,3,224,224
I1109 12:50:07.032480   878 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1109 12:50:07.032502   878 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:50:07.032510   878 layer_factory.hpp:78] Creating layer label_data_1_split
I1109 12:50:07.032528   878 net.cpp:67] Creating Layer label_data_1_split
I1109 12:50:07.032536   878 net.cpp:394] label_data_1_split <- label
I1109 12:50:07.032547   878 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1109 12:50:07.032562   878 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1109 12:50:07.032572   878 net.cpp:96] Setting up label_data_1_split
I1109 12:50:07.032582   878 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:50:07.032588   878 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:50:07.032593   878 layer_factory.hpp:78] Creating layer conv1_1
I1109 12:50:07.032604   878 net.cpp:67] Creating Layer conv1_1
I1109 12:50:07.032610   878 net.cpp:394] conv1_1 <- data
I1109 12:50:07.032619   878 net.cpp:356] conv1_1 -> conv1_1
I1109 12:50:07.032629   878 net.cpp:96] Setting up conv1_1
I1109 12:50:07.032918   878 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:07.032946   878 layer_factory.hpp:78] Creating layer relu1_1
I1109 12:50:07.032956   878 net.cpp:67] Creating Layer relu1_1
I1109 12:50:07.032961   878 net.cpp:394] relu1_1 <- conv1_1
I1109 12:50:07.032970   878 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1109 12:50:07.032979   878 net.cpp:96] Setting up relu1_1
I1109 12:50:07.032989   878 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:07.033009   878 layer_factory.hpp:78] Creating layer conv1_2
I1109 12:50:07.033018   878 net.cpp:67] Creating Layer conv1_2
I1109 12:50:07.033023   878 net.cpp:394] conv1_2 <- conv1_1
I1109 12:50:07.033032   878 net.cpp:356] conv1_2 -> conv1_2
I1109 12:50:07.033042   878 net.cpp:96] Setting up conv1_2
I1109 12:50:07.034960   878 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:07.034986   878 layer_factory.hpp:78] Creating layer relu1_2
I1109 12:50:07.034996   878 net.cpp:67] Creating Layer relu1_2
I1109 12:50:07.035001   878 net.cpp:394] relu1_2 <- conv1_2
I1109 12:50:07.035011   878 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1109 12:50:07.035018   878 net.cpp:96] Setting up relu1_2
I1109 12:50:07.035028   878 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:07.035034   878 layer_factory.hpp:78] Creating layer pool1
I1109 12:50:07.035043   878 net.cpp:67] Creating Layer pool1
I1109 12:50:07.035049   878 net.cpp:394] pool1 <- conv1_2
I1109 12:50:07.035058   878 net.cpp:356] pool1 -> pool1
I1109 12:50:07.035065   878 net.cpp:96] Setting up pool1
I1109 12:50:07.035078   878 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1109 12:50:07.035084   878 layer_factory.hpp:78] Creating layer conv2_1
I1109 12:50:07.035092   878 net.cpp:67] Creating Layer conv2_1
I1109 12:50:07.035099   878 net.cpp:394] conv2_1 <- pool1
I1109 12:50:07.035106   878 net.cpp:356] conv2_1 -> conv2_1
I1109 12:50:07.035115   878 net.cpp:96] Setting up conv2_1
I1109 12:50:07.038961   878 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:07.038987   878 layer_factory.hpp:78] Creating layer relu2_1
I1109 12:50:07.038998   878 net.cpp:67] Creating Layer relu2_1
I1109 12:50:07.039005   878 net.cpp:394] relu2_1 <- conv2_1
I1109 12:50:07.039013   878 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1109 12:50:07.039022   878 net.cpp:96] Setting up relu2_1
I1109 12:50:07.039032   878 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:07.039038   878 layer_factory.hpp:78] Creating layer conv2_2
I1109 12:50:07.039047   878 net.cpp:67] Creating Layer conv2_2
I1109 12:50:07.039052   878 net.cpp:394] conv2_2 <- conv2_1
I1109 12:50:07.039062   878 net.cpp:356] conv2_2 -> conv2_2
I1109 12:50:07.039072   878 net.cpp:96] Setting up conv2_2
I1109 12:50:07.046190   878 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:07.046213   878 layer_factory.hpp:78] Creating layer relu2_2
I1109 12:50:07.046223   878 net.cpp:67] Creating Layer relu2_2
I1109 12:50:07.046229   878 net.cpp:394] relu2_2 <- conv2_2
I1109 12:50:07.046237   878 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1109 12:50:07.046247   878 net.cpp:96] Setting up relu2_2
I1109 12:50:07.046257   878 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:07.046262   878 layer_factory.hpp:78] Creating layer pool2
I1109 12:50:07.046270   878 net.cpp:67] Creating Layer pool2
I1109 12:50:07.046275   878 net.cpp:394] pool2 <- conv2_2
I1109 12:50:07.046284   878 net.cpp:356] pool2 -> pool2
I1109 12:50:07.046293   878 net.cpp:96] Setting up pool2
I1109 12:50:07.046303   878 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1109 12:50:07.046309   878 layer_factory.hpp:78] Creating layer conv3_1
I1109 12:50:07.046319   878 net.cpp:67] Creating Layer conv3_1
I1109 12:50:07.046324   878 net.cpp:394] conv3_1 <- pool2
I1109 12:50:07.046332   878 net.cpp:356] conv3_1 -> conv3_1
I1109 12:50:07.046341   878 net.cpp:96] Setting up conv3_1
I1109 12:50:07.060487   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:07.060519   878 layer_factory.hpp:78] Creating layer relu3_1
I1109 12:50:07.060530   878 net.cpp:67] Creating Layer relu3_1
I1109 12:50:07.060536   878 net.cpp:394] relu3_1 <- conv3_1
I1109 12:50:07.060545   878 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1109 12:50:07.060555   878 net.cpp:96] Setting up relu3_1
I1109 12:50:07.060564   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:07.060570   878 layer_factory.hpp:78] Creating layer conv3_2
I1109 12:50:07.060580   878 net.cpp:67] Creating Layer conv3_2
I1109 12:50:07.060585   878 net.cpp:394] conv3_2 <- conv3_1
I1109 12:50:07.060609   878 net.cpp:356] conv3_2 -> conv3_2
I1109 12:50:07.060619   878 net.cpp:96] Setting up conv3_2
I1109 12:50:07.089376   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:07.089412   878 layer_factory.hpp:78] Creating layer relu3_2
I1109 12:50:07.089428   878 net.cpp:67] Creating Layer relu3_2
I1109 12:50:07.089436   878 net.cpp:394] relu3_2 <- conv3_2
I1109 12:50:07.089445   878 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1109 12:50:07.089457   878 net.cpp:96] Setting up relu3_2
I1109 12:50:07.089467   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:07.089473   878 layer_factory.hpp:78] Creating layer conv3_3
I1109 12:50:07.089488   878 net.cpp:67] Creating Layer conv3_3
I1109 12:50:07.089494   878 net.cpp:394] conv3_3 <- conv3_2
I1109 12:50:07.089504   878 net.cpp:356] conv3_3 -> conv3_3
I1109 12:50:07.089514   878 net.cpp:96] Setting up conv3_3
I1109 12:50:07.118510   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:07.118543   878 layer_factory.hpp:78] Creating layer relu3_3
I1109 12:50:07.118556   878 net.cpp:67] Creating Layer relu3_3
I1109 12:50:07.118562   878 net.cpp:394] relu3_3 <- conv3_3
I1109 12:50:07.118572   878 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1109 12:50:07.118583   878 net.cpp:96] Setting up relu3_3
I1109 12:50:07.118593   878 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:07.118600   878 layer_factory.hpp:78] Creating layer pool3
I1109 12:50:07.118613   878 net.cpp:67] Creating Layer pool3
I1109 12:50:07.118618   878 net.cpp:394] pool3 <- conv3_3
I1109 12:50:07.118628   878 net.cpp:356] pool3 -> pool3
I1109 12:50:07.118636   878 net.cpp:96] Setting up pool3
I1109 12:50:07.118649   878 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1109 12:50:07.118655   878 layer_factory.hpp:78] Creating layer conv4_1
I1109 12:50:07.118667   878 net.cpp:67] Creating Layer conv4_1
I1109 12:50:07.118674   878 net.cpp:394] conv4_1 <- pool3
I1109 12:50:07.118682   878 net.cpp:356] conv4_1 -> conv4_1
I1109 12:50:07.118692   878 net.cpp:96] Setting up conv4_1
I1109 12:50:07.175922   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:07.175961   878 layer_factory.hpp:78] Creating layer relu4_1
I1109 12:50:07.175973   878 net.cpp:67] Creating Layer relu4_1
I1109 12:50:07.175981   878 net.cpp:394] relu4_1 <- conv4_1
I1109 12:50:07.175992   878 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1109 12:50:07.176002   878 net.cpp:96] Setting up relu4_1
I1109 12:50:07.176012   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:07.176019   878 layer_factory.hpp:78] Creating layer conv4_2
I1109 12:50:07.176033   878 net.cpp:67] Creating Layer conv4_2
I1109 12:50:07.176038   878 net.cpp:394] conv4_2 <- conv4_1
I1109 12:50:07.176048   878 net.cpp:356] conv4_2 -> conv4_2
I1109 12:50:07.176059   878 net.cpp:96] Setting up conv4_2
I1109 12:50:07.288851   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:07.288903   878 layer_factory.hpp:78] Creating layer relu4_2
I1109 12:50:07.288919   878 net.cpp:67] Creating Layer relu4_2
I1109 12:50:07.288926   878 net.cpp:394] relu4_2 <- conv4_2
I1109 12:50:07.288938   878 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1109 12:50:07.288949   878 net.cpp:96] Setting up relu4_2
I1109 12:50:07.288959   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:07.288966   878 layer_factory.hpp:78] Creating layer conv4_3
I1109 12:50:07.288979   878 net.cpp:67] Creating Layer conv4_3
I1109 12:50:07.288985   878 net.cpp:394] conv4_3 <- conv4_2
I1109 12:50:07.288993   878 net.cpp:356] conv4_3 -> conv4_3
I1109 12:50:07.289005   878 net.cpp:96] Setting up conv4_3
I1109 12:50:07.402252   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:07.402298   878 layer_factory.hpp:78] Creating layer relu4_3
I1109 12:50:07.402314   878 net.cpp:67] Creating Layer relu4_3
I1109 12:50:07.402323   878 net.cpp:394] relu4_3 <- conv4_3
I1109 12:50:07.402331   878 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1109 12:50:07.402343   878 net.cpp:96] Setting up relu4_3
I1109 12:50:07.402354   878 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:07.402375   878 layer_factory.hpp:78] Creating layer pool4
I1109 12:50:07.402387   878 net.cpp:67] Creating Layer pool4
I1109 12:50:07.402393   878 net.cpp:394] pool4 <- conv4_3
I1109 12:50:07.402401   878 net.cpp:356] pool4 -> pool4
I1109 12:50:07.402411   878 net.cpp:96] Setting up pool4
I1109 12:50:07.402425   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:07.402431   878 layer_factory.hpp:78] Creating layer conv5_1
I1109 12:50:07.402441   878 net.cpp:67] Creating Layer conv5_1
I1109 12:50:07.402446   878 net.cpp:394] conv5_1 <- pool4
I1109 12:50:07.402457   878 net.cpp:356] conv5_1 -> conv5_1
I1109 12:50:07.402467   878 net.cpp:96] Setting up conv5_1
I1109 12:50:07.515305   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:07.515352   878 layer_factory.hpp:78] Creating layer relu5_1
I1109 12:50:07.515374   878 net.cpp:67] Creating Layer relu5_1
I1109 12:50:07.515383   878 net.cpp:394] relu5_1 <- conv5_1
I1109 12:50:07.515393   878 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1109 12:50:07.515406   878 net.cpp:96] Setting up relu5_1
I1109 12:50:07.515418   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:07.515424   878 layer_factory.hpp:78] Creating layer conv5_2
I1109 12:50:07.515435   878 net.cpp:67] Creating Layer conv5_2
I1109 12:50:07.515441   878 net.cpp:394] conv5_2 <- conv5_1
I1109 12:50:07.515450   878 net.cpp:356] conv5_2 -> conv5_2
I1109 12:50:07.515460   878 net.cpp:96] Setting up conv5_2
I1109 12:50:07.628669   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:07.628713   878 layer_factory.hpp:78] Creating layer relu5_2
I1109 12:50:07.628726   878 net.cpp:67] Creating Layer relu5_2
I1109 12:50:07.628733   878 net.cpp:394] relu5_2 <- conv5_2
I1109 12:50:07.628743   878 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1109 12:50:07.628754   878 net.cpp:96] Setting up relu5_2
I1109 12:50:07.628764   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:07.628770   878 layer_factory.hpp:78] Creating layer conv5_3
I1109 12:50:07.628780   878 net.cpp:67] Creating Layer conv5_3
I1109 12:50:07.628785   878 net.cpp:394] conv5_3 <- conv5_2
I1109 12:50:07.628798   878 net.cpp:356] conv5_3 -> conv5_3
I1109 12:50:07.628808   878 net.cpp:96] Setting up conv5_3
I1109 12:50:07.742524   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:07.742564   878 layer_factory.hpp:78] Creating layer relu5_3
I1109 12:50:07.742580   878 net.cpp:67] Creating Layer relu5_3
I1109 12:50:07.742588   878 net.cpp:394] relu5_3 <- conv5_3
I1109 12:50:07.742599   878 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1109 12:50:07.742611   878 net.cpp:96] Setting up relu5_3
I1109 12:50:07.742621   878 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:07.742627   878 layer_factory.hpp:78] Creating layer pool5
I1109 12:50:07.742645   878 net.cpp:67] Creating Layer pool5
I1109 12:50:07.742650   878 net.cpp:394] pool5 <- conv5_3
I1109 12:50:07.742660   878 net.cpp:356] pool5 -> pool5
I1109 12:50:07.742668   878 net.cpp:96] Setting up pool5
I1109 12:50:07.742681   878 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1109 12:50:07.742687   878 layer_factory.hpp:78] Creating layer fc6
I1109 12:50:07.742699   878 net.cpp:67] Creating Layer fc6
I1109 12:50:07.742705   878 net.cpp:394] fc6 <- pool5
I1109 12:50:07.742713   878 net.cpp:356] fc6 -> fc6
I1109 12:50:07.742722   878 net.cpp:96] Setting up fc6
I1109 12:50:12.633862   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:12.633908   878 layer_factory.hpp:78] Creating layer relu6
I1109 12:50:12.633923   878 net.cpp:67] Creating Layer relu6
I1109 12:50:12.633931   878 net.cpp:394] relu6 <- fc6
I1109 12:50:12.633942   878 net.cpp:345] relu6 -> fc6 (in-place)
I1109 12:50:12.633954   878 net.cpp:96] Setting up relu6
I1109 12:50:12.633973   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:12.633980   878 layer_factory.hpp:78] Creating layer drop6
I1109 12:50:12.633988   878 net.cpp:67] Creating Layer drop6
I1109 12:50:12.633993   878 net.cpp:394] drop6 <- fc6
I1109 12:50:12.634003   878 net.cpp:345] drop6 -> fc6 (in-place)
I1109 12:50:12.634027   878 net.cpp:96] Setting up drop6
I1109 12:50:12.634034   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:12.634040   878 layer_factory.hpp:78] Creating layer fc7
I1109 12:50:12.634049   878 net.cpp:67] Creating Layer fc7
I1109 12:50:12.634055   878 net.cpp:394] fc7 <- fc6
I1109 12:50:12.634063   878 net.cpp:356] fc7 -> fc7
I1109 12:50:12.634073   878 net.cpp:96] Setting up fc7
I1109 12:50:13.434325   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:13.434371   878 layer_factory.hpp:78] Creating layer relu7
I1109 12:50:13.434384   878 net.cpp:67] Creating Layer relu7
I1109 12:50:13.434392   878 net.cpp:394] relu7 <- fc7
I1109 12:50:13.434406   878 net.cpp:345] relu7 -> fc7 (in-place)
I1109 12:50:13.434417   878 net.cpp:96] Setting up relu7
I1109 12:50:13.434437   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:13.434443   878 layer_factory.hpp:78] Creating layer drop7
I1109 12:50:13.434453   878 net.cpp:67] Creating Layer drop7
I1109 12:50:13.434458   878 net.cpp:394] drop7 <- fc7
I1109 12:50:13.434465   878 net.cpp:345] drop7 -> fc7 (in-place)
I1109 12:50:13.434473   878 net.cpp:96] Setting up drop7
I1109 12:50:13.434479   878 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:13.434485   878 layer_factory.hpp:78] Creating layer fc8_2
I1109 12:50:13.434494   878 net.cpp:67] Creating Layer fc8_2
I1109 12:50:13.434499   878 net.cpp:394] fc8_2 <- fc7
I1109 12:50:13.434510   878 net.cpp:356] fc8_2 -> fc8_2
I1109 12:50:13.434521   878 net.cpp:96] Setting up fc8_2
I1109 12:50:13.434937   878 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:50:13.434954   878 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1109 12:50:13.434965   878 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1109 12:50:13.434972   878 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1109 12:50:13.434979   878 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1109 12:50:13.434989   878 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1109 12:50:13.434998   878 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1109 12:50:13.435005   878 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:50:13.435011   878 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:50:13.435016   878 layer_factory.hpp:78] Creating layer loss
I1109 12:50:13.435027   878 net.cpp:67] Creating Layer loss
I1109 12:50:13.435034   878 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1109 12:50:13.435039   878 net.cpp:394] loss <- label_data_1_split_0
I1109 12:50:13.435048   878 net.cpp:356] loss -> (automatic)
I1109 12:50:13.435055   878 net.cpp:96] Setting up loss
I1109 12:50:13.435065   878 net.cpp:103] Top shape: 1 1 1 1 (1)
I1109 12:50:13.435071   878 net.cpp:109]     with loss weight 1
I1109 12:50:13.435091   878 layer_factory.hpp:78] Creating layer accuracy
I1109 12:50:13.435107   878 net.cpp:67] Creating Layer accuracy
I1109 12:50:13.435113   878 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1109 12:50:13.435120   878 net.cpp:394] accuracy <- label_data_1_split_1
I1109 12:50:13.435128   878 net.cpp:356] accuracy -> accuracy
I1109 12:50:13.435137   878 net.cpp:96] Setting up accuracy
I1109 12:50:13.435148   878 net.cpp:103] Top shape: 1 1 1 4 (4)
I1109 12:50:13.435154   878 net.cpp:172] accuracy does not need backward computation.
I1109 12:50:13.435159   878 net.cpp:170] loss needs backward computation.
I1109 12:50:13.435165   878 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1109 12:50:13.435170   878 net.cpp:170] fc8_2 needs backward computation.
I1109 12:50:13.435175   878 net.cpp:170] drop7 needs backward computation.
I1109 12:50:13.435180   878 net.cpp:170] relu7 needs backward computation.
I1109 12:50:13.435185   878 net.cpp:170] fc7 needs backward computation.
I1109 12:50:13.435190   878 net.cpp:170] drop6 needs backward computation.
I1109 12:50:13.435195   878 net.cpp:170] relu6 needs backward computation.
I1109 12:50:13.435200   878 net.cpp:170] fc6 needs backward computation.
I1109 12:50:13.435205   878 net.cpp:170] pool5 needs backward computation.
I1109 12:50:13.435223   878 net.cpp:170] relu5_3 needs backward computation.
I1109 12:50:13.435230   878 net.cpp:170] conv5_3 needs backward computation.
I1109 12:50:13.435235   878 net.cpp:170] relu5_2 needs backward computation.
I1109 12:50:13.435240   878 net.cpp:170] conv5_2 needs backward computation.
I1109 12:50:13.435245   878 net.cpp:170] relu5_1 needs backward computation.
I1109 12:50:13.435250   878 net.cpp:170] conv5_1 needs backward computation.
I1109 12:50:13.435256   878 net.cpp:170] pool4 needs backward computation.
I1109 12:50:13.435261   878 net.cpp:170] relu4_3 needs backward computation.
I1109 12:50:13.435266   878 net.cpp:170] conv4_3 needs backward computation.
I1109 12:50:13.435272   878 net.cpp:170] relu4_2 needs backward computation.
I1109 12:50:13.435277   878 net.cpp:170] conv4_2 needs backward computation.
I1109 12:50:13.435282   878 net.cpp:170] relu4_1 needs backward computation.
I1109 12:50:13.435287   878 net.cpp:170] conv4_1 needs backward computation.
I1109 12:50:13.435292   878 net.cpp:170] pool3 needs backward computation.
I1109 12:50:13.435298   878 net.cpp:170] relu3_3 needs backward computation.
I1109 12:50:13.435302   878 net.cpp:170] conv3_3 needs backward computation.
I1109 12:50:13.435308   878 net.cpp:170] relu3_2 needs backward computation.
I1109 12:50:13.435313   878 net.cpp:170] conv3_2 needs backward computation.
I1109 12:50:13.435318   878 net.cpp:170] relu3_1 needs backward computation.
I1109 12:50:13.435323   878 net.cpp:170] conv3_1 needs backward computation.
I1109 12:50:13.435329   878 net.cpp:170] pool2 needs backward computation.
I1109 12:50:13.435338   878 net.cpp:170] relu2_2 needs backward computation.
I1109 12:50:13.435343   878 net.cpp:170] conv2_2 needs backward computation.
I1109 12:50:13.435354   878 net.cpp:170] relu2_1 needs backward computation.
I1109 12:50:13.435359   878 net.cpp:170] conv2_1 needs backward computation.
I1109 12:50:13.435365   878 net.cpp:170] pool1 needs backward computation.
I1109 12:50:13.435371   878 net.cpp:170] relu1_2 needs backward computation.
I1109 12:50:13.435376   878 net.cpp:170] conv1_2 needs backward computation.
I1109 12:50:13.435382   878 net.cpp:170] relu1_1 needs backward computation.
I1109 12:50:13.435430   878 net.cpp:170] conv1_1 needs backward computation.
I1109 12:50:13.435442   878 net.cpp:172] label_data_1_split does not need backward computation.
I1109 12:50:13.435449   878 net.cpp:172] data does not need backward computation.
I1109 12:50:13.435454   878 net.cpp:208] This network produces output accuracy
I1109 12:50:13.435489   878 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1109 12:50:13.435502   878 net.cpp:219] Network initialization done.
I1109 12:50:13.435506   878 net.cpp:220] Memory required for data: 921616692
I1109 12:50:13.435768   878 solver.cpp:41] Solver scaffolding done.
I1109 12:50:13.435786   878 caffe.cpp:115] Finetuning from task/inadcl_o/none/_iter_3000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077499
I1109 12:50:15.895036   878 solver.cpp:160] Solving small
I1109 12:50:15.895072   878 solver.cpp:161] Learning Rate Policy: step
I1109 12:50:17.225045   878 solver.cpp:339] Snapshotting to _iter_0.caffemodel
I1109 12:50:19.558432   878 solver.cpp:347] Snapshotting solver state to _iter_0.solverstate
I1109 12:50:21.849158   878 solver.cpp:246] Iteration 0, loss = 0.454959
I1109 12:50:21.849215   878 solver.cpp:264] Iteration 0, Testing net (#0)
I1109 12:50:32.794317   878 solver.cpp:305] Test loss: 0.532343
I1109 12:50:32.794404   878 solver.cpp:320]     Test net output #0: accuracy = 0.820197
I1109 12:50:32.794416   878 solver.cpp:320]     Test net output #1: accuracy = 0.637931
I1109 12:50:32.794425   878 solver.cpp:320]     Test net output #2: accuracy = 0.729064
I1109 12:50:32.794432   878 solver.cpp:320]     Test net output #3: accuracy = 0.775862
I1109 12:50:32.794441   878 solver.cpp:251] Optimization Done.
I1109 12:50:32.794446   878 caffe.cpp:121] Optimization Done.
I1109 12:50:33.059289   924 caffe.cpp:99] Use GPU with device ID 0
I1109 12:50:33.373608   924 caffe.cpp:107] Starting Optimization
I1109 12:50:33.373757   924 solver.cpp:32] Initializing solver from parameters: 
test_iter: 29
test_interval: 1
base_lr: 0
display: 10
max_iter: 0
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 200
solver_mode: GPU
test_compute_loss: true
net: "task/inadcl_o/train_val.prototxt"
I1109 12:50:33.373793   924 solver.cpp:67] Creating training net from net file: task/inadcl_o/train_val.prototxt
I1109 12:50:33.375265   924 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 12:50:33.375322   924 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 12:50:33.375690   924 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/inadcl_o/train.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1109 12:50:33.375900   924 layer_factory.hpp:78] Creating layer data
I1109 12:50:33.375928   924 net.cpp:67] Creating Layer data
I1109 12:50:33.375939   924 net.cpp:356] data -> data
I1109 12:50:33.375979   924 net.cpp:356] data -> label
I1109 12:50:33.376004   924 net.cpp:96] Setting up data
I1109 12:50:33.376015   924 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/inadcl_o/train.txt
I1109 12:50:33.389673   924 image_data_layer.cpp:49] A total of 20637 images.
I1109 12:50:33.400265   924 image_data_layer.cpp:78] output data size: 8,3,224,224
I1109 12:50:33.402640   924 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1109 12:50:33.402664   924 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:50:33.402673   924 layer_factory.hpp:78] Creating layer conv1_1
I1109 12:50:33.402691   924 net.cpp:67] Creating Layer conv1_1
I1109 12:50:33.402699   924 net.cpp:394] conv1_1 <- data
I1109 12:50:33.402744   924 net.cpp:356] conv1_1 -> conv1_1
I1109 12:50:33.402765   924 net.cpp:96] Setting up conv1_1
I1109 12:50:33.431900   924 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:33.431953   924 layer_factory.hpp:78] Creating layer relu1_1
I1109 12:50:33.431977   924 net.cpp:67] Creating Layer relu1_1
I1109 12:50:33.431984   924 net.cpp:394] relu1_1 <- conv1_1
I1109 12:50:33.431995   924 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1109 12:50:33.432009   924 net.cpp:96] Setting up relu1_1
I1109 12:50:33.432024   924 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:33.432031   924 layer_factory.hpp:78] Creating layer conv1_2
I1109 12:50:33.432044   924 net.cpp:67] Creating Layer conv1_2
I1109 12:50:33.432050   924 net.cpp:394] conv1_2 <- conv1_1
I1109 12:50:33.432060   924 net.cpp:356] conv1_2 -> conv1_2
I1109 12:50:33.432070   924 net.cpp:96] Setting up conv1_2
I1109 12:50:33.434185   924 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:33.434211   924 layer_factory.hpp:78] Creating layer relu1_2
I1109 12:50:33.434227   924 net.cpp:67] Creating Layer relu1_2
I1109 12:50:33.434233   924 net.cpp:394] relu1_2 <- conv1_2
I1109 12:50:33.434242   924 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1109 12:50:33.434252   924 net.cpp:96] Setting up relu1_2
I1109 12:50:33.434262   924 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:33.434267   924 layer_factory.hpp:78] Creating layer pool1
I1109 12:50:33.434281   924 net.cpp:67] Creating Layer pool1
I1109 12:50:33.434288   924 net.cpp:394] pool1 <- conv1_2
I1109 12:50:33.434296   924 net.cpp:356] pool1 -> pool1
I1109 12:50:33.434306   924 net.cpp:96] Setting up pool1
I1109 12:50:33.434332   924 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1109 12:50:33.434340   924 layer_factory.hpp:78] Creating layer conv2_1
I1109 12:50:33.434351   924 net.cpp:67] Creating Layer conv2_1
I1109 12:50:33.434358   924 net.cpp:394] conv2_1 <- pool1
I1109 12:50:33.434367   924 net.cpp:356] conv2_1 -> conv2_1
I1109 12:50:33.434377   924 net.cpp:96] Setting up conv2_1
I1109 12:50:33.438143   924 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:33.438169   924 layer_factory.hpp:78] Creating layer relu2_1
I1109 12:50:33.438179   924 net.cpp:67] Creating Layer relu2_1
I1109 12:50:33.438184   924 net.cpp:394] relu2_1 <- conv2_1
I1109 12:50:33.438196   924 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1109 12:50:33.438205   924 net.cpp:96] Setting up relu2_1
I1109 12:50:33.438215   924 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:33.438222   924 layer_factory.hpp:78] Creating layer conv2_2
I1109 12:50:33.438235   924 net.cpp:67] Creating Layer conv2_2
I1109 12:50:33.438242   924 net.cpp:394] conv2_2 <- conv2_1
I1109 12:50:33.438251   924 net.cpp:356] conv2_2 -> conv2_2
I1109 12:50:33.438261   924 net.cpp:96] Setting up conv2_2
I1109 12:50:33.445629   924 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:33.445654   924 layer_factory.hpp:78] Creating layer relu2_2
I1109 12:50:33.445677   924 net.cpp:67] Creating Layer relu2_2
I1109 12:50:33.445683   924 net.cpp:394] relu2_2 <- conv2_2
I1109 12:50:33.445693   924 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1109 12:50:33.445701   924 net.cpp:96] Setting up relu2_2
I1109 12:50:33.445713   924 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:33.445719   924 layer_factory.hpp:78] Creating layer pool2
I1109 12:50:33.445739   924 net.cpp:67] Creating Layer pool2
I1109 12:50:33.445843   924 net.cpp:394] pool2 <- conv2_2
I1109 12:50:33.445862   924 net.cpp:356] pool2 -> pool2
I1109 12:50:33.445878   924 net.cpp:96] Setting up pool2
I1109 12:50:33.445893   924 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1109 12:50:33.445900   924 layer_factory.hpp:78] Creating layer conv3_1
I1109 12:50:33.445910   924 net.cpp:67] Creating Layer conv3_1
I1109 12:50:33.445915   924 net.cpp:394] conv3_1 <- pool2
I1109 12:50:33.445929   924 net.cpp:356] conv3_1 -> conv3_1
I1109 12:50:33.445940   924 net.cpp:96] Setting up conv3_1
I1109 12:50:33.460427   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:33.460464   924 layer_factory.hpp:78] Creating layer relu3_1
I1109 12:50:33.460474   924 net.cpp:67] Creating Layer relu3_1
I1109 12:50:33.460481   924 net.cpp:394] relu3_1 <- conv3_1
I1109 12:50:33.460494   924 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1109 12:50:33.460505   924 net.cpp:96] Setting up relu3_1
I1109 12:50:33.460515   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:33.460520   924 layer_factory.hpp:78] Creating layer conv3_2
I1109 12:50:33.460530   924 net.cpp:67] Creating Layer conv3_2
I1109 12:50:33.460536   924 net.cpp:394] conv3_2 <- conv3_1
I1109 12:50:33.460548   924 net.cpp:356] conv3_2 -> conv3_2
I1109 12:50:33.460559   924 net.cpp:96] Setting up conv3_2
I1109 12:50:33.489593   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:33.489626   924 layer_factory.hpp:78] Creating layer relu3_2
I1109 12:50:33.489640   924 net.cpp:67] Creating Layer relu3_2
I1109 12:50:33.489648   924 net.cpp:394] relu3_2 <- conv3_2
I1109 12:50:33.489657   924 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1109 12:50:33.489668   924 net.cpp:96] Setting up relu3_2
I1109 12:50:33.489678   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:33.489684   924 layer_factory.hpp:78] Creating layer conv3_3
I1109 12:50:33.489693   924 net.cpp:67] Creating Layer conv3_3
I1109 12:50:33.489699   924 net.cpp:394] conv3_3 <- conv3_2
I1109 12:50:33.489711   924 net.cpp:356] conv3_3 -> conv3_3
I1109 12:50:33.489722   924 net.cpp:96] Setting up conv3_3
I1109 12:50:33.518596   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:33.518631   924 layer_factory.hpp:78] Creating layer relu3_3
I1109 12:50:33.518651   924 net.cpp:67] Creating Layer relu3_3
I1109 12:50:33.518657   924 net.cpp:394] relu3_3 <- conv3_3
I1109 12:50:33.518667   924 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1109 12:50:33.518678   924 net.cpp:96] Setting up relu3_3
I1109 12:50:33.518688   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:33.518694   924 layer_factory.hpp:78] Creating layer pool3
I1109 12:50:33.518703   924 net.cpp:67] Creating Layer pool3
I1109 12:50:33.518709   924 net.cpp:394] pool3 <- conv3_3
I1109 12:50:33.518720   924 net.cpp:356] pool3 -> pool3
I1109 12:50:33.518730   924 net.cpp:96] Setting up pool3
I1109 12:50:33.518743   924 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1109 12:50:33.518749   924 layer_factory.hpp:78] Creating layer conv4_1
I1109 12:50:33.518761   924 net.cpp:67] Creating Layer conv4_1
I1109 12:50:33.518767   924 net.cpp:394] conv4_1 <- pool3
I1109 12:50:33.518776   924 net.cpp:356] conv4_1 -> conv4_1
I1109 12:50:33.518785   924 net.cpp:96] Setting up conv4_1
I1109 12:50:33.575541   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:33.575567   924 layer_factory.hpp:78] Creating layer relu4_1
I1109 12:50:33.575577   924 net.cpp:67] Creating Layer relu4_1
I1109 12:50:33.575583   924 net.cpp:394] relu4_1 <- conv4_1
I1109 12:50:33.575595   924 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1109 12:50:33.575604   924 net.cpp:96] Setting up relu4_1
I1109 12:50:33.575615   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:33.575621   924 layer_factory.hpp:78] Creating layer conv4_2
I1109 12:50:33.575631   924 net.cpp:67] Creating Layer conv4_2
I1109 12:50:33.575636   924 net.cpp:394] conv4_2 <- conv4_1
I1109 12:50:33.575645   924 net.cpp:356] conv4_2 -> conv4_2
I1109 12:50:33.575655   924 net.cpp:96] Setting up conv4_2
I1109 12:50:33.688591   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:33.688643   924 layer_factory.hpp:78] Creating layer relu4_2
I1109 12:50:33.688657   924 net.cpp:67] Creating Layer relu4_2
I1109 12:50:33.688664   924 net.cpp:394] relu4_2 <- conv4_2
I1109 12:50:33.688675   924 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1109 12:50:33.688686   924 net.cpp:96] Setting up relu4_2
I1109 12:50:33.688698   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:33.688704   924 layer_factory.hpp:78] Creating layer conv4_3
I1109 12:50:33.688714   924 net.cpp:67] Creating Layer conv4_3
I1109 12:50:33.688719   924 net.cpp:394] conv4_3 <- conv4_2
I1109 12:50:33.688731   924 net.cpp:356] conv4_3 -> conv4_3
I1109 12:50:33.688742   924 net.cpp:96] Setting up conv4_3
I1109 12:50:33.802148   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:33.802192   924 layer_factory.hpp:78] Creating layer relu4_3
I1109 12:50:33.802204   924 net.cpp:67] Creating Layer relu4_3
I1109 12:50:33.802212   924 net.cpp:394] relu4_3 <- conv4_3
I1109 12:50:33.802222   924 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1109 12:50:33.802233   924 net.cpp:96] Setting up relu4_3
I1109 12:50:33.802244   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:33.802250   924 layer_factory.hpp:78] Creating layer pool4
I1109 12:50:33.802263   924 net.cpp:67] Creating Layer pool4
I1109 12:50:33.802268   924 net.cpp:394] pool4 <- conv4_3
I1109 12:50:33.802278   924 net.cpp:356] pool4 -> pool4
I1109 12:50:33.802287   924 net.cpp:96] Setting up pool4
I1109 12:50:33.802300   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:33.802306   924 layer_factory.hpp:78] Creating layer conv5_1
I1109 12:50:33.802320   924 net.cpp:67] Creating Layer conv5_1
I1109 12:50:33.802325   924 net.cpp:394] conv5_1 <- pool4
I1109 12:50:33.802333   924 net.cpp:356] conv5_1 -> conv5_1
I1109 12:50:33.802347   924 net.cpp:96] Setting up conv5_1
I1109 12:50:33.915503   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:33.915547   924 layer_factory.hpp:78] Creating layer relu5_1
I1109 12:50:33.915560   924 net.cpp:67] Creating Layer relu5_1
I1109 12:50:33.915568   924 net.cpp:394] relu5_1 <- conv5_1
I1109 12:50:33.915581   924 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1109 12:50:33.915593   924 net.cpp:96] Setting up relu5_1
I1109 12:50:33.915604   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:33.915611   924 layer_factory.hpp:78] Creating layer conv5_2
I1109 12:50:33.915621   924 net.cpp:67] Creating Layer conv5_2
I1109 12:50:33.915627   924 net.cpp:394] conv5_2 <- conv5_1
I1109 12:50:33.915634   924 net.cpp:356] conv5_2 -> conv5_2
I1109 12:50:33.915644   924 net.cpp:96] Setting up conv5_2
I1109 12:50:34.029042   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:34.029088   924 layer_factory.hpp:78] Creating layer relu5_2
I1109 12:50:34.029101   924 net.cpp:67] Creating Layer relu5_2
I1109 12:50:34.029109   924 net.cpp:394] relu5_2 <- conv5_2
I1109 12:50:34.029119   924 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1109 12:50:34.029139   924 net.cpp:96] Setting up relu5_2
I1109 12:50:34.029150   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:34.029157   924 layer_factory.hpp:78] Creating layer conv5_3
I1109 12:50:34.029170   924 net.cpp:67] Creating Layer conv5_3
I1109 12:50:34.029177   924 net.cpp:394] conv5_3 <- conv5_2
I1109 12:50:34.029186   924 net.cpp:356] conv5_3 -> conv5_3
I1109 12:50:34.029197   924 net.cpp:96] Setting up conv5_3
I1109 12:50:34.142366   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:34.142407   924 layer_factory.hpp:78] Creating layer relu5_3
I1109 12:50:34.142421   924 net.cpp:67] Creating Layer relu5_3
I1109 12:50:34.142427   924 net.cpp:394] relu5_3 <- conv5_3
I1109 12:50:34.142441   924 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1109 12:50:34.142453   924 net.cpp:96] Setting up relu5_3
I1109 12:50:34.142464   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:34.142470   924 layer_factory.hpp:78] Creating layer pool5
I1109 12:50:34.142495   924 net.cpp:67] Creating Layer pool5
I1109 12:50:34.142501   924 net.cpp:394] pool5 <- conv5_3
I1109 12:50:34.142510   924 net.cpp:356] pool5 -> pool5
I1109 12:50:34.142520   924 net.cpp:96] Setting up pool5
I1109 12:50:34.142534   924 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1109 12:50:34.142539   924 layer_factory.hpp:78] Creating layer fc6
I1109 12:50:34.142563   924 net.cpp:67] Creating Layer fc6
I1109 12:50:34.142570   924 net.cpp:394] fc6 <- pool5
I1109 12:50:34.142580   924 net.cpp:356] fc6 -> fc6
I1109 12:50:34.142591   924 net.cpp:96] Setting up fc6
I1109 12:50:39.034710   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:39.034755   924 layer_factory.hpp:78] Creating layer relu6
I1109 12:50:39.034768   924 net.cpp:67] Creating Layer relu6
I1109 12:50:39.034776   924 net.cpp:394] relu6 <- fc6
I1109 12:50:39.034790   924 net.cpp:345] relu6 -> fc6 (in-place)
I1109 12:50:39.034801   924 net.cpp:96] Setting up relu6
I1109 12:50:39.034822   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:39.034829   924 layer_factory.hpp:78] Creating layer drop6
I1109 12:50:39.034843   924 net.cpp:67] Creating Layer drop6
I1109 12:50:39.034849   924 net.cpp:394] drop6 <- fc6
I1109 12:50:39.034857   924 net.cpp:345] drop6 -> fc6 (in-place)
I1109 12:50:39.034865   924 net.cpp:96] Setting up drop6
I1109 12:50:39.034879   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:39.034886   924 layer_factory.hpp:78] Creating layer fc7
I1109 12:50:39.034895   924 net.cpp:67] Creating Layer fc7
I1109 12:50:39.034900   924 net.cpp:394] fc7 <- fc6
I1109 12:50:39.034909   924 net.cpp:356] fc7 -> fc7
I1109 12:50:39.034920   924 net.cpp:96] Setting up fc7
I1109 12:50:39.834848   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:39.834895   924 layer_factory.hpp:78] Creating layer relu7
I1109 12:50:39.834915   924 net.cpp:67] Creating Layer relu7
I1109 12:50:39.834923   924 net.cpp:394] relu7 <- fc7
I1109 12:50:39.834934   924 net.cpp:345] relu7 -> fc7 (in-place)
I1109 12:50:39.834945   924 net.cpp:96] Setting up relu7
I1109 12:50:39.834966   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:39.834974   924 layer_factory.hpp:78] Creating layer drop7
I1109 12:50:39.834981   924 net.cpp:67] Creating Layer drop7
I1109 12:50:39.834987   924 net.cpp:394] drop7 <- fc7
I1109 12:50:39.834997   924 net.cpp:345] drop7 -> fc7 (in-place)
I1109 12:50:39.835013   924 net.cpp:96] Setting up drop7
I1109 12:50:39.835021   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:39.835026   924 layer_factory.hpp:78] Creating layer fc8_2
I1109 12:50:39.835036   924 net.cpp:67] Creating Layer fc8_2
I1109 12:50:39.835041   924 net.cpp:394] fc8_2 <- fc7
I1109 12:50:39.835049   924 net.cpp:356] fc8_2 -> fc8_2
I1109 12:50:39.835059   924 net.cpp:96] Setting up fc8_2
I1109 12:50:39.835479   924 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:50:39.835495   924 layer_factory.hpp:78] Creating layer loss
I1109 12:50:39.835512   924 net.cpp:67] Creating Layer loss
I1109 12:50:39.835520   924 net.cpp:394] loss <- fc8_2
I1109 12:50:39.835526   924 net.cpp:394] loss <- label
I1109 12:50:39.835538   924 net.cpp:356] loss -> (automatic)
I1109 12:50:39.835546   924 net.cpp:96] Setting up loss
I1109 12:50:39.835559   924 net.cpp:103] Top shape: 1 1 1 1 (1)
I1109 12:50:39.835566   924 net.cpp:109]     with loss weight 1
I1109 12:50:39.835608   924 net.cpp:170] loss needs backward computation.
I1109 12:50:39.835614   924 net.cpp:170] fc8_2 needs backward computation.
I1109 12:50:39.835619   924 net.cpp:170] drop7 needs backward computation.
I1109 12:50:39.835624   924 net.cpp:170] relu7 needs backward computation.
I1109 12:50:39.835629   924 net.cpp:170] fc7 needs backward computation.
I1109 12:50:39.835634   924 net.cpp:170] drop6 needs backward computation.
I1109 12:50:39.835640   924 net.cpp:170] relu6 needs backward computation.
I1109 12:50:39.835645   924 net.cpp:170] fc6 needs backward computation.
I1109 12:50:39.835651   924 net.cpp:170] pool5 needs backward computation.
I1109 12:50:39.835657   924 net.cpp:170] relu5_3 needs backward computation.
I1109 12:50:39.835676   924 net.cpp:170] conv5_3 needs backward computation.
I1109 12:50:39.835682   924 net.cpp:170] relu5_2 needs backward computation.
I1109 12:50:39.835687   924 net.cpp:170] conv5_2 needs backward computation.
I1109 12:50:39.835693   924 net.cpp:170] relu5_1 needs backward computation.
I1109 12:50:39.835698   924 net.cpp:170] conv5_1 needs backward computation.
I1109 12:50:39.835705   924 net.cpp:170] pool4 needs backward computation.
I1109 12:50:39.835711   924 net.cpp:170] relu4_3 needs backward computation.
I1109 12:50:39.835716   924 net.cpp:170] conv4_3 needs backward computation.
I1109 12:50:39.835722   924 net.cpp:170] relu4_2 needs backward computation.
I1109 12:50:39.835727   924 net.cpp:170] conv4_2 needs backward computation.
I1109 12:50:39.835733   924 net.cpp:170] relu4_1 needs backward computation.
I1109 12:50:39.835738   924 net.cpp:170] conv4_1 needs backward computation.
I1109 12:50:39.835744   924 net.cpp:170] pool3 needs backward computation.
I1109 12:50:39.835750   924 net.cpp:170] relu3_3 needs backward computation.
I1109 12:50:39.835755   924 net.cpp:170] conv3_3 needs backward computation.
I1109 12:50:39.835762   924 net.cpp:170] relu3_2 needs backward computation.
I1109 12:50:39.835767   924 net.cpp:170] conv3_2 needs backward computation.
I1109 12:50:39.835772   924 net.cpp:170] relu3_1 needs backward computation.
I1109 12:50:39.835777   924 net.cpp:170] conv3_1 needs backward computation.
I1109 12:50:39.835783   924 net.cpp:170] pool2 needs backward computation.
I1109 12:50:39.835789   924 net.cpp:170] relu2_2 needs backward computation.
I1109 12:50:39.835794   924 net.cpp:170] conv2_2 needs backward computation.
I1109 12:50:39.835800   924 net.cpp:170] relu2_1 needs backward computation.
I1109 12:50:39.835805   924 net.cpp:170] conv2_1 needs backward computation.
I1109 12:50:39.835811   924 net.cpp:170] pool1 needs backward computation.
I1109 12:50:39.835818   924 net.cpp:170] relu1_2 needs backward computation.
I1109 12:50:39.835822   924 net.cpp:170] conv1_2 needs backward computation.
I1109 12:50:39.835868   924 net.cpp:170] relu1_1 needs backward computation.
I1109 12:50:39.835881   924 net.cpp:170] conv1_1 needs backward computation.
I1109 12:50:39.835887   924 net.cpp:172] data does not need backward computation.
I1109 12:50:39.835934   924 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1109 12:50:39.835963   924 net.cpp:219] Network initialization done.
I1109 12:50:39.835968   924 net.cpp:220] Memory required for data: 921616484
I1109 12:50:39.837540   924 solver.cpp:151] Creating test net (#0) specified by net file: task/inadcl_o/train_val.prototxt
I1109 12:50:39.837630   924 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1109 12:50:39.838022   924 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/inadcl_o/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1109 12:50:39.838286   924 layer_factory.hpp:78] Creating layer data
I1109 12:50:39.838305   924 net.cpp:67] Creating Layer data
I1109 12:50:39.838313   924 net.cpp:356] data -> data
I1109 12:50:39.838326   924 net.cpp:356] data -> label
I1109 12:50:39.838337   924 net.cpp:96] Setting up data
I1109 12:50:39.838343   924 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/inadcl_o/val.txt
I1109 12:50:39.838595   924 image_data_layer.cpp:49] A total of 315 images.
I1109 12:50:39.853101   924 image_data_layer.cpp:78] output data size: 8,3,224,224
I1109 12:50:39.855018   924 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1109 12:50:39.855042   924 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:50:39.855051   924 layer_factory.hpp:78] Creating layer label_data_1_split
I1109 12:50:39.855068   924 net.cpp:67] Creating Layer label_data_1_split
I1109 12:50:39.855077   924 net.cpp:394] label_data_1_split <- label
I1109 12:50:39.855090   924 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1109 12:50:39.855106   924 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1109 12:50:39.855115   924 net.cpp:96] Setting up label_data_1_split
I1109 12:50:39.855126   924 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:50:39.855132   924 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:50:39.855137   924 layer_factory.hpp:78] Creating layer conv1_1
I1109 12:50:39.855149   924 net.cpp:67] Creating Layer conv1_1
I1109 12:50:39.855154   924 net.cpp:394] conv1_1 <- data
I1109 12:50:39.855164   924 net.cpp:356] conv1_1 -> conv1_1
I1109 12:50:39.855175   924 net.cpp:96] Setting up conv1_1
I1109 12:50:39.855473   924 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:39.855501   924 layer_factory.hpp:78] Creating layer relu1_1
I1109 12:50:39.855512   924 net.cpp:67] Creating Layer relu1_1
I1109 12:50:39.855518   924 net.cpp:394] relu1_1 <- conv1_1
I1109 12:50:39.855526   924 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1109 12:50:39.855535   924 net.cpp:96] Setting up relu1_1
I1109 12:50:39.855546   924 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:39.855567   924 layer_factory.hpp:78] Creating layer conv1_2
I1109 12:50:39.855577   924 net.cpp:67] Creating Layer conv1_2
I1109 12:50:39.855583   924 net.cpp:394] conv1_2 <- conv1_1
I1109 12:50:39.855592   924 net.cpp:356] conv1_2 -> conv1_2
I1109 12:50:39.855602   924 net.cpp:96] Setting up conv1_2
I1109 12:50:39.857563   924 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:39.857590   924 layer_factory.hpp:78] Creating layer relu1_2
I1109 12:50:39.857599   924 net.cpp:67] Creating Layer relu1_2
I1109 12:50:39.857605   924 net.cpp:394] relu1_2 <- conv1_2
I1109 12:50:39.857614   924 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1109 12:50:39.857624   924 net.cpp:96] Setting up relu1_2
I1109 12:50:39.857633   924 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:50:39.857640   924 layer_factory.hpp:78] Creating layer pool1
I1109 12:50:39.857650   924 net.cpp:67] Creating Layer pool1
I1109 12:50:39.857655   924 net.cpp:394] pool1 <- conv1_2
I1109 12:50:39.857663   924 net.cpp:356] pool1 -> pool1
I1109 12:50:39.857671   924 net.cpp:96] Setting up pool1
I1109 12:50:39.857683   924 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1109 12:50:39.857691   924 layer_factory.hpp:78] Creating layer conv2_1
I1109 12:50:39.857699   924 net.cpp:67] Creating Layer conv2_1
I1109 12:50:39.857704   924 net.cpp:394] conv2_1 <- pool1
I1109 12:50:39.857713   924 net.cpp:356] conv2_1 -> conv2_1
I1109 12:50:39.857722   924 net.cpp:96] Setting up conv2_1
I1109 12:50:39.861583   924 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:39.861610   924 layer_factory.hpp:78] Creating layer relu2_1
I1109 12:50:39.861621   924 net.cpp:67] Creating Layer relu2_1
I1109 12:50:39.861627   924 net.cpp:394] relu2_1 <- conv2_1
I1109 12:50:39.861635   924 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1109 12:50:39.861645   924 net.cpp:96] Setting up relu2_1
I1109 12:50:39.861655   924 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:39.861661   924 layer_factory.hpp:78] Creating layer conv2_2
I1109 12:50:39.861670   924 net.cpp:67] Creating Layer conv2_2
I1109 12:50:39.861675   924 net.cpp:394] conv2_2 <- conv2_1
I1109 12:50:39.861685   924 net.cpp:356] conv2_2 -> conv2_2
I1109 12:50:39.861696   924 net.cpp:96] Setting up conv2_2
I1109 12:50:39.868830   924 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:39.868854   924 layer_factory.hpp:78] Creating layer relu2_2
I1109 12:50:39.868865   924 net.cpp:67] Creating Layer relu2_2
I1109 12:50:39.868870   924 net.cpp:394] relu2_2 <- conv2_2
I1109 12:50:39.868878   924 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1109 12:50:39.868888   924 net.cpp:96] Setting up relu2_2
I1109 12:50:39.868898   924 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:50:39.868904   924 layer_factory.hpp:78] Creating layer pool2
I1109 12:50:39.868913   924 net.cpp:67] Creating Layer pool2
I1109 12:50:39.868918   924 net.cpp:394] pool2 <- conv2_2
I1109 12:50:39.868927   924 net.cpp:356] pool2 -> pool2
I1109 12:50:39.868935   924 net.cpp:96] Setting up pool2
I1109 12:50:39.868947   924 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1109 12:50:39.868953   924 layer_factory.hpp:78] Creating layer conv3_1
I1109 12:50:39.868963   924 net.cpp:67] Creating Layer conv3_1
I1109 12:50:39.868968   924 net.cpp:394] conv3_1 <- pool2
I1109 12:50:39.868976   924 net.cpp:356] conv3_1 -> conv3_1
I1109 12:50:39.868985   924 net.cpp:96] Setting up conv3_1
I1109 12:50:39.883163   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:39.883198   924 layer_factory.hpp:78] Creating layer relu3_1
I1109 12:50:39.883209   924 net.cpp:67] Creating Layer relu3_1
I1109 12:50:39.883216   924 net.cpp:394] relu3_1 <- conv3_1
I1109 12:50:39.883225   924 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1109 12:50:39.883235   924 net.cpp:96] Setting up relu3_1
I1109 12:50:39.883245   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:39.883251   924 layer_factory.hpp:78] Creating layer conv3_2
I1109 12:50:39.883261   924 net.cpp:67] Creating Layer conv3_2
I1109 12:50:39.883267   924 net.cpp:394] conv3_2 <- conv3_1
I1109 12:50:39.883294   924 net.cpp:356] conv3_2 -> conv3_2
I1109 12:50:39.883306   924 net.cpp:96] Setting up conv3_2
I1109 12:50:39.911909   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:39.911947   924 layer_factory.hpp:78] Creating layer relu3_2
I1109 12:50:39.911960   924 net.cpp:67] Creating Layer relu3_2
I1109 12:50:39.911967   924 net.cpp:394] relu3_2 <- conv3_2
I1109 12:50:39.911978   924 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1109 12:50:39.911989   924 net.cpp:96] Setting up relu3_2
I1109 12:50:39.911999   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:39.912006   924 layer_factory.hpp:78] Creating layer conv3_3
I1109 12:50:39.912021   924 net.cpp:67] Creating Layer conv3_3
I1109 12:50:39.912029   924 net.cpp:394] conv3_3 <- conv3_2
I1109 12:50:39.912037   924 net.cpp:356] conv3_3 -> conv3_3
I1109 12:50:39.912049   924 net.cpp:96] Setting up conv3_3
I1109 12:50:39.941028   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:39.941064   924 layer_factory.hpp:78] Creating layer relu3_3
I1109 12:50:39.941081   924 net.cpp:67] Creating Layer relu3_3
I1109 12:50:39.941088   924 net.cpp:394] relu3_3 <- conv3_3
I1109 12:50:39.941099   924 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1109 12:50:39.941109   924 net.cpp:96] Setting up relu3_3
I1109 12:50:39.941120   924 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:50:39.941126   924 layer_factory.hpp:78] Creating layer pool3
I1109 12:50:39.941162   924 net.cpp:67] Creating Layer pool3
I1109 12:50:39.941169   924 net.cpp:394] pool3 <- conv3_3
I1109 12:50:39.941179   924 net.cpp:356] pool3 -> pool3
I1109 12:50:39.941190   924 net.cpp:96] Setting up pool3
I1109 12:50:39.941203   924 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1109 12:50:39.941210   924 layer_factory.hpp:78] Creating layer conv4_1
I1109 12:50:39.941222   924 net.cpp:67] Creating Layer conv4_1
I1109 12:50:39.941234   924 net.cpp:394] conv4_1 <- pool3
I1109 12:50:39.941244   924 net.cpp:356] conv4_1 -> conv4_1
I1109 12:50:39.941254   924 net.cpp:96] Setting up conv4_1
I1109 12:50:39.998582   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:39.998622   924 layer_factory.hpp:78] Creating layer relu4_1
I1109 12:50:39.998638   924 net.cpp:67] Creating Layer relu4_1
I1109 12:50:39.998646   924 net.cpp:394] relu4_1 <- conv4_1
I1109 12:50:39.998657   924 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1109 12:50:39.998668   924 net.cpp:96] Setting up relu4_1
I1109 12:50:39.998679   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:39.998685   924 layer_factory.hpp:78] Creating layer conv4_2
I1109 12:50:39.998698   924 net.cpp:67] Creating Layer conv4_2
I1109 12:50:39.998704   924 net.cpp:394] conv4_2 <- conv4_1
I1109 12:50:39.998713   924 net.cpp:356] conv4_2 -> conv4_2
I1109 12:50:39.998724   924 net.cpp:96] Setting up conv4_2
I1109 12:50:40.111548   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:40.111599   924 layer_factory.hpp:78] Creating layer relu4_2
I1109 12:50:40.111613   924 net.cpp:67] Creating Layer relu4_2
I1109 12:50:40.111621   924 net.cpp:394] relu4_2 <- conv4_2
I1109 12:50:40.111631   924 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1109 12:50:40.111642   924 net.cpp:96] Setting up relu4_2
I1109 12:50:40.111654   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:40.111660   924 layer_factory.hpp:78] Creating layer conv4_3
I1109 12:50:40.111670   924 net.cpp:67] Creating Layer conv4_3
I1109 12:50:40.111675   924 net.cpp:394] conv4_3 <- conv4_2
I1109 12:50:40.111690   924 net.cpp:356] conv4_3 -> conv4_3
I1109 12:50:40.111703   924 net.cpp:96] Setting up conv4_3
I1109 12:50:40.224959   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:40.225006   924 layer_factory.hpp:78] Creating layer relu4_3
I1109 12:50:40.225019   924 net.cpp:67] Creating Layer relu4_3
I1109 12:50:40.225028   924 net.cpp:394] relu4_3 <- conv4_3
I1109 12:50:40.225038   924 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1109 12:50:40.225049   924 net.cpp:96] Setting up relu4_3
I1109 12:50:40.225061   924 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:50:40.225083   924 layer_factory.hpp:78] Creating layer pool4
I1109 12:50:40.225092   924 net.cpp:67] Creating Layer pool4
I1109 12:50:40.225098   924 net.cpp:394] pool4 <- conv4_3
I1109 12:50:40.225111   924 net.cpp:356] pool4 -> pool4
I1109 12:50:40.225121   924 net.cpp:96] Setting up pool4
I1109 12:50:40.225175   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:40.225185   924 layer_factory.hpp:78] Creating layer conv5_1
I1109 12:50:40.225199   924 net.cpp:67] Creating Layer conv5_1
I1109 12:50:40.225213   924 net.cpp:394] conv5_1 <- pool4
I1109 12:50:40.225222   924 net.cpp:356] conv5_1 -> conv5_1
I1109 12:50:40.225234   924 net.cpp:96] Setting up conv5_1
I1109 12:50:40.338043   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:40.338086   924 layer_factory.hpp:78] Creating layer relu5_1
I1109 12:50:40.338099   924 net.cpp:67] Creating Layer relu5_1
I1109 12:50:40.338107   924 net.cpp:394] relu5_1 <- conv5_1
I1109 12:50:40.338117   924 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1109 12:50:40.338129   924 net.cpp:96] Setting up relu5_1
I1109 12:50:40.338140   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:40.338146   924 layer_factory.hpp:78] Creating layer conv5_2
I1109 12:50:40.338158   924 net.cpp:67] Creating Layer conv5_2
I1109 12:50:40.338165   924 net.cpp:394] conv5_2 <- conv5_1
I1109 12:50:40.338174   924 net.cpp:356] conv5_2 -> conv5_2
I1109 12:50:40.338184   924 net.cpp:96] Setting up conv5_2
I1109 12:50:40.451462   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:40.451504   924 layer_factory.hpp:78] Creating layer relu5_2
I1109 12:50:40.451517   924 net.cpp:67] Creating Layer relu5_2
I1109 12:50:40.451525   924 net.cpp:394] relu5_2 <- conv5_2
I1109 12:50:40.451539   924 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1109 12:50:40.451550   924 net.cpp:96] Setting up relu5_2
I1109 12:50:40.451561   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:40.451567   924 layer_factory.hpp:78] Creating layer conv5_3
I1109 12:50:40.451581   924 net.cpp:67] Creating Layer conv5_3
I1109 12:50:40.451586   924 net.cpp:394] conv5_3 <- conv5_2
I1109 12:50:40.451596   924 net.cpp:356] conv5_3 -> conv5_3
I1109 12:50:40.451606   924 net.cpp:96] Setting up conv5_3
I1109 12:50:40.564601   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:40.564645   924 layer_factory.hpp:78] Creating layer relu5_3
I1109 12:50:40.564657   924 net.cpp:67] Creating Layer relu5_3
I1109 12:50:40.564666   924 net.cpp:394] relu5_3 <- conv5_3
I1109 12:50:40.564678   924 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1109 12:50:40.564692   924 net.cpp:96] Setting up relu5_3
I1109 12:50:40.564702   924 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:50:40.564708   924 layer_factory.hpp:78] Creating layer pool5
I1109 12:50:40.564725   924 net.cpp:67] Creating Layer pool5
I1109 12:50:40.564731   924 net.cpp:394] pool5 <- conv5_3
I1109 12:50:40.564740   924 net.cpp:356] pool5 -> pool5
I1109 12:50:40.564750   924 net.cpp:96] Setting up pool5
I1109 12:50:40.564764   924 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1109 12:50:40.564769   924 layer_factory.hpp:78] Creating layer fc6
I1109 12:50:40.564779   924 net.cpp:67] Creating Layer fc6
I1109 12:50:40.564785   924 net.cpp:394] fc6 <- pool5
I1109 12:50:40.564795   924 net.cpp:356] fc6 -> fc6
I1109 12:50:40.564805   924 net.cpp:96] Setting up fc6
I1109 12:50:45.454913   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:45.454958   924 layer_factory.hpp:78] Creating layer relu6
I1109 12:50:45.454975   924 net.cpp:67] Creating Layer relu6
I1109 12:50:45.454983   924 net.cpp:394] relu6 <- fc6
I1109 12:50:45.454994   924 net.cpp:345] relu6 -> fc6 (in-place)
I1109 12:50:45.455006   924 net.cpp:96] Setting up relu6
I1109 12:50:45.455029   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:45.455035   924 layer_factory.hpp:78] Creating layer drop6
I1109 12:50:45.455044   924 net.cpp:67] Creating Layer drop6
I1109 12:50:45.455049   924 net.cpp:394] drop6 <- fc6
I1109 12:50:45.455060   924 net.cpp:345] drop6 -> fc6 (in-place)
I1109 12:50:45.455085   924 net.cpp:96] Setting up drop6
I1109 12:50:45.455092   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:45.455098   924 layer_factory.hpp:78] Creating layer fc7
I1109 12:50:45.455108   924 net.cpp:67] Creating Layer fc7
I1109 12:50:45.455114   924 net.cpp:394] fc7 <- fc6
I1109 12:50:45.455123   924 net.cpp:356] fc7 -> fc7
I1109 12:50:45.455133   924 net.cpp:96] Setting up fc7
I1109 12:50:46.254812   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:46.254856   924 layer_factory.hpp:78] Creating layer relu7
I1109 12:50:46.254869   924 net.cpp:67] Creating Layer relu7
I1109 12:50:46.254878   924 net.cpp:394] relu7 <- fc7
I1109 12:50:46.254887   924 net.cpp:345] relu7 -> fc7 (in-place)
I1109 12:50:46.254899   924 net.cpp:96] Setting up relu7
I1109 12:50:46.254919   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:46.254925   924 layer_factory.hpp:78] Creating layer drop7
I1109 12:50:46.254936   924 net.cpp:67] Creating Layer drop7
I1109 12:50:46.254943   924 net.cpp:394] drop7 <- fc7
I1109 12:50:46.254951   924 net.cpp:345] drop7 -> fc7 (in-place)
I1109 12:50:46.254961   924 net.cpp:96] Setting up drop7
I1109 12:50:46.254967   924 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:50:46.254972   924 layer_factory.hpp:78] Creating layer fc8_2
I1109 12:50:46.254981   924 net.cpp:67] Creating Layer fc8_2
I1109 12:50:46.254987   924 net.cpp:394] fc8_2 <- fc7
I1109 12:50:46.254998   924 net.cpp:356] fc8_2 -> fc8_2
I1109 12:50:46.255009   924 net.cpp:96] Setting up fc8_2
I1109 12:50:46.255429   924 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:50:46.255445   924 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1109 12:50:46.255453   924 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1109 12:50:46.255460   924 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1109 12:50:46.255470   924 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1109 12:50:46.255481   924 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1109 12:50:46.255491   924 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1109 12:50:46.255498   924 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:50:46.255503   924 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:50:46.255508   924 layer_factory.hpp:78] Creating layer loss
I1109 12:50:46.255519   924 net.cpp:67] Creating Layer loss
I1109 12:50:46.255525   924 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1109 12:50:46.255533   924 net.cpp:394] loss <- label_data_1_split_0
I1109 12:50:46.255542   924 net.cpp:356] loss -> (automatic)
I1109 12:50:46.255584   924 net.cpp:96] Setting up loss
I1109 12:50:46.255596   924 net.cpp:103] Top shape: 1 1 1 1 (1)
I1109 12:50:46.255602   924 net.cpp:109]     with loss weight 1
I1109 12:50:46.255626   924 layer_factory.hpp:78] Creating layer accuracy
I1109 12:50:46.255646   924 net.cpp:67] Creating Layer accuracy
I1109 12:50:46.255656   924 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1109 12:50:46.255663   924 net.cpp:394] accuracy <- label_data_1_split_1
I1109 12:50:46.255672   924 net.cpp:356] accuracy -> accuracy
I1109 12:50:46.255682   924 net.cpp:96] Setting up accuracy
I1109 12:50:46.255693   924 net.cpp:103] Top shape: 1 1 1 4 (4)
I1109 12:50:46.255700   924 net.cpp:172] accuracy does not need backward computation.
I1109 12:50:46.255705   924 net.cpp:170] loss needs backward computation.
I1109 12:50:46.255710   924 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1109 12:50:46.255717   924 net.cpp:170] fc8_2 needs backward computation.
I1109 12:50:46.255722   924 net.cpp:170] drop7 needs backward computation.
I1109 12:50:46.255727   924 net.cpp:170] relu7 needs backward computation.
I1109 12:50:46.255731   924 net.cpp:170] fc7 needs backward computation.
I1109 12:50:46.255736   924 net.cpp:170] drop6 needs backward computation.
I1109 12:50:46.255743   924 net.cpp:170] relu6 needs backward computation.
I1109 12:50:46.255748   924 net.cpp:170] fc6 needs backward computation.
I1109 12:50:46.255753   924 net.cpp:170] pool5 needs backward computation.
I1109 12:50:46.255770   924 net.cpp:170] relu5_3 needs backward computation.
I1109 12:50:46.255776   924 net.cpp:170] conv5_3 needs backward computation.
I1109 12:50:46.255782   924 net.cpp:170] relu5_2 needs backward computation.
I1109 12:50:46.255787   924 net.cpp:170] conv5_2 needs backward computation.
I1109 12:50:46.255794   924 net.cpp:170] relu5_1 needs backward computation.
I1109 12:50:46.255799   924 net.cpp:170] conv5_1 needs backward computation.
I1109 12:50:46.255805   924 net.cpp:170] pool4 needs backward computation.
I1109 12:50:46.255810   924 net.cpp:170] relu4_3 needs backward computation.
I1109 12:50:46.255815   924 net.cpp:170] conv4_3 needs backward computation.
I1109 12:50:46.255820   924 net.cpp:170] relu4_2 needs backward computation.
I1109 12:50:46.255826   924 net.cpp:170] conv4_2 needs backward computation.
I1109 12:50:46.255831   924 net.cpp:170] relu4_1 needs backward computation.
I1109 12:50:46.255836   924 net.cpp:170] conv4_1 needs backward computation.
I1109 12:50:46.255842   924 net.cpp:170] pool3 needs backward computation.
I1109 12:50:46.255856   924 net.cpp:170] relu3_3 needs backward computation.
I1109 12:50:46.255862   924 net.cpp:170] conv3_3 needs backward computation.
I1109 12:50:46.255867   924 net.cpp:170] relu3_2 needs backward computation.
I1109 12:50:46.255873   924 net.cpp:170] conv3_2 needs backward computation.
I1109 12:50:46.255878   924 net.cpp:170] relu3_1 needs backward computation.
I1109 12:50:46.255883   924 net.cpp:170] conv3_1 needs backward computation.
I1109 12:50:46.255889   924 net.cpp:170] pool2 needs backward computation.
I1109 12:50:46.255895   924 net.cpp:170] relu2_2 needs backward computation.
I1109 12:50:46.255900   924 net.cpp:170] conv2_2 needs backward computation.
I1109 12:50:46.255906   924 net.cpp:170] relu2_1 needs backward computation.
I1109 12:50:46.255913   924 net.cpp:170] conv2_1 needs backward computation.
I1109 12:50:46.255918   924 net.cpp:170] pool1 needs backward computation.
I1109 12:50:46.255923   924 net.cpp:170] relu1_2 needs backward computation.
I1109 12:50:46.255928   924 net.cpp:170] conv1_2 needs backward computation.
I1109 12:50:46.255934   924 net.cpp:170] relu1_1 needs backward computation.
I1109 12:50:46.255939   924 net.cpp:170] conv1_1 needs backward computation.
I1109 12:50:46.255945   924 net.cpp:172] label_data_1_split does not need backward computation.
I1109 12:50:46.255950   924 net.cpp:172] data does not need backward computation.
I1109 12:50:46.255955   924 net.cpp:208] This network produces output accuracy
I1109 12:50:46.255990   924 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1109 12:50:46.256006   924 net.cpp:219] Network initialization done.
I1109 12:50:46.256011   924 net.cpp:220] Memory required for data: 921616692
I1109 12:50:46.256289   924 solver.cpp:41] Solver scaffolding done.
I1109 12:50:46.256305   924 caffe.cpp:115] Finetuning from task/inadcl_o/none/_iter_3000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077499
I1109 12:50:48.616840   924 solver.cpp:160] Solving small
I1109 12:50:48.616878   924 solver.cpp:161] Learning Rate Policy: step
I1109 12:50:49.944232   924 solver.cpp:339] Snapshotting to _iter_0.caffemodel
I1109 12:50:52.279233   924 solver.cpp:347] Snapshotting solver state to _iter_0.solverstate
I1109 12:50:55.414108   924 solver.cpp:246] Iteration 0, loss = 0.46239
I1109 12:50:55.414161   924 solver.cpp:264] Iteration 0, Testing net (#0)
I1109 12:51:00.604614   924 solver.cpp:305] Test loss: 0.51846
I1109 12:51:00.604671   924 solver.cpp:320]     Test net output #0: accuracy = 0.808703
I1109 12:51:00.604682   924 solver.cpp:320]     Test net output #1: accuracy = 0.695402
I1109 12:51:00.604691   924 solver.cpp:320]     Test net output #2: accuracy = 0.752053
I1109 12:51:00.604701   924 solver.cpp:320]     Test net output #3: accuracy = 0.775862
I1109 12:51:00.604710   924 solver.cpp:251] Optimization Done.
I1109 12:51:00.604717   924 caffe.cpp:121] Optimization Done.
I1109 12:51:00.876086   991 caffe.cpp:99] Use GPU with device ID 0
I1109 12:51:01.175568   991 caffe.cpp:107] Starting Optimization
I1109 12:51:01.175714   991 solver.cpp:32] Initializing solver from parameters: 
test_iter: 29
test_interval: 1
base_lr: 0
display: 10
max_iter: 0
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 200
solver_mode: GPU
test_compute_loss: true
net: "task/inadcl_o/train_val.prototxt"
I1109 12:51:01.175753   991 solver.cpp:67] Creating training net from net file: task/inadcl_o/train_val.prototxt
I1109 12:51:01.177291   991 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 12:51:01.177345   991 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 12:51:01.177708   991 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/inadcl_o/train.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1109 12:51:01.177917   991 layer_factory.hpp:78] Creating layer data
I1109 12:51:01.177947   991 net.cpp:67] Creating Layer data
I1109 12:51:01.177976   991 net.cpp:356] data -> data
I1109 12:51:01.178004   991 net.cpp:356] data -> label
I1109 12:51:01.178026   991 net.cpp:96] Setting up data
I1109 12:51:01.178037   991 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/inadcl_o/train.txt
I1109 12:51:01.191761   991 image_data_layer.cpp:49] A total of 20637 images.
I1109 12:51:01.202611   991 image_data_layer.cpp:78] output data size: 8,3,224,224
I1109 12:51:01.204968   991 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1109 12:51:01.204989   991 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:51:01.204998   991 layer_factory.hpp:78] Creating layer conv1_1
I1109 12:51:01.205018   991 net.cpp:67] Creating Layer conv1_1
I1109 12:51:01.205024   991 net.cpp:394] conv1_1 <- data
I1109 12:51:01.205067   991 net.cpp:356] conv1_1 -> conv1_1
I1109 12:51:01.205087   991 net.cpp:96] Setting up conv1_1
I1109 12:51:01.233341   991 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:01.233402   991 layer_factory.hpp:78] Creating layer relu1_1
I1109 12:51:01.233423   991 net.cpp:67] Creating Layer relu1_1
I1109 12:51:01.233433   991 net.cpp:394] relu1_1 <- conv1_1
I1109 12:51:01.233443   991 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1109 12:51:01.233459   991 net.cpp:96] Setting up relu1_1
I1109 12:51:01.233475   991 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:01.233484   991 layer_factory.hpp:78] Creating layer conv1_2
I1109 12:51:01.233496   991 net.cpp:67] Creating Layer conv1_2
I1109 12:51:01.233502   991 net.cpp:394] conv1_2 <- conv1_1
I1109 12:51:01.233512   991 net.cpp:356] conv1_2 -> conv1_2
I1109 12:51:01.233523   991 net.cpp:96] Setting up conv1_2
I1109 12:51:01.236013   991 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:01.236040   991 layer_factory.hpp:78] Creating layer relu1_2
I1109 12:51:01.236052   991 net.cpp:67] Creating Layer relu1_2
I1109 12:51:01.236059   991 net.cpp:394] relu1_2 <- conv1_2
I1109 12:51:01.236076   991 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1109 12:51:01.236088   991 net.cpp:96] Setting up relu1_2
I1109 12:51:01.236098   991 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:01.236104   991 layer_factory.hpp:78] Creating layer pool1
I1109 12:51:01.236116   991 net.cpp:67] Creating Layer pool1
I1109 12:51:01.236122   991 net.cpp:394] pool1 <- conv1_2
I1109 12:51:01.236134   991 net.cpp:356] pool1 -> pool1
I1109 12:51:01.236143   991 net.cpp:96] Setting up pool1
I1109 12:51:01.236170   991 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1109 12:51:01.236177   991 layer_factory.hpp:78] Creating layer conv2_1
I1109 12:51:01.236187   991 net.cpp:67] Creating Layer conv2_1
I1109 12:51:01.236192   991 net.cpp:394] conv2_1 <- pool1
I1109 12:51:01.236206   991 net.cpp:356] conv2_1 -> conv2_1
I1109 12:51:01.236223   991 net.cpp:96] Setting up conv2_1
I1109 12:51:01.239984   991 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:01.240010   991 layer_factory.hpp:78] Creating layer relu2_1
I1109 12:51:01.240020   991 net.cpp:67] Creating Layer relu2_1
I1109 12:51:01.240025   991 net.cpp:394] relu2_1 <- conv2_1
I1109 12:51:01.240033   991 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1109 12:51:01.240042   991 net.cpp:96] Setting up relu2_1
I1109 12:51:01.240052   991 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:01.240058   991 layer_factory.hpp:78] Creating layer conv2_2
I1109 12:51:01.240072   991 net.cpp:67] Creating Layer conv2_2
I1109 12:51:01.240078   991 net.cpp:394] conv2_2 <- conv2_1
I1109 12:51:01.240092   991 net.cpp:356] conv2_2 -> conv2_2
I1109 12:51:01.240102   991 net.cpp:96] Setting up conv2_2
I1109 12:51:01.247462   991 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:01.247485   991 layer_factory.hpp:78] Creating layer relu2_2
I1109 12:51:01.247494   991 net.cpp:67] Creating Layer relu2_2
I1109 12:51:01.247500   991 net.cpp:394] relu2_2 <- conv2_2
I1109 12:51:01.247512   991 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1109 12:51:01.247522   991 net.cpp:96] Setting up relu2_2
I1109 12:51:01.247532   991 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:01.247539   991 layer_factory.hpp:78] Creating layer pool2
I1109 12:51:01.247563   991 net.cpp:67] Creating Layer pool2
I1109 12:51:01.247570   991 net.cpp:394] pool2 <- conv2_2
I1109 12:51:01.247578   991 net.cpp:356] pool2 -> pool2
I1109 12:51:01.247591   991 net.cpp:96] Setting up pool2
I1109 12:51:01.247601   991 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1109 12:51:01.247607   991 layer_factory.hpp:78] Creating layer conv3_1
I1109 12:51:01.247617   991 net.cpp:67] Creating Layer conv3_1
I1109 12:51:01.247622   991 net.cpp:394] conv3_1 <- pool2
I1109 12:51:01.247630   991 net.cpp:356] conv3_1 -> conv3_1
I1109 12:51:01.247642   991 net.cpp:96] Setting up conv3_1
I1109 12:51:01.262197   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:01.262233   991 layer_factory.hpp:78] Creating layer relu3_1
I1109 12:51:01.262244   991 net.cpp:67] Creating Layer relu3_1
I1109 12:51:01.262251   991 net.cpp:394] relu3_1 <- conv3_1
I1109 12:51:01.262261   991 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1109 12:51:01.262270   991 net.cpp:96] Setting up relu3_1
I1109 12:51:01.262280   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:01.262286   991 layer_factory.hpp:78] Creating layer conv3_2
I1109 12:51:01.262300   991 net.cpp:67] Creating Layer conv3_2
I1109 12:51:01.262306   991 net.cpp:394] conv3_2 <- conv3_1
I1109 12:51:01.262315   991 net.cpp:356] conv3_2 -> conv3_2
I1109 12:51:01.262325   991 net.cpp:96] Setting up conv3_2
I1109 12:51:01.291262   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:01.291297   991 layer_factory.hpp:78] Creating layer relu3_2
I1109 12:51:01.291311   991 net.cpp:67] Creating Layer relu3_2
I1109 12:51:01.291317   991 net.cpp:394] relu3_2 <- conv3_2
I1109 12:51:01.291332   991 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1109 12:51:01.291343   991 net.cpp:96] Setting up relu3_2
I1109 12:51:01.291353   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:01.291360   991 layer_factory.hpp:78] Creating layer conv3_3
I1109 12:51:01.291369   991 net.cpp:67] Creating Layer conv3_3
I1109 12:51:01.291374   991 net.cpp:394] conv3_3 <- conv3_2
I1109 12:51:01.291383   991 net.cpp:356] conv3_3 -> conv3_3
I1109 12:51:01.291393   991 net.cpp:96] Setting up conv3_3
I1109 12:51:01.320231   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:01.320268   991 layer_factory.hpp:78] Creating layer relu3_3
I1109 12:51:01.320283   991 net.cpp:67] Creating Layer relu3_3
I1109 12:51:01.320294   991 net.cpp:394] relu3_3 <- conv3_3
I1109 12:51:01.320304   991 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1109 12:51:01.320315   991 net.cpp:96] Setting up relu3_3
I1109 12:51:01.320325   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:01.320332   991 layer_factory.hpp:78] Creating layer pool3
I1109 12:51:01.320340   991 net.cpp:67] Creating Layer pool3
I1109 12:51:01.320346   991 net.cpp:394] pool3 <- conv3_3
I1109 12:51:01.320354   991 net.cpp:356] pool3 -> pool3
I1109 12:51:01.320363   991 net.cpp:96] Setting up pool3
I1109 12:51:01.320375   991 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1109 12:51:01.320381   991 layer_factory.hpp:78] Creating layer conv4_1
I1109 12:51:01.320394   991 net.cpp:67] Creating Layer conv4_1
I1109 12:51:01.320399   991 net.cpp:394] conv4_1 <- pool3
I1109 12:51:01.320410   991 net.cpp:356] conv4_1 -> conv4_1
I1109 12:51:01.320420   991 net.cpp:96] Setting up conv4_1
I1109 12:51:01.376878   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:01.376904   991 layer_factory.hpp:78] Creating layer relu4_1
I1109 12:51:01.376919   991 net.cpp:67] Creating Layer relu4_1
I1109 12:51:01.376926   991 net.cpp:394] relu4_1 <- conv4_1
I1109 12:51:01.376935   991 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1109 12:51:01.376945   991 net.cpp:96] Setting up relu4_1
I1109 12:51:01.376955   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:01.376960   991 layer_factory.hpp:78] Creating layer conv4_2
I1109 12:51:01.376972   991 net.cpp:67] Creating Layer conv4_2
I1109 12:51:01.376978   991 net.cpp:394] conv4_2 <- conv4_1
I1109 12:51:01.376986   991 net.cpp:356] conv4_2 -> conv4_2
I1109 12:51:01.376996   991 net.cpp:96] Setting up conv4_2
I1109 12:51:01.490331   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:01.490383   991 layer_factory.hpp:78] Creating layer relu4_2
I1109 12:51:01.490396   991 net.cpp:67] Creating Layer relu4_2
I1109 12:51:01.490404   991 net.cpp:394] relu4_2 <- conv4_2
I1109 12:51:01.490417   991 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1109 12:51:01.490429   991 net.cpp:96] Setting up relu4_2
I1109 12:51:01.490439   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:01.490447   991 layer_factory.hpp:78] Creating layer conv4_3
I1109 12:51:01.490455   991 net.cpp:67] Creating Layer conv4_3
I1109 12:51:01.490461   991 net.cpp:394] conv4_3 <- conv4_2
I1109 12:51:01.490473   991 net.cpp:356] conv4_3 -> conv4_3
I1109 12:51:01.490483   991 net.cpp:96] Setting up conv4_3
I1109 12:51:01.603431   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:01.603476   991 layer_factory.hpp:78] Creating layer relu4_3
I1109 12:51:01.603489   991 net.cpp:67] Creating Layer relu4_3
I1109 12:51:01.603497   991 net.cpp:394] relu4_3 <- conv4_3
I1109 12:51:01.603507   991 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1109 12:51:01.603518   991 net.cpp:96] Setting up relu4_3
I1109 12:51:01.603528   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:01.603534   991 layer_factory.hpp:78] Creating layer pool4
I1109 12:51:01.603543   991 net.cpp:67] Creating Layer pool4
I1109 12:51:01.603549   991 net.cpp:394] pool4 <- conv4_3
I1109 12:51:01.603560   991 net.cpp:356] pool4 -> pool4
I1109 12:51:01.603570   991 net.cpp:96] Setting up pool4
I1109 12:51:01.603582   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:01.603590   991 layer_factory.hpp:78] Creating layer conv5_1
I1109 12:51:01.603602   991 net.cpp:67] Creating Layer conv5_1
I1109 12:51:01.603608   991 net.cpp:394] conv5_1 <- pool4
I1109 12:51:01.603616   991 net.cpp:356] conv5_1 -> conv5_1
I1109 12:51:01.603629   991 net.cpp:96] Setting up conv5_1
I1109 12:51:01.717196   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:01.717239   991 layer_factory.hpp:78] Creating layer relu5_1
I1109 12:51:01.717262   991 net.cpp:67] Creating Layer relu5_1
I1109 12:51:01.717269   991 net.cpp:394] relu5_1 <- conv5_1
I1109 12:51:01.717280   991 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1109 12:51:01.717293   991 net.cpp:96] Setting up relu5_1
I1109 12:51:01.717303   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:01.717309   991 layer_factory.hpp:78] Creating layer conv5_2
I1109 12:51:01.717321   991 net.cpp:67] Creating Layer conv5_2
I1109 12:51:01.717327   991 net.cpp:394] conv5_2 <- conv5_1
I1109 12:51:01.717336   991 net.cpp:356] conv5_2 -> conv5_2
I1109 12:51:01.717347   991 net.cpp:96] Setting up conv5_2
I1109 12:51:01.830315   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:01.830359   991 layer_factory.hpp:78] Creating layer relu5_2
I1109 12:51:01.830375   991 net.cpp:67] Creating Layer relu5_2
I1109 12:51:01.830384   991 net.cpp:394] relu5_2 <- conv5_2
I1109 12:51:01.830394   991 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1109 12:51:01.830404   991 net.cpp:96] Setting up relu5_2
I1109 12:51:01.830415   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:01.830421   991 layer_factory.hpp:78] Creating layer conv5_3
I1109 12:51:01.830430   991 net.cpp:67] Creating Layer conv5_3
I1109 12:51:01.830436   991 net.cpp:394] conv5_3 <- conv5_2
I1109 12:51:01.830447   991 net.cpp:356] conv5_3 -> conv5_3
I1109 12:51:01.830458   991 net.cpp:96] Setting up conv5_3
I1109 12:51:01.943831   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:01.943874   991 layer_factory.hpp:78] Creating layer relu5_3
I1109 12:51:01.943889   991 net.cpp:67] Creating Layer relu5_3
I1109 12:51:01.943897   991 net.cpp:394] relu5_3 <- conv5_3
I1109 12:51:01.943908   991 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1109 12:51:01.943919   991 net.cpp:96] Setting up relu5_3
I1109 12:51:01.943930   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:01.943938   991 layer_factory.hpp:78] Creating layer pool5
I1109 12:51:01.943965   991 net.cpp:67] Creating Layer pool5
I1109 12:51:01.943972   991 net.cpp:394] pool5 <- conv5_3
I1109 12:51:01.943982   991 net.cpp:356] pool5 -> pool5
I1109 12:51:01.943991   991 net.cpp:96] Setting up pool5
I1109 12:51:01.944005   991 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1109 12:51:01.944010   991 layer_factory.hpp:78] Creating layer fc6
I1109 12:51:01.944032   991 net.cpp:67] Creating Layer fc6
I1109 12:51:01.944039   991 net.cpp:394] fc6 <- pool5
I1109 12:51:01.944048   991 net.cpp:356] fc6 -> fc6
I1109 12:51:01.944058   991 net.cpp:96] Setting up fc6
I1109 12:51:06.833369   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:06.833415   991 layer_factory.hpp:78] Creating layer relu6
I1109 12:51:06.833428   991 net.cpp:67] Creating Layer relu6
I1109 12:51:06.833436   991 net.cpp:394] relu6 <- fc6
I1109 12:51:06.833446   991 net.cpp:345] relu6 -> fc6 (in-place)
I1109 12:51:06.833457   991 net.cpp:96] Setting up relu6
I1109 12:51:06.833478   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:06.833484   991 layer_factory.hpp:78] Creating layer drop6
I1109 12:51:06.833498   991 net.cpp:67] Creating Layer drop6
I1109 12:51:06.833504   991 net.cpp:394] drop6 <- fc6
I1109 12:51:06.833515   991 net.cpp:345] drop6 -> fc6 (in-place)
I1109 12:51:06.833524   991 net.cpp:96] Setting up drop6
I1109 12:51:06.833534   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:06.833539   991 layer_factory.hpp:78] Creating layer fc7
I1109 12:51:06.833549   991 net.cpp:67] Creating Layer fc7
I1109 12:51:06.833554   991 net.cpp:394] fc7 <- fc6
I1109 12:51:06.833562   991 net.cpp:356] fc7 -> fc7
I1109 12:51:06.833572   991 net.cpp:96] Setting up fc7
I1109 12:51:07.633388   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:07.633433   991 layer_factory.hpp:78] Creating layer relu7
I1109 12:51:07.633446   991 net.cpp:67] Creating Layer relu7
I1109 12:51:07.633455   991 net.cpp:394] relu7 <- fc7
I1109 12:51:07.633468   991 net.cpp:345] relu7 -> fc7 (in-place)
I1109 12:51:07.633479   991 net.cpp:96] Setting up relu7
I1109 12:51:07.633501   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:07.633507   991 layer_factory.hpp:78] Creating layer drop7
I1109 12:51:07.633515   991 net.cpp:67] Creating Layer drop7
I1109 12:51:07.633522   991 net.cpp:394] drop7 <- fc7
I1109 12:51:07.633529   991 net.cpp:345] drop7 -> fc7 (in-place)
I1109 12:51:07.633538   991 net.cpp:96] Setting up drop7
I1109 12:51:07.633544   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:07.633549   991 layer_factory.hpp:78] Creating layer fc8_2
I1109 12:51:07.633565   991 net.cpp:67] Creating Layer fc8_2
I1109 12:51:07.633571   991 net.cpp:394] fc8_2 <- fc7
I1109 12:51:07.633580   991 net.cpp:356] fc8_2 -> fc8_2
I1109 12:51:07.633590   991 net.cpp:96] Setting up fc8_2
I1109 12:51:07.634011   991 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:51:07.634027   991 layer_factory.hpp:78] Creating layer loss
I1109 12:51:07.634044   991 net.cpp:67] Creating Layer loss
I1109 12:51:07.634050   991 net.cpp:394] loss <- fc8_2
I1109 12:51:07.634057   991 net.cpp:394] loss <- label
I1109 12:51:07.634074   991 net.cpp:356] loss -> (automatic)
I1109 12:51:07.634083   991 net.cpp:96] Setting up loss
I1109 12:51:07.634096   991 net.cpp:103] Top shape: 1 1 1 1 (1)
I1109 12:51:07.634102   991 net.cpp:109]     with loss weight 1
I1109 12:51:07.634145   991 net.cpp:170] loss needs backward computation.
I1109 12:51:07.634150   991 net.cpp:170] fc8_2 needs backward computation.
I1109 12:51:07.634156   991 net.cpp:170] drop7 needs backward computation.
I1109 12:51:07.634160   991 net.cpp:170] relu7 needs backward computation.
I1109 12:51:07.634166   991 net.cpp:170] fc7 needs backward computation.
I1109 12:51:07.634171   991 net.cpp:170] drop6 needs backward computation.
I1109 12:51:07.634176   991 net.cpp:170] relu6 needs backward computation.
I1109 12:51:07.634181   991 net.cpp:170] fc6 needs backward computation.
I1109 12:51:07.634187   991 net.cpp:170] pool5 needs backward computation.
I1109 12:51:07.634192   991 net.cpp:170] relu5_3 needs backward computation.
I1109 12:51:07.634210   991 net.cpp:170] conv5_3 needs backward computation.
I1109 12:51:07.634217   991 net.cpp:170] relu5_2 needs backward computation.
I1109 12:51:07.634222   991 net.cpp:170] conv5_2 needs backward computation.
I1109 12:51:07.634260   991 net.cpp:170] relu5_1 needs backward computation.
I1109 12:51:07.634266   991 net.cpp:170] conv5_1 needs backward computation.
I1109 12:51:07.634273   991 net.cpp:170] pool4 needs backward computation.
I1109 12:51:07.634279   991 net.cpp:170] relu4_3 needs backward computation.
I1109 12:51:07.634284   991 net.cpp:170] conv4_3 needs backward computation.
I1109 12:51:07.634289   991 net.cpp:170] relu4_2 needs backward computation.
I1109 12:51:07.634294   991 net.cpp:170] conv4_2 needs backward computation.
I1109 12:51:07.634300   991 net.cpp:170] relu4_1 needs backward computation.
I1109 12:51:07.634305   991 net.cpp:170] conv4_1 needs backward computation.
I1109 12:51:07.634310   991 net.cpp:170] pool3 needs backward computation.
I1109 12:51:07.634316   991 net.cpp:170] relu3_3 needs backward computation.
I1109 12:51:07.634321   991 net.cpp:170] conv3_3 needs backward computation.
I1109 12:51:07.634327   991 net.cpp:170] relu3_2 needs backward computation.
I1109 12:51:07.634332   991 net.cpp:170] conv3_2 needs backward computation.
I1109 12:51:07.634338   991 net.cpp:170] relu3_1 needs backward computation.
I1109 12:51:07.634343   991 net.cpp:170] conv3_1 needs backward computation.
I1109 12:51:07.634349   991 net.cpp:170] pool2 needs backward computation.
I1109 12:51:07.634356   991 net.cpp:170] relu2_2 needs backward computation.
I1109 12:51:07.634361   991 net.cpp:170] conv2_2 needs backward computation.
I1109 12:51:07.634366   991 net.cpp:170] relu2_1 needs backward computation.
I1109 12:51:07.634371   991 net.cpp:170] conv2_1 needs backward computation.
I1109 12:51:07.634377   991 net.cpp:170] pool1 needs backward computation.
I1109 12:51:07.634382   991 net.cpp:170] relu1_2 needs backward computation.
I1109 12:51:07.634388   991 net.cpp:170] conv1_2 needs backward computation.
I1109 12:51:07.634393   991 net.cpp:170] relu1_1 needs backward computation.
I1109 12:51:07.634399   991 net.cpp:170] conv1_1 needs backward computation.
I1109 12:51:07.634404   991 net.cpp:172] data does not need backward computation.
I1109 12:51:07.634438   991 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1109 12:51:07.634459   991 net.cpp:219] Network initialization done.
I1109 12:51:07.634469   991 net.cpp:220] Memory required for data: 921616484
I1109 12:51:07.636020   991 solver.cpp:151] Creating test net (#0) specified by net file: task/inadcl_o/train_val.prototxt
I1109 12:51:07.636109   991 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1109 12:51:07.636498   991 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/inadcl_o/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1109 12:51:07.636759   991 layer_factory.hpp:78] Creating layer data
I1109 12:51:07.636777   991 net.cpp:67] Creating Layer data
I1109 12:51:07.636785   991 net.cpp:356] data -> data
I1109 12:51:07.636797   991 net.cpp:356] data -> label
I1109 12:51:07.636808   991 net.cpp:96] Setting up data
I1109 12:51:07.636814   991 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/inadcl_o/val.txt
I1109 12:51:07.637065   991 image_data_layer.cpp:49] A total of 315 images.
I1109 12:51:07.651865   991 image_data_layer.cpp:78] output data size: 8,3,224,224
I1109 12:51:07.653331   991 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1109 12:51:07.653353   991 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:51:07.653362   991 layer_factory.hpp:78] Creating layer label_data_1_split
I1109 12:51:07.653381   991 net.cpp:67] Creating Layer label_data_1_split
I1109 12:51:07.653389   991 net.cpp:394] label_data_1_split <- label
I1109 12:51:07.653401   991 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1109 12:51:07.653415   991 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1109 12:51:07.653425   991 net.cpp:96] Setting up label_data_1_split
I1109 12:51:07.653435   991 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:51:07.653441   991 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:51:07.653446   991 layer_factory.hpp:78] Creating layer conv1_1
I1109 12:51:07.653458   991 net.cpp:67] Creating Layer conv1_1
I1109 12:51:07.653465   991 net.cpp:394] conv1_1 <- data
I1109 12:51:07.653472   991 net.cpp:356] conv1_1 -> conv1_1
I1109 12:51:07.653483   991 net.cpp:96] Setting up conv1_1
I1109 12:51:07.653780   991 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:07.653807   991 layer_factory.hpp:78] Creating layer relu1_1
I1109 12:51:07.653817   991 net.cpp:67] Creating Layer relu1_1
I1109 12:51:07.653823   991 net.cpp:394] relu1_1 <- conv1_1
I1109 12:51:07.653832   991 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1109 12:51:07.653841   991 net.cpp:96] Setting up relu1_1
I1109 12:51:07.653851   991 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:07.653869   991 layer_factory.hpp:78] Creating layer conv1_2
I1109 12:51:07.653879   991 net.cpp:67] Creating Layer conv1_2
I1109 12:51:07.653885   991 net.cpp:394] conv1_2 <- conv1_1
I1109 12:51:07.653893   991 net.cpp:356] conv1_2 -> conv1_2
I1109 12:51:07.653903   991 net.cpp:96] Setting up conv1_2
I1109 12:51:07.655855   991 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:07.655881   991 layer_factory.hpp:78] Creating layer relu1_2
I1109 12:51:07.655890   991 net.cpp:67] Creating Layer relu1_2
I1109 12:51:07.655896   991 net.cpp:394] relu1_2 <- conv1_2
I1109 12:51:07.655905   991 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1109 12:51:07.655915   991 net.cpp:96] Setting up relu1_2
I1109 12:51:07.655925   991 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:07.655930   991 layer_factory.hpp:78] Creating layer pool1
I1109 12:51:07.655939   991 net.cpp:67] Creating Layer pool1
I1109 12:51:07.655944   991 net.cpp:394] pool1 <- conv1_2
I1109 12:51:07.655952   991 net.cpp:356] pool1 -> pool1
I1109 12:51:07.655961   991 net.cpp:96] Setting up pool1
I1109 12:51:07.655972   991 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1109 12:51:07.655978   991 layer_factory.hpp:78] Creating layer conv2_1
I1109 12:51:07.655987   991 net.cpp:67] Creating Layer conv2_1
I1109 12:51:07.655992   991 net.cpp:394] conv2_1 <- pool1
I1109 12:51:07.656002   991 net.cpp:356] conv2_1 -> conv2_1
I1109 12:51:07.656010   991 net.cpp:96] Setting up conv2_1
I1109 12:51:07.659862   991 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:07.659890   991 layer_factory.hpp:78] Creating layer relu2_1
I1109 12:51:07.659901   991 net.cpp:67] Creating Layer relu2_1
I1109 12:51:07.659907   991 net.cpp:394] relu2_1 <- conv2_1
I1109 12:51:07.659915   991 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1109 12:51:07.659924   991 net.cpp:96] Setting up relu2_1
I1109 12:51:07.659934   991 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:07.659940   991 layer_factory.hpp:78] Creating layer conv2_2
I1109 12:51:07.659950   991 net.cpp:67] Creating Layer conv2_2
I1109 12:51:07.659955   991 net.cpp:394] conv2_2 <- conv2_1
I1109 12:51:07.659965   991 net.cpp:356] conv2_2 -> conv2_2
I1109 12:51:07.659975   991 net.cpp:96] Setting up conv2_2
I1109 12:51:07.667112   991 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:07.667136   991 layer_factory.hpp:78] Creating layer relu2_2
I1109 12:51:07.667146   991 net.cpp:67] Creating Layer relu2_2
I1109 12:51:07.667152   991 net.cpp:394] relu2_2 <- conv2_2
I1109 12:51:07.667161   991 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1109 12:51:07.667171   991 net.cpp:96] Setting up relu2_2
I1109 12:51:07.667181   991 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:07.667186   991 layer_factory.hpp:78] Creating layer pool2
I1109 12:51:07.667196   991 net.cpp:67] Creating Layer pool2
I1109 12:51:07.667201   991 net.cpp:394] pool2 <- conv2_2
I1109 12:51:07.667208   991 net.cpp:356] pool2 -> pool2
I1109 12:51:07.667217   991 net.cpp:96] Setting up pool2
I1109 12:51:07.667228   991 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1109 12:51:07.667234   991 layer_factory.hpp:78] Creating layer conv3_1
I1109 12:51:07.667243   991 net.cpp:67] Creating Layer conv3_1
I1109 12:51:07.667249   991 net.cpp:394] conv3_1 <- pool2
I1109 12:51:07.667258   991 net.cpp:356] conv3_1 -> conv3_1
I1109 12:51:07.667266   991 net.cpp:96] Setting up conv3_1
I1109 12:51:07.681478   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:07.681512   991 layer_factory.hpp:78] Creating layer relu3_1
I1109 12:51:07.681524   991 net.cpp:67] Creating Layer relu3_1
I1109 12:51:07.681531   991 net.cpp:394] relu3_1 <- conv3_1
I1109 12:51:07.681540   991 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1109 12:51:07.681551   991 net.cpp:96] Setting up relu3_1
I1109 12:51:07.681561   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:07.681567   991 layer_factory.hpp:78] Creating layer conv3_2
I1109 12:51:07.681576   991 net.cpp:67] Creating Layer conv3_2
I1109 12:51:07.681582   991 net.cpp:394] conv3_2 <- conv3_1
I1109 12:51:07.681606   991 net.cpp:356] conv3_2 -> conv3_2
I1109 12:51:07.681617   991 net.cpp:96] Setting up conv3_2
I1109 12:51:07.710327   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:07.710368   991 layer_factory.hpp:78] Creating layer relu3_2
I1109 12:51:07.710381   991 net.cpp:67] Creating Layer relu3_2
I1109 12:51:07.710389   991 net.cpp:394] relu3_2 <- conv3_2
I1109 12:51:07.710402   991 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1109 12:51:07.710418   991 net.cpp:96] Setting up relu3_2
I1109 12:51:07.710429   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:07.710436   991 layer_factory.hpp:78] Creating layer conv3_3
I1109 12:51:07.710449   991 net.cpp:67] Creating Layer conv3_3
I1109 12:51:07.710455   991 net.cpp:394] conv3_3 <- conv3_2
I1109 12:51:07.710468   991 net.cpp:356] conv3_3 -> conv3_3
I1109 12:51:07.710479   991 net.cpp:96] Setting up conv3_3
I1109 12:51:07.739523   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:07.739560   991 layer_factory.hpp:78] Creating layer relu3_3
I1109 12:51:07.739574   991 net.cpp:67] Creating Layer relu3_3
I1109 12:51:07.739581   991 net.cpp:394] relu3_3 <- conv3_3
I1109 12:51:07.739595   991 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1109 12:51:07.739608   991 net.cpp:96] Setting up relu3_3
I1109 12:51:07.739619   991 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:07.739625   991 layer_factory.hpp:78] Creating layer pool3
I1109 12:51:07.739634   991 net.cpp:67] Creating Layer pool3
I1109 12:51:07.739640   991 net.cpp:394] pool3 <- conv3_3
I1109 12:51:07.739651   991 net.cpp:356] pool3 -> pool3
I1109 12:51:07.739662   991 net.cpp:96] Setting up pool3
I1109 12:51:07.739675   991 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1109 12:51:07.739681   991 layer_factory.hpp:78] Creating layer conv4_1
I1109 12:51:07.739691   991 net.cpp:67] Creating Layer conv4_1
I1109 12:51:07.739696   991 net.cpp:394] conv4_1 <- pool3
I1109 12:51:07.739707   991 net.cpp:356] conv4_1 -> conv4_1
I1109 12:51:07.739718   991 net.cpp:96] Setting up conv4_1
I1109 12:51:07.796663   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:07.796701   991 layer_factory.hpp:78] Creating layer relu4_1
I1109 12:51:07.796715   991 net.cpp:67] Creating Layer relu4_1
I1109 12:51:07.796722   991 net.cpp:394] relu4_1 <- conv4_1
I1109 12:51:07.796737   991 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1109 12:51:07.796749   991 net.cpp:96] Setting up relu4_1
I1109 12:51:07.796761   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:07.796766   991 layer_factory.hpp:78] Creating layer conv4_2
I1109 12:51:07.796777   991 net.cpp:67] Creating Layer conv4_2
I1109 12:51:07.796782   991 net.cpp:394] conv4_2 <- conv4_1
I1109 12:51:07.796794   991 net.cpp:356] conv4_2 -> conv4_2
I1109 12:51:07.796804   991 net.cpp:96] Setting up conv4_2
I1109 12:51:07.909983   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:07.910035   991 layer_factory.hpp:78] Creating layer relu4_2
I1109 12:51:07.910050   991 net.cpp:67] Creating Layer relu4_2
I1109 12:51:07.910058   991 net.cpp:394] relu4_2 <- conv4_2
I1109 12:51:07.910070   991 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1109 12:51:07.910084   991 net.cpp:96] Setting up relu4_2
I1109 12:51:07.910094   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:07.910100   991 layer_factory.hpp:78] Creating layer conv4_3
I1109 12:51:07.910110   991 net.cpp:67] Creating Layer conv4_3
I1109 12:51:07.910116   991 net.cpp:394] conv4_3 <- conv4_2
I1109 12:51:07.910125   991 net.cpp:356] conv4_3 -> conv4_3
I1109 12:51:07.910136   991 net.cpp:96] Setting up conv4_3
I1109 12:51:08.022966   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:08.023011   991 layer_factory.hpp:78] Creating layer relu4_3
I1109 12:51:08.023023   991 net.cpp:67] Creating Layer relu4_3
I1109 12:51:08.023031   991 net.cpp:394] relu4_3 <- conv4_3
I1109 12:51:08.023048   991 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1109 12:51:08.023061   991 net.cpp:96] Setting up relu4_3
I1109 12:51:08.023071   991 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:08.023092   991 layer_factory.hpp:78] Creating layer pool4
I1109 12:51:08.023102   991 net.cpp:67] Creating Layer pool4
I1109 12:51:08.023108   991 net.cpp:394] pool4 <- conv4_3
I1109 12:51:08.023116   991 net.cpp:356] pool4 -> pool4
I1109 12:51:08.023125   991 net.cpp:96] Setting up pool4
I1109 12:51:08.023138   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:08.023144   991 layer_factory.hpp:78] Creating layer conv5_1
I1109 12:51:08.023157   991 net.cpp:67] Creating Layer conv5_1
I1109 12:51:08.023164   991 net.cpp:394] conv5_1 <- pool4
I1109 12:51:08.023172   991 net.cpp:356] conv5_1 -> conv5_1
I1109 12:51:08.023182   991 net.cpp:96] Setting up conv5_1
I1109 12:51:08.136411   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:08.136453   991 layer_factory.hpp:78] Creating layer relu5_1
I1109 12:51:08.136469   991 net.cpp:67] Creating Layer relu5_1
I1109 12:51:08.136477   991 net.cpp:394] relu5_1 <- conv5_1
I1109 12:51:08.136487   991 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1109 12:51:08.136498   991 net.cpp:96] Setting up relu5_1
I1109 12:51:08.136509   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:08.136515   991 layer_factory.hpp:78] Creating layer conv5_2
I1109 12:51:08.136525   991 net.cpp:67] Creating Layer conv5_2
I1109 12:51:08.136530   991 net.cpp:394] conv5_2 <- conv5_1
I1109 12:51:08.136543   991 net.cpp:356] conv5_2 -> conv5_2
I1109 12:51:08.136554   991 net.cpp:96] Setting up conv5_2
I1109 12:51:08.249362   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:08.249404   991 layer_factory.hpp:78] Creating layer relu5_2
I1109 12:51:08.249418   991 net.cpp:67] Creating Layer relu5_2
I1109 12:51:08.249424   991 net.cpp:394] relu5_2 <- conv5_2
I1109 12:51:08.249435   991 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1109 12:51:08.249447   991 net.cpp:96] Setting up relu5_2
I1109 12:51:08.249457   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:08.249464   991 layer_factory.hpp:78] Creating layer conv5_3
I1109 12:51:08.249477   991 net.cpp:67] Creating Layer conv5_3
I1109 12:51:08.249483   991 net.cpp:394] conv5_3 <- conv5_2
I1109 12:51:08.249495   991 net.cpp:356] conv5_3 -> conv5_3
I1109 12:51:08.249506   991 net.cpp:96] Setting up conv5_3
I1109 12:51:08.362923   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:08.362968   991 layer_factory.hpp:78] Creating layer relu5_3
I1109 12:51:08.362982   991 net.cpp:67] Creating Layer relu5_3
I1109 12:51:08.362989   991 net.cpp:394] relu5_3 <- conv5_3
I1109 12:51:08.363000   991 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1109 12:51:08.363013   991 net.cpp:96] Setting up relu5_3
I1109 12:51:08.363023   991 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:08.363029   991 layer_factory.hpp:78] Creating layer pool5
I1109 12:51:08.363045   991 net.cpp:67] Creating Layer pool5
I1109 12:51:08.363052   991 net.cpp:394] pool5 <- conv5_3
I1109 12:51:08.363064   991 net.cpp:356] pool5 -> pool5
I1109 12:51:08.363073   991 net.cpp:96] Setting up pool5
I1109 12:51:08.363086   991 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1109 12:51:08.363092   991 layer_factory.hpp:78] Creating layer fc6
I1109 12:51:08.363102   991 net.cpp:67] Creating Layer fc6
I1109 12:51:08.363107   991 net.cpp:394] fc6 <- pool5
I1109 12:51:08.363116   991 net.cpp:356] fc6 -> fc6
I1109 12:51:08.363126   991 net.cpp:96] Setting up fc6
I1109 12:51:13.251008   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:13.251054   991 layer_factory.hpp:78] Creating layer relu6
I1109 12:51:13.251066   991 net.cpp:67] Creating Layer relu6
I1109 12:51:13.251073   991 net.cpp:394] relu6 <- fc6
I1109 12:51:13.251091   991 net.cpp:345] relu6 -> fc6 (in-place)
I1109 12:51:13.251102   991 net.cpp:96] Setting up relu6
I1109 12:51:13.251123   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:13.251129   991 layer_factory.hpp:78] Creating layer drop6
I1109 12:51:13.251138   991 net.cpp:67] Creating Layer drop6
I1109 12:51:13.251143   991 net.cpp:394] drop6 <- fc6
I1109 12:51:13.251152   991 net.cpp:345] drop6 -> fc6 (in-place)
I1109 12:51:13.251176   991 net.cpp:96] Setting up drop6
I1109 12:51:13.251184   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:13.251189   991 layer_factory.hpp:78] Creating layer fc7
I1109 12:51:13.251199   991 net.cpp:67] Creating Layer fc7
I1109 12:51:13.251204   991 net.cpp:394] fc7 <- fc6
I1109 12:51:13.251216   991 net.cpp:356] fc7 -> fc7
I1109 12:51:13.251227   991 net.cpp:96] Setting up fc7
I1109 12:51:14.050629   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:14.050675   991 layer_factory.hpp:78] Creating layer relu7
I1109 12:51:14.050690   991 net.cpp:67] Creating Layer relu7
I1109 12:51:14.050698   991 net.cpp:394] relu7 <- fc7
I1109 12:51:14.050709   991 net.cpp:345] relu7 -> fc7 (in-place)
I1109 12:51:14.050720   991 net.cpp:96] Setting up relu7
I1109 12:51:14.050742   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:14.050748   991 layer_factory.hpp:78] Creating layer drop7
I1109 12:51:14.050756   991 net.cpp:67] Creating Layer drop7
I1109 12:51:14.050762   991 net.cpp:394] drop7 <- fc7
I1109 12:51:14.050770   991 net.cpp:345] drop7 -> fc7 (in-place)
I1109 12:51:14.050778   991 net.cpp:96] Setting up drop7
I1109 12:51:14.050786   991 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:14.050791   991 layer_factory.hpp:78] Creating layer fc8_2
I1109 12:51:14.050803   991 net.cpp:67] Creating Layer fc8_2
I1109 12:51:14.050809   991 net.cpp:394] fc8_2 <- fc7
I1109 12:51:14.050818   991 net.cpp:356] fc8_2 -> fc8_2
I1109 12:51:14.050828   991 net.cpp:96] Setting up fc8_2
I1109 12:51:14.051239   991 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:51:14.051254   991 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1109 12:51:14.051264   991 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1109 12:51:14.051269   991 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1109 12:51:14.051276   991 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1109 12:51:14.051286   991 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1109 12:51:14.051295   991 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1109 12:51:14.051302   991 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:51:14.051308   991 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:51:14.051313   991 layer_factory.hpp:78] Creating layer loss
I1109 12:51:14.051326   991 net.cpp:67] Creating Layer loss
I1109 12:51:14.051331   991 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1109 12:51:14.051338   991 net.cpp:394] loss <- label_data_1_split_0
I1109 12:51:14.051349   991 net.cpp:356] loss -> (automatic)
I1109 12:51:14.051357   991 net.cpp:96] Setting up loss
I1109 12:51:14.051367   991 net.cpp:103] Top shape: 1 1 1 1 (1)
I1109 12:51:14.051373   991 net.cpp:109]     with loss weight 1
I1109 12:51:14.051393   991 layer_factory.hpp:78] Creating layer accuracy
I1109 12:51:14.051406   991 net.cpp:67] Creating Layer accuracy
I1109 12:51:14.051412   991 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1109 12:51:14.051419   991 net.cpp:394] accuracy <- label_data_1_split_1
I1109 12:51:14.051432   991 net.cpp:356] accuracy -> accuracy
I1109 12:51:14.051442   991 net.cpp:96] Setting up accuracy
I1109 12:51:14.051455   991 net.cpp:103] Top shape: 1 1 1 4 (4)
I1109 12:51:14.051467   991 net.cpp:172] accuracy does not need backward computation.
I1109 12:51:14.051472   991 net.cpp:170] loss needs backward computation.
I1109 12:51:14.051478   991 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1109 12:51:14.051483   991 net.cpp:170] fc8_2 needs backward computation.
I1109 12:51:14.051488   991 net.cpp:170] drop7 needs backward computation.
I1109 12:51:14.051493   991 net.cpp:170] relu7 needs backward computation.
I1109 12:51:14.051497   991 net.cpp:170] fc7 needs backward computation.
I1109 12:51:14.051503   991 net.cpp:170] drop6 needs backward computation.
I1109 12:51:14.051508   991 net.cpp:170] relu6 needs backward computation.
I1109 12:51:14.051513   991 net.cpp:170] fc6 needs backward computation.
I1109 12:51:14.051518   991 net.cpp:170] pool5 needs backward computation.
I1109 12:51:14.051537   991 net.cpp:170] relu5_3 needs backward computation.
I1109 12:51:14.051543   991 net.cpp:170] conv5_3 needs backward computation.
I1109 12:51:14.051549   991 net.cpp:170] relu5_2 needs backward computation.
I1109 12:51:14.051554   991 net.cpp:170] conv5_2 needs backward computation.
I1109 12:51:14.051560   991 net.cpp:170] relu5_1 needs backward computation.
I1109 12:51:14.051565   991 net.cpp:170] conv5_1 needs backward computation.
I1109 12:51:14.051571   991 net.cpp:170] pool4 needs backward computation.
I1109 12:51:14.051576   991 net.cpp:170] relu4_3 needs backward computation.
I1109 12:51:14.051581   991 net.cpp:170] conv4_3 needs backward computation.
I1109 12:51:14.051587   991 net.cpp:170] relu4_2 needs backward computation.
I1109 12:51:14.051592   991 net.cpp:170] conv4_2 needs backward computation.
I1109 12:51:14.051597   991 net.cpp:170] relu4_1 needs backward computation.
I1109 12:51:14.051602   991 net.cpp:170] conv4_1 needs backward computation.
I1109 12:51:14.051609   991 net.cpp:170] pool3 needs backward computation.
I1109 12:51:14.051614   991 net.cpp:170] relu3_3 needs backward computation.
I1109 12:51:14.051619   991 net.cpp:170] conv3_3 needs backward computation.
I1109 12:51:14.051623   991 net.cpp:170] relu3_2 needs backward computation.
I1109 12:51:14.051628   991 net.cpp:170] conv3_2 needs backward computation.
I1109 12:51:14.051635   991 net.cpp:170] relu3_1 needs backward computation.
I1109 12:51:14.051640   991 net.cpp:170] conv3_1 needs backward computation.
I1109 12:51:14.051645   991 net.cpp:170] pool2 needs backward computation.
I1109 12:51:14.051650   991 net.cpp:170] relu2_2 needs backward computation.
I1109 12:51:14.051655   991 net.cpp:170] conv2_2 needs backward computation.
I1109 12:51:14.051661   991 net.cpp:170] relu2_1 needs backward computation.
I1109 12:51:14.051666   991 net.cpp:170] conv2_1 needs backward computation.
I1109 12:51:14.051671   991 net.cpp:170] pool1 needs backward computation.
I1109 12:51:14.051676   991 net.cpp:170] relu1_2 needs backward computation.
I1109 12:51:14.051681   991 net.cpp:170] conv1_2 needs backward computation.
I1109 12:51:14.051687   991 net.cpp:170] relu1_1 needs backward computation.
I1109 12:51:14.051692   991 net.cpp:170] conv1_1 needs backward computation.
I1109 12:51:14.051697   991 net.cpp:172] label_data_1_split does not need backward computation.
I1109 12:51:14.051702   991 net.cpp:172] data does not need backward computation.
I1109 12:51:14.051707   991 net.cpp:208] This network produces output accuracy
I1109 12:51:14.051746   991 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1109 12:51:14.051759   991 net.cpp:219] Network initialization done.
I1109 12:51:14.051764   991 net.cpp:220] Memory required for data: 921616692
I1109 12:51:14.051946   991 solver.cpp:41] Solver scaffolding done.
I1109 12:51:14.051959   991 caffe.cpp:115] Finetuning from task/inadcl_o/none/_iter_3000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077499
I1109 12:51:16.002430   991 solver.cpp:160] Solving small
I1109 12:51:16.002463   991 solver.cpp:161] Learning Rate Policy: step
I1109 12:51:16.813946   991 solver.cpp:339] Snapshotting to _iter_0.caffemodel
I1109 12:51:19.138653   991 solver.cpp:347] Snapshotting solver state to _iter_0.solverstate
I1109 12:51:21.935225   991 solver.cpp:246] Iteration 0, loss = 0.660151
I1109 12:51:21.935283   991 solver.cpp:264] Iteration 0, Testing net (#0)
I1109 12:51:27.105986   991 solver.cpp:305] Test loss: 0.516058
I1109 12:51:27.106044   991 solver.cpp:320]     Test net output #0: accuracy = 0.808703
I1109 12:51:27.106056   991 solver.cpp:320]     Test net output #1: accuracy = 0.666667
I1109 12:51:27.106065   991 solver.cpp:320]     Test net output #2: accuracy = 0.737685
I1109 12:51:27.106072   991 solver.cpp:320]     Test net output #3: accuracy = 0.771552
I1109 12:51:27.106081   991 solver.cpp:251] Optimization Done.
I1109 12:51:27.106086   991 caffe.cpp:121] Optimization Done.
I1109 12:51:27.372123  1049 caffe.cpp:99] Use GPU with device ID 0
I1109 12:51:27.665683  1049 caffe.cpp:107] Starting Optimization
I1109 12:51:27.665832  1049 solver.cpp:32] Initializing solver from parameters: 
test_iter: 29
test_interval: 1
base_lr: 0
display: 10
max_iter: 0
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 200
solver_mode: GPU
test_compute_loss: true
net: "task/inadcl_o/train_val.prototxt"
I1109 12:51:27.665870  1049 solver.cpp:67] Creating training net from net file: task/inadcl_o/train_val.prototxt
I1109 12:51:27.667403  1049 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 12:51:27.667460  1049 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 12:51:27.667826  1049 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/inadcl_o/train.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1109 12:51:27.668035  1049 layer_factory.hpp:78] Creating layer data
I1109 12:51:27.668081  1049 net.cpp:67] Creating Layer data
I1109 12:51:27.668098  1049 net.cpp:356] data -> data
I1109 12:51:27.668123  1049 net.cpp:356] data -> label
I1109 12:51:27.668144  1049 net.cpp:96] Setting up data
I1109 12:51:27.668155  1049 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/inadcl_o/train.txt
I1109 12:51:27.681773  1049 image_data_layer.cpp:49] A total of 20637 images.
I1109 12:51:27.692788  1049 image_data_layer.cpp:78] output data size: 8,3,224,224
I1109 12:51:27.695663  1049 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1109 12:51:27.695695  1049 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:51:27.695704  1049 layer_factory.hpp:78] Creating layer conv1_1
I1109 12:51:27.695724  1049 net.cpp:67] Creating Layer conv1_1
I1109 12:51:27.695731  1049 net.cpp:394] conv1_1 <- data
I1109 12:51:27.695754  1049 net.cpp:356] conv1_1 -> conv1_1
I1109 12:51:27.695771  1049 net.cpp:96] Setting up conv1_1
I1109 12:51:27.721277  1049 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:27.721328  1049 layer_factory.hpp:78] Creating layer relu1_1
I1109 12:51:27.721348  1049 net.cpp:67] Creating Layer relu1_1
I1109 12:51:27.721354  1049 net.cpp:394] relu1_1 <- conv1_1
I1109 12:51:27.721365  1049 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1109 12:51:27.721385  1049 net.cpp:96] Setting up relu1_1
I1109 12:51:27.721400  1049 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:27.721410  1049 layer_factory.hpp:78] Creating layer conv1_2
I1109 12:51:27.721423  1049 net.cpp:67] Creating Layer conv1_2
I1109 12:51:27.721431  1049 net.cpp:394] conv1_2 <- conv1_1
I1109 12:51:27.721441  1049 net.cpp:356] conv1_2 -> conv1_2
I1109 12:51:27.721454  1049 net.cpp:96] Setting up conv1_2
I1109 12:51:27.723583  1049 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:27.723609  1049 layer_factory.hpp:78] Creating layer relu1_2
I1109 12:51:27.723619  1049 net.cpp:67] Creating Layer relu1_2
I1109 12:51:27.723625  1049 net.cpp:394] relu1_2 <- conv1_2
I1109 12:51:27.723637  1049 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1109 12:51:27.723647  1049 net.cpp:96] Setting up relu1_2
I1109 12:51:27.723657  1049 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:27.723670  1049 layer_factory.hpp:78] Creating layer pool1
I1109 12:51:27.723682  1049 net.cpp:67] Creating Layer pool1
I1109 12:51:27.723688  1049 net.cpp:394] pool1 <- conv1_2
I1109 12:51:27.723697  1049 net.cpp:356] pool1 -> pool1
I1109 12:51:27.723707  1049 net.cpp:96] Setting up pool1
I1109 12:51:27.723743  1049 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1109 12:51:27.723752  1049 layer_factory.hpp:78] Creating layer conv2_1
I1109 12:51:27.723760  1049 net.cpp:67] Creating Layer conv2_1
I1109 12:51:27.723767  1049 net.cpp:394] conv2_1 <- pool1
I1109 12:51:27.723779  1049 net.cpp:356] conv2_1 -> conv2_1
I1109 12:51:27.723790  1049 net.cpp:96] Setting up conv2_1
I1109 12:51:27.727567  1049 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:27.727593  1049 layer_factory.hpp:78] Creating layer relu2_1
I1109 12:51:27.727602  1049 net.cpp:67] Creating Layer relu2_1
I1109 12:51:27.727608  1049 net.cpp:394] relu2_1 <- conv2_1
I1109 12:51:27.727617  1049 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1109 12:51:27.727625  1049 net.cpp:96] Setting up relu2_1
I1109 12:51:27.727635  1049 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:27.727643  1049 layer_factory.hpp:78] Creating layer conv2_2
I1109 12:51:27.727658  1049 net.cpp:67] Creating Layer conv2_2
I1109 12:51:27.727664  1049 net.cpp:394] conv2_2 <- conv2_1
I1109 12:51:27.727674  1049 net.cpp:356] conv2_2 -> conv2_2
I1109 12:51:27.727682  1049 net.cpp:96] Setting up conv2_2
I1109 12:51:27.735059  1049 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:27.735086  1049 layer_factory.hpp:78] Creating layer relu2_2
I1109 12:51:27.735095  1049 net.cpp:67] Creating Layer relu2_2
I1109 12:51:27.735102  1049 net.cpp:394] relu2_2 <- conv2_2
I1109 12:51:27.735111  1049 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1109 12:51:27.735121  1049 net.cpp:96] Setting up relu2_2
I1109 12:51:27.735131  1049 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:27.735137  1049 layer_factory.hpp:78] Creating layer pool2
I1109 12:51:27.735394  1049 net.cpp:67] Creating Layer pool2
I1109 12:51:27.735407  1049 net.cpp:394] pool2 <- conv2_2
I1109 12:51:27.735417  1049 net.cpp:356] pool2 -> pool2
I1109 12:51:27.735427  1049 net.cpp:96] Setting up pool2
I1109 12:51:27.735443  1049 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1109 12:51:27.735450  1049 layer_factory.hpp:78] Creating layer conv3_1
I1109 12:51:27.735462  1049 net.cpp:67] Creating Layer conv3_1
I1109 12:51:27.735468  1049 net.cpp:394] conv3_1 <- pool2
I1109 12:51:27.735477  1049 net.cpp:356] conv3_1 -> conv3_1
I1109 12:51:27.735488  1049 net.cpp:96] Setting up conv3_1
I1109 12:51:27.749950  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:27.749984  1049 layer_factory.hpp:78] Creating layer relu3_1
I1109 12:51:27.749995  1049 net.cpp:67] Creating Layer relu3_1
I1109 12:51:27.750001  1049 net.cpp:394] relu3_1 <- conv3_1
I1109 12:51:27.750010  1049 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1109 12:51:27.750020  1049 net.cpp:96] Setting up relu3_1
I1109 12:51:27.750030  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:27.750036  1049 layer_factory.hpp:78] Creating layer conv3_2
I1109 12:51:27.750048  1049 net.cpp:67] Creating Layer conv3_2
I1109 12:51:27.750054  1049 net.cpp:394] conv3_2 <- conv3_1
I1109 12:51:27.750063  1049 net.cpp:356] conv3_2 -> conv3_2
I1109 12:51:27.750073  1049 net.cpp:96] Setting up conv3_2
I1109 12:51:27.779295  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:27.779331  1049 layer_factory.hpp:78] Creating layer relu3_2
I1109 12:51:27.779347  1049 net.cpp:67] Creating Layer relu3_2
I1109 12:51:27.779356  1049 net.cpp:394] relu3_2 <- conv3_2
I1109 12:51:27.779366  1049 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1109 12:51:27.779381  1049 net.cpp:96] Setting up relu3_2
I1109 12:51:27.779391  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:27.779397  1049 layer_factory.hpp:78] Creating layer conv3_3
I1109 12:51:27.779407  1049 net.cpp:67] Creating Layer conv3_3
I1109 12:51:27.779412  1049 net.cpp:394] conv3_3 <- conv3_2
I1109 12:51:27.779422  1049 net.cpp:356] conv3_3 -> conv3_3
I1109 12:51:27.779431  1049 net.cpp:96] Setting up conv3_3
I1109 12:51:27.807927  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:27.807960  1049 layer_factory.hpp:78] Creating layer relu3_3
I1109 12:51:27.807975  1049 net.cpp:67] Creating Layer relu3_3
I1109 12:51:27.807981  1049 net.cpp:394] relu3_3 <- conv3_3
I1109 12:51:27.807991  1049 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1109 12:51:27.808001  1049 net.cpp:96] Setting up relu3_3
I1109 12:51:27.808012  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:27.808018  1049 layer_factory.hpp:78] Creating layer pool3
I1109 12:51:27.808028  1049 net.cpp:67] Creating Layer pool3
I1109 12:51:27.808033  1049 net.cpp:394] pool3 <- conv3_3
I1109 12:51:27.808042  1049 net.cpp:356] pool3 -> pool3
I1109 12:51:27.808050  1049 net.cpp:96] Setting up pool3
I1109 12:51:27.808063  1049 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1109 12:51:27.808069  1049 layer_factory.hpp:78] Creating layer conv4_1
I1109 12:51:27.808079  1049 net.cpp:67] Creating Layer conv4_1
I1109 12:51:27.808084  1049 net.cpp:394] conv4_1 <- pool3
I1109 12:51:27.808092  1049 net.cpp:356] conv4_1 -> conv4_1
I1109 12:51:27.808101  1049 net.cpp:96] Setting up conv4_1
I1109 12:51:27.864959  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:27.864987  1049 layer_factory.hpp:78] Creating layer relu4_1
I1109 12:51:27.864998  1049 net.cpp:67] Creating Layer relu4_1
I1109 12:51:27.865005  1049 net.cpp:394] relu4_1 <- conv4_1
I1109 12:51:27.865013  1049 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1109 12:51:27.865023  1049 net.cpp:96] Setting up relu4_1
I1109 12:51:27.865033  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:27.865039  1049 layer_factory.hpp:78] Creating layer conv4_2
I1109 12:51:27.865048  1049 net.cpp:67] Creating Layer conv4_2
I1109 12:51:27.865054  1049 net.cpp:394] conv4_2 <- conv4_1
I1109 12:51:27.865062  1049 net.cpp:356] conv4_2 -> conv4_2
I1109 12:51:27.865072  1049 net.cpp:96] Setting up conv4_2
I1109 12:51:27.978468  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:27.978523  1049 layer_factory.hpp:78] Creating layer relu4_2
I1109 12:51:27.978538  1049 net.cpp:67] Creating Layer relu4_2
I1109 12:51:27.978544  1049 net.cpp:394] relu4_2 <- conv4_2
I1109 12:51:27.978555  1049 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1109 12:51:27.978566  1049 net.cpp:96] Setting up relu4_2
I1109 12:51:27.978577  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:27.978584  1049 layer_factory.hpp:78] Creating layer conv4_3
I1109 12:51:27.978593  1049 net.cpp:67] Creating Layer conv4_3
I1109 12:51:27.978598  1049 net.cpp:394] conv4_3 <- conv4_2
I1109 12:51:27.978607  1049 net.cpp:356] conv4_3 -> conv4_3
I1109 12:51:27.978617  1049 net.cpp:96] Setting up conv4_3
I1109 12:51:28.091574  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:28.091617  1049 layer_factory.hpp:78] Creating layer relu4_3
I1109 12:51:28.091630  1049 net.cpp:67] Creating Layer relu4_3
I1109 12:51:28.091637  1049 net.cpp:394] relu4_3 <- conv4_3
I1109 12:51:28.091647  1049 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1109 12:51:28.091657  1049 net.cpp:96] Setting up relu4_3
I1109 12:51:28.091668  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:28.091675  1049 layer_factory.hpp:78] Creating layer pool4
I1109 12:51:28.091683  1049 net.cpp:67] Creating Layer pool4
I1109 12:51:28.091689  1049 net.cpp:394] pool4 <- conv4_3
I1109 12:51:28.091701  1049 net.cpp:356] pool4 -> pool4
I1109 12:51:28.091711  1049 net.cpp:96] Setting up pool4
I1109 12:51:28.091723  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:28.091730  1049 layer_factory.hpp:78] Creating layer conv5_1
I1109 12:51:28.091740  1049 net.cpp:67] Creating Layer conv5_1
I1109 12:51:28.091747  1049 net.cpp:394] conv5_1 <- pool4
I1109 12:51:28.091755  1049 net.cpp:356] conv5_1 -> conv5_1
I1109 12:51:28.091768  1049 net.cpp:96] Setting up conv5_1
I1109 12:51:28.205361  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:28.205404  1049 layer_factory.hpp:78] Creating layer relu5_1
I1109 12:51:28.205426  1049 net.cpp:67] Creating Layer relu5_1
I1109 12:51:28.205435  1049 net.cpp:394] relu5_1 <- conv5_1
I1109 12:51:28.205446  1049 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1109 12:51:28.205457  1049 net.cpp:96] Setting up relu5_1
I1109 12:51:28.205468  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:28.205474  1049 layer_factory.hpp:78] Creating layer conv5_2
I1109 12:51:28.205487  1049 net.cpp:67] Creating Layer conv5_2
I1109 12:51:28.205492  1049 net.cpp:394] conv5_2 <- conv5_1
I1109 12:51:28.205502  1049 net.cpp:356] conv5_2 -> conv5_2
I1109 12:51:28.205512  1049 net.cpp:96] Setting up conv5_2
I1109 12:51:28.318663  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:28.318707  1049 layer_factory.hpp:78] Creating layer relu5_2
I1109 12:51:28.318722  1049 net.cpp:67] Creating Layer relu5_2
I1109 12:51:28.318728  1049 net.cpp:394] relu5_2 <- conv5_2
I1109 12:51:28.318742  1049 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1109 12:51:28.318754  1049 net.cpp:96] Setting up relu5_2
I1109 12:51:28.318781  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:28.318790  1049 layer_factory.hpp:78] Creating layer conv5_3
I1109 12:51:28.318800  1049 net.cpp:67] Creating Layer conv5_3
I1109 12:51:28.318806  1049 net.cpp:394] conv5_3 <- conv5_2
I1109 12:51:28.318819  1049 net.cpp:356] conv5_3 -> conv5_3
I1109 12:51:28.318830  1049 net.cpp:96] Setting up conv5_3
I1109 12:51:28.435017  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:28.435060  1049 layer_factory.hpp:78] Creating layer relu5_3
I1109 12:51:28.435073  1049 net.cpp:67] Creating Layer relu5_3
I1109 12:51:28.435081  1049 net.cpp:394] relu5_3 <- conv5_3
I1109 12:51:28.435094  1049 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1109 12:51:28.435106  1049 net.cpp:96] Setting up relu5_3
I1109 12:51:28.435117  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:28.435123  1049 layer_factory.hpp:78] Creating layer pool5
I1109 12:51:28.435147  1049 net.cpp:67] Creating Layer pool5
I1109 12:51:28.435153  1049 net.cpp:394] pool5 <- conv5_3
I1109 12:51:28.435163  1049 net.cpp:356] pool5 -> pool5
I1109 12:51:28.435174  1049 net.cpp:96] Setting up pool5
I1109 12:51:28.435188  1049 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1109 12:51:28.435194  1049 layer_factory.hpp:78] Creating layer fc6
I1109 12:51:28.435215  1049 net.cpp:67] Creating Layer fc6
I1109 12:51:28.435221  1049 net.cpp:394] fc6 <- pool5
I1109 12:51:28.435231  1049 net.cpp:356] fc6 -> fc6
I1109 12:51:28.435240  1049 net.cpp:96] Setting up fc6
I1109 12:51:33.348248  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:33.348299  1049 layer_factory.hpp:78] Creating layer relu6
I1109 12:51:33.348314  1049 net.cpp:67] Creating Layer relu6
I1109 12:51:33.348320  1049 net.cpp:394] relu6 <- fc6
I1109 12:51:33.348332  1049 net.cpp:345] relu6 -> fc6 (in-place)
I1109 12:51:33.348342  1049 net.cpp:96] Setting up relu6
I1109 12:51:33.348364  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:33.348371  1049 layer_factory.hpp:78] Creating layer drop6
I1109 12:51:33.348386  1049 net.cpp:67] Creating Layer drop6
I1109 12:51:33.348392  1049 net.cpp:394] drop6 <- fc6
I1109 12:51:33.348402  1049 net.cpp:345] drop6 -> fc6 (in-place)
I1109 12:51:33.348412  1049 net.cpp:96] Setting up drop6
I1109 12:51:33.348419  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:33.348425  1049 layer_factory.hpp:78] Creating layer fc7
I1109 12:51:33.348435  1049 net.cpp:67] Creating Layer fc7
I1109 12:51:33.348441  1049 net.cpp:394] fc7 <- fc6
I1109 12:51:33.348449  1049 net.cpp:356] fc7 -> fc7
I1109 12:51:33.348460  1049 net.cpp:96] Setting up fc7
I1109 12:51:34.150074  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:34.150118  1049 layer_factory.hpp:78] Creating layer relu7
I1109 12:51:34.150131  1049 net.cpp:67] Creating Layer relu7
I1109 12:51:34.150140  1049 net.cpp:394] relu7 <- fc7
I1109 12:51:34.150149  1049 net.cpp:345] relu7 -> fc7 (in-place)
I1109 12:51:34.150161  1049 net.cpp:96] Setting up relu7
I1109 12:51:34.150182  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:34.150189  1049 layer_factory.hpp:78] Creating layer drop7
I1109 12:51:34.150200  1049 net.cpp:67] Creating Layer drop7
I1109 12:51:34.150207  1049 net.cpp:394] drop7 <- fc7
I1109 12:51:34.150214  1049 net.cpp:345] drop7 -> fc7 (in-place)
I1109 12:51:34.150223  1049 net.cpp:96] Setting up drop7
I1109 12:51:34.150229  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:34.150235  1049 layer_factory.hpp:78] Creating layer fc8_2
I1109 12:51:34.150244  1049 net.cpp:67] Creating Layer fc8_2
I1109 12:51:34.150254  1049 net.cpp:394] fc8_2 <- fc7
I1109 12:51:34.150262  1049 net.cpp:356] fc8_2 -> fc8_2
I1109 12:51:34.150272  1049 net.cpp:96] Setting up fc8_2
I1109 12:51:34.150686  1049 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:51:34.150701  1049 layer_factory.hpp:78] Creating layer loss
I1109 12:51:34.150717  1049 net.cpp:67] Creating Layer loss
I1109 12:51:34.150724  1049 net.cpp:394] loss <- fc8_2
I1109 12:51:34.150732  1049 net.cpp:394] loss <- label
I1109 12:51:34.150743  1049 net.cpp:356] loss -> (automatic)
I1109 12:51:34.150750  1049 net.cpp:96] Setting up loss
I1109 12:51:34.150763  1049 net.cpp:103] Top shape: 1 1 1 1 (1)
I1109 12:51:34.150771  1049 net.cpp:109]     with loss weight 1
I1109 12:51:34.150813  1049 net.cpp:170] loss needs backward computation.
I1109 12:51:34.150820  1049 net.cpp:170] fc8_2 needs backward computation.
I1109 12:51:34.150825  1049 net.cpp:170] drop7 needs backward computation.
I1109 12:51:34.150830  1049 net.cpp:170] relu7 needs backward computation.
I1109 12:51:34.150835  1049 net.cpp:170] fc7 needs backward computation.
I1109 12:51:34.150840  1049 net.cpp:170] drop6 needs backward computation.
I1109 12:51:34.150846  1049 net.cpp:170] relu6 needs backward computation.
I1109 12:51:34.150851  1049 net.cpp:170] fc6 needs backward computation.
I1109 12:51:34.150856  1049 net.cpp:170] pool5 needs backward computation.
I1109 12:51:34.150861  1049 net.cpp:170] relu5_3 needs backward computation.
I1109 12:51:34.150878  1049 net.cpp:170] conv5_3 needs backward computation.
I1109 12:51:34.150885  1049 net.cpp:170] relu5_2 needs backward computation.
I1109 12:51:34.150890  1049 net.cpp:170] conv5_2 needs backward computation.
I1109 12:51:34.150895  1049 net.cpp:170] relu5_1 needs backward computation.
I1109 12:51:34.150902  1049 net.cpp:170] conv5_1 needs backward computation.
I1109 12:51:34.150907  1049 net.cpp:170] pool4 needs backward computation.
I1109 12:51:34.150913  1049 net.cpp:170] relu4_3 needs backward computation.
I1109 12:51:34.150918  1049 net.cpp:170] conv4_3 needs backward computation.
I1109 12:51:34.150923  1049 net.cpp:170] relu4_2 needs backward computation.
I1109 12:51:34.150928  1049 net.cpp:170] conv4_2 needs backward computation.
I1109 12:51:34.150934  1049 net.cpp:170] relu4_1 needs backward computation.
I1109 12:51:34.150939  1049 net.cpp:170] conv4_1 needs backward computation.
I1109 12:51:34.150944  1049 net.cpp:170] pool3 needs backward computation.
I1109 12:51:34.150950  1049 net.cpp:170] relu3_3 needs backward computation.
I1109 12:51:34.150955  1049 net.cpp:170] conv3_3 needs backward computation.
I1109 12:51:34.150961  1049 net.cpp:170] relu3_2 needs backward computation.
I1109 12:51:34.150966  1049 net.cpp:170] conv3_2 needs backward computation.
I1109 12:51:34.150971  1049 net.cpp:170] relu3_1 needs backward computation.
I1109 12:51:34.150977  1049 net.cpp:170] conv3_1 needs backward computation.
I1109 12:51:34.150982  1049 net.cpp:170] pool2 needs backward computation.
I1109 12:51:34.150988  1049 net.cpp:170] relu2_2 needs backward computation.
I1109 12:51:34.150993  1049 net.cpp:170] conv2_2 needs backward computation.
I1109 12:51:34.150998  1049 net.cpp:170] relu2_1 needs backward computation.
I1109 12:51:34.151003  1049 net.cpp:170] conv2_1 needs backward computation.
I1109 12:51:34.151010  1049 net.cpp:170] pool1 needs backward computation.
I1109 12:51:34.151015  1049 net.cpp:170] relu1_2 needs backward computation.
I1109 12:51:34.151021  1049 net.cpp:170] conv1_2 needs backward computation.
I1109 12:51:34.151026  1049 net.cpp:170] relu1_1 needs backward computation.
I1109 12:51:34.151031  1049 net.cpp:170] conv1_1 needs backward computation.
I1109 12:51:34.151036  1049 net.cpp:172] data does not need backward computation.
I1109 12:51:34.151068  1049 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1109 12:51:34.151087  1049 net.cpp:219] Network initialization done.
I1109 12:51:34.151092  1049 net.cpp:220] Memory required for data: 921616484
I1109 12:51:34.152585  1049 solver.cpp:151] Creating test net (#0) specified by net file: task/inadcl_o/train_val.prototxt
I1109 12:51:34.152673  1049 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1109 12:51:34.153060  1049 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/inadcl_o/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1109 12:51:34.153317  1049 layer_factory.hpp:78] Creating layer data
I1109 12:51:34.153337  1049 net.cpp:67] Creating Layer data
I1109 12:51:34.153344  1049 net.cpp:356] data -> data
I1109 12:51:34.153357  1049 net.cpp:356] data -> label
I1109 12:51:34.153368  1049 net.cpp:96] Setting up data
I1109 12:51:34.153374  1049 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/inadcl_o/val.txt
I1109 12:51:34.153616  1049 image_data_layer.cpp:49] A total of 315 images.
I1109 12:51:34.168387  1049 image_data_layer.cpp:78] output data size: 8,3,224,224
I1109 12:51:34.169860  1049 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1109 12:51:34.169883  1049 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:51:34.169891  1049 layer_factory.hpp:78] Creating layer label_data_1_split
I1109 12:51:34.169911  1049 net.cpp:67] Creating Layer label_data_1_split
I1109 12:51:34.169917  1049 net.cpp:394] label_data_1_split <- label
I1109 12:51:34.169931  1049 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1109 12:51:34.169947  1049 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1109 12:51:34.169956  1049 net.cpp:96] Setting up label_data_1_split
I1109 12:51:34.169966  1049 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:51:34.169972  1049 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:51:34.169978  1049 layer_factory.hpp:78] Creating layer conv1_1
I1109 12:51:34.169989  1049 net.cpp:67] Creating Layer conv1_1
I1109 12:51:34.169996  1049 net.cpp:394] conv1_1 <- data
I1109 12:51:34.170004  1049 net.cpp:356] conv1_1 -> conv1_1
I1109 12:51:34.170014  1049 net.cpp:96] Setting up conv1_1
I1109 12:51:34.170310  1049 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:34.170336  1049 layer_factory.hpp:78] Creating layer relu1_1
I1109 12:51:34.170346  1049 net.cpp:67] Creating Layer relu1_1
I1109 12:51:34.170352  1049 net.cpp:394] relu1_1 <- conv1_1
I1109 12:51:34.170361  1049 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1109 12:51:34.170369  1049 net.cpp:96] Setting up relu1_1
I1109 12:51:34.170380  1049 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:34.170398  1049 layer_factory.hpp:78] Creating layer conv1_2
I1109 12:51:34.170409  1049 net.cpp:67] Creating Layer conv1_2
I1109 12:51:34.170414  1049 net.cpp:394] conv1_2 <- conv1_1
I1109 12:51:34.170423  1049 net.cpp:356] conv1_2 -> conv1_2
I1109 12:51:34.170433  1049 net.cpp:96] Setting up conv1_2
I1109 12:51:34.172340  1049 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:34.172365  1049 layer_factory.hpp:78] Creating layer relu1_2
I1109 12:51:34.172374  1049 net.cpp:67] Creating Layer relu1_2
I1109 12:51:34.172380  1049 net.cpp:394] relu1_2 <- conv1_2
I1109 12:51:34.172389  1049 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1109 12:51:34.172397  1049 net.cpp:96] Setting up relu1_2
I1109 12:51:34.172407  1049 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:34.172413  1049 layer_factory.hpp:78] Creating layer pool1
I1109 12:51:34.172422  1049 net.cpp:67] Creating Layer pool1
I1109 12:51:34.172428  1049 net.cpp:394] pool1 <- conv1_2
I1109 12:51:34.172436  1049 net.cpp:356] pool1 -> pool1
I1109 12:51:34.172444  1049 net.cpp:96] Setting up pool1
I1109 12:51:34.172456  1049 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1109 12:51:34.172462  1049 layer_factory.hpp:78] Creating layer conv2_1
I1109 12:51:34.172472  1049 net.cpp:67] Creating Layer conv2_1
I1109 12:51:34.172477  1049 net.cpp:394] conv2_1 <- pool1
I1109 12:51:34.172485  1049 net.cpp:356] conv2_1 -> conv2_1
I1109 12:51:34.172495  1049 net.cpp:96] Setting up conv2_1
I1109 12:51:34.176343  1049 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:34.176370  1049 layer_factory.hpp:78] Creating layer relu2_1
I1109 12:51:34.176381  1049 net.cpp:67] Creating Layer relu2_1
I1109 12:51:34.176388  1049 net.cpp:394] relu2_1 <- conv2_1
I1109 12:51:34.176396  1049 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1109 12:51:34.176405  1049 net.cpp:96] Setting up relu2_1
I1109 12:51:34.176415  1049 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:34.176421  1049 layer_factory.hpp:78] Creating layer conv2_2
I1109 12:51:34.176431  1049 net.cpp:67] Creating Layer conv2_2
I1109 12:51:34.176436  1049 net.cpp:394] conv2_2 <- conv2_1
I1109 12:51:34.176445  1049 net.cpp:356] conv2_2 -> conv2_2
I1109 12:51:34.176455  1049 net.cpp:96] Setting up conv2_2
I1109 12:51:34.183611  1049 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:34.183636  1049 layer_factory.hpp:78] Creating layer relu2_2
I1109 12:51:34.183646  1049 net.cpp:67] Creating Layer relu2_2
I1109 12:51:34.183651  1049 net.cpp:394] relu2_2 <- conv2_2
I1109 12:51:34.183660  1049 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1109 12:51:34.183670  1049 net.cpp:96] Setting up relu2_2
I1109 12:51:34.183679  1049 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:34.183686  1049 layer_factory.hpp:78] Creating layer pool2
I1109 12:51:34.183693  1049 net.cpp:67] Creating Layer pool2
I1109 12:51:34.183698  1049 net.cpp:394] pool2 <- conv2_2
I1109 12:51:34.183707  1049 net.cpp:356] pool2 -> pool2
I1109 12:51:34.183715  1049 net.cpp:96] Setting up pool2
I1109 12:51:34.183727  1049 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1109 12:51:34.183733  1049 layer_factory.hpp:78] Creating layer conv3_1
I1109 12:51:34.183743  1049 net.cpp:67] Creating Layer conv3_1
I1109 12:51:34.183748  1049 net.cpp:394] conv3_1 <- pool2
I1109 12:51:34.183756  1049 net.cpp:356] conv3_1 -> conv3_1
I1109 12:51:34.183765  1049 net.cpp:96] Setting up conv3_1
I1109 12:51:34.197929  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:34.197964  1049 layer_factory.hpp:78] Creating layer relu3_1
I1109 12:51:34.197975  1049 net.cpp:67] Creating Layer relu3_1
I1109 12:51:34.197983  1049 net.cpp:394] relu3_1 <- conv3_1
I1109 12:51:34.197993  1049 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1109 12:51:34.198003  1049 net.cpp:96] Setting up relu3_1
I1109 12:51:34.198012  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:34.198019  1049 layer_factory.hpp:78] Creating layer conv3_2
I1109 12:51:34.198029  1049 net.cpp:67] Creating Layer conv3_2
I1109 12:51:34.198035  1049 net.cpp:394] conv3_2 <- conv3_1
I1109 12:51:34.198056  1049 net.cpp:356] conv3_2 -> conv3_2
I1109 12:51:34.198067  1049 net.cpp:96] Setting up conv3_2
I1109 12:51:34.226726  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:34.226763  1049 layer_factory.hpp:78] Creating layer relu3_2
I1109 12:51:34.226775  1049 net.cpp:67] Creating Layer relu3_2
I1109 12:51:34.226783  1049 net.cpp:394] relu3_2 <- conv3_2
I1109 12:51:34.226796  1049 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1109 12:51:34.226807  1049 net.cpp:96] Setting up relu3_2
I1109 12:51:34.226819  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:34.226824  1049 layer_factory.hpp:78] Creating layer conv3_3
I1109 12:51:34.226837  1049 net.cpp:67] Creating Layer conv3_3
I1109 12:51:34.226843  1049 net.cpp:394] conv3_3 <- conv3_2
I1109 12:51:34.226855  1049 net.cpp:356] conv3_3 -> conv3_3
I1109 12:51:34.226866  1049 net.cpp:96] Setting up conv3_3
I1109 12:51:34.256279  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:34.256319  1049 layer_factory.hpp:78] Creating layer relu3_3
I1109 12:51:34.256331  1049 net.cpp:67] Creating Layer relu3_3
I1109 12:51:34.256338  1049 net.cpp:394] relu3_3 <- conv3_3
I1109 12:51:34.256352  1049 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1109 12:51:34.256364  1049 net.cpp:96] Setting up relu3_3
I1109 12:51:34.256374  1049 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:34.256381  1049 layer_factory.hpp:78] Creating layer pool3
I1109 12:51:34.256391  1049 net.cpp:67] Creating Layer pool3
I1109 12:51:34.256397  1049 net.cpp:394] pool3 <- conv3_3
I1109 12:51:34.256405  1049 net.cpp:356] pool3 -> pool3
I1109 12:51:34.256414  1049 net.cpp:96] Setting up pool3
I1109 12:51:34.256428  1049 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1109 12:51:34.256433  1049 layer_factory.hpp:78] Creating layer conv4_1
I1109 12:51:34.256446  1049 net.cpp:67] Creating Layer conv4_1
I1109 12:51:34.256453  1049 net.cpp:394] conv4_1 <- pool3
I1109 12:51:34.256460  1049 net.cpp:356] conv4_1 -> conv4_1
I1109 12:51:34.256470  1049 net.cpp:96] Setting up conv4_1
I1109 12:51:34.313390  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:34.313429  1049 layer_factory.hpp:78] Creating layer relu4_1
I1109 12:51:34.313443  1049 net.cpp:67] Creating Layer relu4_1
I1109 12:51:34.313452  1049 net.cpp:394] relu4_1 <- conv4_1
I1109 12:51:34.313464  1049 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1109 12:51:34.313477  1049 net.cpp:96] Setting up relu4_1
I1109 12:51:34.313488  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:34.313494  1049 layer_factory.hpp:78] Creating layer conv4_2
I1109 12:51:34.313504  1049 net.cpp:67] Creating Layer conv4_2
I1109 12:51:34.313509  1049 net.cpp:394] conv4_2 <- conv4_1
I1109 12:51:34.313521  1049 net.cpp:356] conv4_2 -> conv4_2
I1109 12:51:34.313531  1049 net.cpp:96] Setting up conv4_2
I1109 12:51:34.426861  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:34.426915  1049 layer_factory.hpp:78] Creating layer relu4_2
I1109 12:51:34.426929  1049 net.cpp:67] Creating Layer relu4_2
I1109 12:51:34.426937  1049 net.cpp:394] relu4_2 <- conv4_2
I1109 12:51:34.426947  1049 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1109 12:51:34.426959  1049 net.cpp:96] Setting up relu4_2
I1109 12:51:34.426970  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:34.426976  1049 layer_factory.hpp:78] Creating layer conv4_3
I1109 12:51:34.426990  1049 net.cpp:67] Creating Layer conv4_3
I1109 12:51:34.426995  1049 net.cpp:394] conv4_3 <- conv4_2
I1109 12:51:34.427003  1049 net.cpp:356] conv4_3 -> conv4_3
I1109 12:51:34.427016  1049 net.cpp:96] Setting up conv4_3
I1109 12:51:34.540184  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:34.540228  1049 layer_factory.hpp:78] Creating layer relu4_3
I1109 12:51:34.540241  1049 net.cpp:67] Creating Layer relu4_3
I1109 12:51:34.540249  1049 net.cpp:394] relu4_3 <- conv4_3
I1109 12:51:34.540259  1049 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1109 12:51:34.540274  1049 net.cpp:96] Setting up relu4_3
I1109 12:51:34.540287  1049 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:34.540308  1049 layer_factory.hpp:78] Creating layer pool4
I1109 12:51:34.540318  1049 net.cpp:67] Creating Layer pool4
I1109 12:51:34.540323  1049 net.cpp:394] pool4 <- conv4_3
I1109 12:51:34.540333  1049 net.cpp:356] pool4 -> pool4
I1109 12:51:34.540343  1049 net.cpp:96] Setting up pool4
I1109 12:51:34.540355  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:34.540361  1049 layer_factory.hpp:78] Creating layer conv5_1
I1109 12:51:34.540377  1049 net.cpp:67] Creating Layer conv5_1
I1109 12:51:34.540384  1049 net.cpp:394] conv5_1 <- pool4
I1109 12:51:34.540392  1049 net.cpp:356] conv5_1 -> conv5_1
I1109 12:51:34.540402  1049 net.cpp:96] Setting up conv5_1
I1109 12:51:34.654031  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:34.654073  1049 layer_factory.hpp:78] Creating layer relu5_1
I1109 12:51:34.654086  1049 net.cpp:67] Creating Layer relu5_1
I1109 12:51:34.654094  1049 net.cpp:394] relu5_1 <- conv5_1
I1109 12:51:34.654108  1049 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1109 12:51:34.654119  1049 net.cpp:96] Setting up relu5_1
I1109 12:51:34.654129  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:34.654135  1049 layer_factory.hpp:78] Creating layer conv5_2
I1109 12:51:34.654145  1049 net.cpp:67] Creating Layer conv5_2
I1109 12:51:34.654151  1049 net.cpp:394] conv5_2 <- conv5_1
I1109 12:51:34.654160  1049 net.cpp:356] conv5_2 -> conv5_2
I1109 12:51:34.654170  1049 net.cpp:96] Setting up conv5_2
I1109 12:51:34.767180  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:34.767225  1049 layer_factory.hpp:78] Creating layer relu5_2
I1109 12:51:34.767238  1049 net.cpp:67] Creating Layer relu5_2
I1109 12:51:34.767246  1049 net.cpp:394] relu5_2 <- conv5_2
I1109 12:51:34.767256  1049 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1109 12:51:34.767266  1049 net.cpp:96] Setting up relu5_2
I1109 12:51:34.767277  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:34.767283  1049 layer_factory.hpp:78] Creating layer conv5_3
I1109 12:51:34.767297  1049 net.cpp:67] Creating Layer conv5_3
I1109 12:51:34.767303  1049 net.cpp:394] conv5_3 <- conv5_2
I1109 12:51:34.767313  1049 net.cpp:356] conv5_3 -> conv5_3
I1109 12:51:34.767323  1049 net.cpp:96] Setting up conv5_3
I1109 12:51:34.881014  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:34.881062  1049 layer_factory.hpp:78] Creating layer relu5_3
I1109 12:51:34.881075  1049 net.cpp:67] Creating Layer relu5_3
I1109 12:51:34.881083  1049 net.cpp:394] relu5_3 <- conv5_3
I1109 12:51:34.881094  1049 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1109 12:51:34.881105  1049 net.cpp:96] Setting up relu5_3
I1109 12:51:34.881116  1049 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:34.881122  1049 layer_factory.hpp:78] Creating layer pool5
I1109 12:51:34.881152  1049 net.cpp:67] Creating Layer pool5
I1109 12:51:34.881160  1049 net.cpp:394] pool5 <- conv5_3
I1109 12:51:34.881172  1049 net.cpp:356] pool5 -> pool5
I1109 12:51:34.881182  1049 net.cpp:96] Setting up pool5
I1109 12:51:34.881196  1049 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1109 12:51:34.881203  1049 layer_factory.hpp:78] Creating layer fc6
I1109 12:51:34.881212  1049 net.cpp:67] Creating Layer fc6
I1109 12:51:34.881217  1049 net.cpp:394] fc6 <- pool5
I1109 12:51:34.881227  1049 net.cpp:356] fc6 -> fc6
I1109 12:51:34.881235  1049 net.cpp:96] Setting up fc6
I1109 12:51:39.783467  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:39.783512  1049 layer_factory.hpp:78] Creating layer relu6
I1109 12:51:39.783525  1049 net.cpp:67] Creating Layer relu6
I1109 12:51:39.783534  1049 net.cpp:394] relu6 <- fc6
I1109 12:51:39.783545  1049 net.cpp:345] relu6 -> fc6 (in-place)
I1109 12:51:39.783555  1049 net.cpp:96] Setting up relu6
I1109 12:51:39.783576  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:39.783582  1049 layer_factory.hpp:78] Creating layer drop6
I1109 12:51:39.783594  1049 net.cpp:67] Creating Layer drop6
I1109 12:51:39.783601  1049 net.cpp:394] drop6 <- fc6
I1109 12:51:39.783608  1049 net.cpp:345] drop6 -> fc6 (in-place)
I1109 12:51:39.783637  1049 net.cpp:96] Setting up drop6
I1109 12:51:39.783644  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:39.783650  1049 layer_factory.hpp:78] Creating layer fc7
I1109 12:51:39.783659  1049 net.cpp:67] Creating Layer fc7
I1109 12:51:39.783664  1049 net.cpp:394] fc7 <- fc6
I1109 12:51:39.783675  1049 net.cpp:356] fc7 -> fc7
I1109 12:51:39.783686  1049 net.cpp:96] Setting up fc7
I1109 12:51:40.586585  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:40.586632  1049 layer_factory.hpp:78] Creating layer relu7
I1109 12:51:40.586643  1049 net.cpp:67] Creating Layer relu7
I1109 12:51:40.586652  1049 net.cpp:394] relu7 <- fc7
I1109 12:51:40.586665  1049 net.cpp:345] relu7 -> fc7 (in-place)
I1109 12:51:40.586676  1049 net.cpp:96] Setting up relu7
I1109 12:51:40.586700  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:40.586707  1049 layer_factory.hpp:78] Creating layer drop7
I1109 12:51:40.586716  1049 net.cpp:67] Creating Layer drop7
I1109 12:51:40.586721  1049 net.cpp:394] drop7 <- fc7
I1109 12:51:40.586730  1049 net.cpp:345] drop7 -> fc7 (in-place)
I1109 12:51:40.586737  1049 net.cpp:96] Setting up drop7
I1109 12:51:40.586751  1049 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:51:40.586757  1049 layer_factory.hpp:78] Creating layer fc8_2
I1109 12:51:40.586769  1049 net.cpp:67] Creating Layer fc8_2
I1109 12:51:40.586776  1049 net.cpp:394] fc8_2 <- fc7
I1109 12:51:40.586784  1049 net.cpp:356] fc8_2 -> fc8_2
I1109 12:51:40.586796  1049 net.cpp:96] Setting up fc8_2
I1109 12:51:40.587203  1049 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:51:40.587221  1049 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1109 12:51:40.587230  1049 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1109 12:51:40.587235  1049 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1109 12:51:40.587244  1049 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1109 12:51:40.587255  1049 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1109 12:51:40.587263  1049 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1109 12:51:40.587270  1049 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:51:40.587276  1049 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:51:40.587281  1049 layer_factory.hpp:78] Creating layer loss
I1109 12:51:40.587292  1049 net.cpp:67] Creating Layer loss
I1109 12:51:40.587299  1049 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1109 12:51:40.587306  1049 net.cpp:394] loss <- label_data_1_split_0
I1109 12:51:40.587314  1049 net.cpp:356] loss -> (automatic)
I1109 12:51:40.587322  1049 net.cpp:96] Setting up loss
I1109 12:51:40.587334  1049 net.cpp:103] Top shape: 1 1 1 1 (1)
I1109 12:51:40.587340  1049 net.cpp:109]     with loss weight 1
I1109 12:51:40.587359  1049 layer_factory.hpp:78] Creating layer accuracy
I1109 12:51:40.587373  1049 net.cpp:67] Creating Layer accuracy
I1109 12:51:40.587379  1049 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1109 12:51:40.587386  1049 net.cpp:394] accuracy <- label_data_1_split_1
I1109 12:51:40.587394  1049 net.cpp:356] accuracy -> accuracy
I1109 12:51:40.587404  1049 net.cpp:96] Setting up accuracy
I1109 12:51:40.587415  1049 net.cpp:103] Top shape: 1 1 1 4 (4)
I1109 12:51:40.587421  1049 net.cpp:172] accuracy does not need backward computation.
I1109 12:51:40.587426  1049 net.cpp:170] loss needs backward computation.
I1109 12:51:40.587431  1049 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1109 12:51:40.587437  1049 net.cpp:170] fc8_2 needs backward computation.
I1109 12:51:40.587442  1049 net.cpp:170] drop7 needs backward computation.
I1109 12:51:40.587447  1049 net.cpp:170] relu7 needs backward computation.
I1109 12:51:40.587452  1049 net.cpp:170] fc7 needs backward computation.
I1109 12:51:40.587458  1049 net.cpp:170] drop6 needs backward computation.
I1109 12:51:40.587463  1049 net.cpp:170] relu6 needs backward computation.
I1109 12:51:40.587468  1049 net.cpp:170] fc6 needs backward computation.
I1109 12:51:40.587476  1049 net.cpp:170] pool5 needs backward computation.
I1109 12:51:40.587494  1049 net.cpp:170] relu5_3 needs backward computation.
I1109 12:51:40.587501  1049 net.cpp:170] conv5_3 needs backward computation.
I1109 12:51:40.587507  1049 net.cpp:170] relu5_2 needs backward computation.
I1109 12:51:40.587512  1049 net.cpp:170] conv5_2 needs backward computation.
I1109 12:51:40.587517  1049 net.cpp:170] relu5_1 needs backward computation.
I1109 12:51:40.587522  1049 net.cpp:170] conv5_1 needs backward computation.
I1109 12:51:40.587528  1049 net.cpp:170] pool4 needs backward computation.
I1109 12:51:40.587533  1049 net.cpp:170] relu4_3 needs backward computation.
I1109 12:51:40.587538  1049 net.cpp:170] conv4_3 needs backward computation.
I1109 12:51:40.587544  1049 net.cpp:170] relu4_2 needs backward computation.
I1109 12:51:40.587549  1049 net.cpp:170] conv4_2 needs backward computation.
I1109 12:51:40.587554  1049 net.cpp:170] relu4_1 needs backward computation.
I1109 12:51:40.587560  1049 net.cpp:170] conv4_1 needs backward computation.
I1109 12:51:40.587565  1049 net.cpp:170] pool3 needs backward computation.
I1109 12:51:40.587573  1049 net.cpp:170] relu3_3 needs backward computation.
I1109 12:51:40.587577  1049 net.cpp:170] conv3_3 needs backward computation.
I1109 12:51:40.587582  1049 net.cpp:170] relu3_2 needs backward computation.
I1109 12:51:40.587589  1049 net.cpp:170] conv3_2 needs backward computation.
I1109 12:51:40.587594  1049 net.cpp:170] relu3_1 needs backward computation.
I1109 12:51:40.587599  1049 net.cpp:170] conv3_1 needs backward computation.
I1109 12:51:40.587605  1049 net.cpp:170] pool2 needs backward computation.
I1109 12:51:40.587610  1049 net.cpp:170] relu2_2 needs backward computation.
I1109 12:51:40.587615  1049 net.cpp:170] conv2_2 needs backward computation.
I1109 12:51:40.587621  1049 net.cpp:170] relu2_1 needs backward computation.
I1109 12:51:40.587626  1049 net.cpp:170] conv2_1 needs backward computation.
I1109 12:51:40.587631  1049 net.cpp:170] pool1 needs backward computation.
I1109 12:51:40.587637  1049 net.cpp:170] relu1_2 needs backward computation.
I1109 12:51:40.587642  1049 net.cpp:170] conv1_2 needs backward computation.
I1109 12:51:40.587648  1049 net.cpp:170] relu1_1 needs backward computation.
I1109 12:51:40.587653  1049 net.cpp:170] conv1_1 needs backward computation.
I1109 12:51:40.587658  1049 net.cpp:172] label_data_1_split does not need backward computation.
I1109 12:51:40.587664  1049 net.cpp:172] data does not need backward computation.
I1109 12:51:40.587669  1049 net.cpp:208] This network produces output accuracy
I1109 12:51:40.587704  1049 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1109 12:51:40.587723  1049 net.cpp:219] Network initialization done.
I1109 12:51:40.587729  1049 net.cpp:220] Memory required for data: 921616692
I1109 12:51:40.587913  1049 solver.cpp:41] Solver scaffolding done.
I1109 12:51:40.587924  1049 caffe.cpp:115] Finetuning from task/inadcl_o/none/_iter_3000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077499
I1109 12:51:43.172829  1049 solver.cpp:160] Solving small
I1109 12:51:43.172864  1049 solver.cpp:161] Learning Rate Policy: step
I1109 12:51:44.513188  1049 solver.cpp:339] Snapshotting to _iter_0.caffemodel
I1109 12:51:46.893857  1049 solver.cpp:347] Snapshotting solver state to _iter_0.solverstate
I1109 12:51:49.758059  1049 solver.cpp:246] Iteration 0, loss = 0.541643
I1109 12:51:49.758112  1049 solver.cpp:264] Iteration 0, Testing net (#0)
I1109 12:51:54.928704  1049 solver.cpp:305] Test loss: 0.516231
I1109 12:51:54.928760  1049 solver.cpp:320]     Test net output #0: accuracy = 0.8211
I1109 12:51:54.928771  1049 solver.cpp:320]     Test net output #1: accuracy = 0.683908
I1109 12:51:54.928779  1049 solver.cpp:320]     Test net output #2: accuracy = 0.752504
I1109 12:51:54.928787  1049 solver.cpp:320]     Test net output #3: accuracy = 0.784483
I1109 12:51:54.928797  1049 solver.cpp:251] Optimization Done.
I1109 12:51:54.928802  1049 caffe.cpp:121] Optimization Done.
I1109 12:51:55.192004  1092 caffe.cpp:99] Use GPU with device ID 0
I1109 12:51:55.491902  1092 caffe.cpp:107] Starting Optimization
I1109 12:51:55.492051  1092 solver.cpp:32] Initializing solver from parameters: 
test_iter: 29
test_interval: 1
base_lr: 0
display: 10
max_iter: 0
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 200
solver_mode: GPU
test_compute_loss: true
net: "task/inadcl_o/train_val.prototxt"
I1109 12:51:55.492089  1092 solver.cpp:67] Creating training net from net file: task/inadcl_o/train_val.prototxt
I1109 12:51:55.493676  1092 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1109 12:51:55.493732  1092 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1109 12:51:55.494099  1092 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/inadcl_o/train.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1109 12:51:55.494331  1092 layer_factory.hpp:78] Creating layer data
I1109 12:51:55.494360  1092 net.cpp:67] Creating Layer data
I1109 12:51:55.494372  1092 net.cpp:356] data -> data
I1109 12:51:55.494396  1092 net.cpp:356] data -> label
I1109 12:51:55.494416  1092 net.cpp:96] Setting up data
I1109 12:51:55.494427  1092 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/inadcl_o/train.txt
I1109 12:51:55.508074  1092 image_data_layer.cpp:49] A total of 20637 images.
I1109 12:51:55.518812  1092 image_data_layer.cpp:78] output data size: 8,3,224,224
I1109 12:51:55.521193  1092 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1109 12:51:55.521216  1092 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:51:55.521230  1092 layer_factory.hpp:78] Creating layer conv1_1
I1109 12:51:55.521250  1092 net.cpp:67] Creating Layer conv1_1
I1109 12:51:55.521257  1092 net.cpp:394] conv1_1 <- data
I1109 12:51:55.521276  1092 net.cpp:356] conv1_1 -> conv1_1
I1109 12:51:55.521292  1092 net.cpp:96] Setting up conv1_1
I1109 12:51:55.547371  1092 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:55.547425  1092 layer_factory.hpp:78] Creating layer relu1_1
I1109 12:51:55.547443  1092 net.cpp:67] Creating Layer relu1_1
I1109 12:51:55.547451  1092 net.cpp:394] relu1_1 <- conv1_1
I1109 12:51:55.547461  1092 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1109 12:51:55.547476  1092 net.cpp:96] Setting up relu1_1
I1109 12:51:55.547490  1092 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:55.547497  1092 layer_factory.hpp:78] Creating layer conv1_2
I1109 12:51:55.547508  1092 net.cpp:67] Creating Layer conv1_2
I1109 12:51:55.547513  1092 net.cpp:394] conv1_2 <- conv1_1
I1109 12:51:55.547523  1092 net.cpp:356] conv1_2 -> conv1_2
I1109 12:51:55.547533  1092 net.cpp:96] Setting up conv1_2
I1109 12:51:55.549645  1092 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:55.549672  1092 layer_factory.hpp:78] Creating layer relu1_2
I1109 12:51:55.549684  1092 net.cpp:67] Creating Layer relu1_2
I1109 12:51:55.549690  1092 net.cpp:394] relu1_2 <- conv1_2
I1109 12:51:55.549697  1092 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1109 12:51:55.549706  1092 net.cpp:96] Setting up relu1_2
I1109 12:51:55.549716  1092 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:51:55.549723  1092 layer_factory.hpp:78] Creating layer pool1
I1109 12:51:55.549739  1092 net.cpp:67] Creating Layer pool1
I1109 12:51:55.549746  1092 net.cpp:394] pool1 <- conv1_2
I1109 12:51:55.549754  1092 net.cpp:356] pool1 -> pool1
I1109 12:51:55.549764  1092 net.cpp:96] Setting up pool1
I1109 12:51:55.549790  1092 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1109 12:51:55.549798  1092 layer_factory.hpp:78] Creating layer conv2_1
I1109 12:51:55.549810  1092 net.cpp:67] Creating Layer conv2_1
I1109 12:51:55.549816  1092 net.cpp:394] conv2_1 <- pool1
I1109 12:51:55.549824  1092 net.cpp:356] conv2_1 -> conv2_1
I1109 12:51:55.549834  1092 net.cpp:96] Setting up conv2_1
I1109 12:51:55.553617  1092 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:55.553647  1092 layer_factory.hpp:78] Creating layer relu2_1
I1109 12:51:55.553657  1092 net.cpp:67] Creating Layer relu2_1
I1109 12:51:55.553663  1092 net.cpp:394] relu2_1 <- conv2_1
I1109 12:51:55.553670  1092 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1109 12:51:55.553679  1092 net.cpp:96] Setting up relu2_1
I1109 12:51:55.553689  1092 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:55.553695  1092 layer_factory.hpp:78] Creating layer conv2_2
I1109 12:51:55.553710  1092 net.cpp:67] Creating Layer conv2_2
I1109 12:51:55.553716  1092 net.cpp:394] conv2_2 <- conv2_1
I1109 12:51:55.553725  1092 net.cpp:356] conv2_2 -> conv2_2
I1109 12:51:55.553735  1092 net.cpp:96] Setting up conv2_2
I1109 12:51:55.561100  1092 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:55.561126  1092 layer_factory.hpp:78] Creating layer relu2_2
I1109 12:51:55.561152  1092 net.cpp:67] Creating Layer relu2_2
I1109 12:51:55.561158  1092 net.cpp:394] relu2_2 <- conv2_2
I1109 12:51:55.561167  1092 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1109 12:51:55.561175  1092 net.cpp:96] Setting up relu2_2
I1109 12:51:55.561187  1092 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:51:55.561192  1092 layer_factory.hpp:78] Creating layer pool2
I1109 12:51:55.561420  1092 net.cpp:67] Creating Layer pool2
I1109 12:51:55.561445  1092 net.cpp:394] pool2 <- conv2_2
I1109 12:51:55.561465  1092 net.cpp:356] pool2 -> pool2
I1109 12:51:55.561480  1092 net.cpp:96] Setting up pool2
I1109 12:51:55.561496  1092 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1109 12:51:55.561502  1092 layer_factory.hpp:78] Creating layer conv3_1
I1109 12:51:55.561517  1092 net.cpp:67] Creating Layer conv3_1
I1109 12:51:55.561522  1092 net.cpp:394] conv3_1 <- pool2
I1109 12:51:55.561532  1092 net.cpp:356] conv3_1 -> conv3_1
I1109 12:51:55.561542  1092 net.cpp:96] Setting up conv3_1
I1109 12:51:55.576081  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:55.576118  1092 layer_factory.hpp:78] Creating layer relu3_1
I1109 12:51:55.576130  1092 net.cpp:67] Creating Layer relu3_1
I1109 12:51:55.576138  1092 net.cpp:394] relu3_1 <- conv3_1
I1109 12:51:55.576148  1092 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1109 12:51:55.576156  1092 net.cpp:96] Setting up relu3_1
I1109 12:51:55.576167  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:55.576174  1092 layer_factory.hpp:78] Creating layer conv3_2
I1109 12:51:55.576184  1092 net.cpp:67] Creating Layer conv3_2
I1109 12:51:55.576189  1092 net.cpp:394] conv3_2 <- conv3_1
I1109 12:51:55.576200  1092 net.cpp:356] conv3_2 -> conv3_2
I1109 12:51:55.576210  1092 net.cpp:96] Setting up conv3_2
I1109 12:51:55.605249  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:55.605283  1092 layer_factory.hpp:78] Creating layer relu3_2
I1109 12:51:55.605298  1092 net.cpp:67] Creating Layer relu3_2
I1109 12:51:55.605305  1092 net.cpp:394] relu3_2 <- conv3_2
I1109 12:51:55.605315  1092 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1109 12:51:55.605326  1092 net.cpp:96] Setting up relu3_2
I1109 12:51:55.605336  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:55.605343  1092 layer_factory.hpp:78] Creating layer conv3_3
I1109 12:51:55.605355  1092 net.cpp:67] Creating Layer conv3_3
I1109 12:51:55.605361  1092 net.cpp:394] conv3_3 <- conv3_2
I1109 12:51:55.605370  1092 net.cpp:356] conv3_3 -> conv3_3
I1109 12:51:55.605379  1092 net.cpp:96] Setting up conv3_3
I1109 12:51:55.633857  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:55.633893  1092 layer_factory.hpp:78] Creating layer relu3_3
I1109 12:51:55.633908  1092 net.cpp:67] Creating Layer relu3_3
I1109 12:51:55.633915  1092 net.cpp:394] relu3_3 <- conv3_3
I1109 12:51:55.633925  1092 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1109 12:51:55.633935  1092 net.cpp:96] Setting up relu3_3
I1109 12:51:55.633946  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:51:55.633952  1092 layer_factory.hpp:78] Creating layer pool3
I1109 12:51:55.633961  1092 net.cpp:67] Creating Layer pool3
I1109 12:51:55.633967  1092 net.cpp:394] pool3 <- conv3_3
I1109 12:51:55.633975  1092 net.cpp:356] pool3 -> pool3
I1109 12:51:55.633985  1092 net.cpp:96] Setting up pool3
I1109 12:51:55.633996  1092 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1109 12:51:55.634002  1092 layer_factory.hpp:78] Creating layer conv4_1
I1109 12:51:55.634019  1092 net.cpp:67] Creating Layer conv4_1
I1109 12:51:55.634027  1092 net.cpp:394] conv4_1 <- pool3
I1109 12:51:55.634045  1092 net.cpp:356] conv4_1 -> conv4_1
I1109 12:51:55.634057  1092 net.cpp:96] Setting up conv4_1
I1109 12:51:55.690968  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:55.690994  1092 layer_factory.hpp:78] Creating layer relu4_1
I1109 12:51:55.691004  1092 net.cpp:67] Creating Layer relu4_1
I1109 12:51:55.691009  1092 net.cpp:394] relu4_1 <- conv4_1
I1109 12:51:55.691020  1092 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1109 12:51:55.691030  1092 net.cpp:96] Setting up relu4_1
I1109 12:51:55.691040  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:55.691046  1092 layer_factory.hpp:78] Creating layer conv4_2
I1109 12:51:55.691056  1092 net.cpp:67] Creating Layer conv4_2
I1109 12:51:55.691061  1092 net.cpp:394] conv4_2 <- conv4_1
I1109 12:51:55.691069  1092 net.cpp:356] conv4_2 -> conv4_2
I1109 12:51:55.691078  1092 net.cpp:96] Setting up conv4_2
I1109 12:51:55.804393  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:55.804445  1092 layer_factory.hpp:78] Creating layer relu4_2
I1109 12:51:55.804460  1092 net.cpp:67] Creating Layer relu4_2
I1109 12:51:55.804466  1092 net.cpp:394] relu4_2 <- conv4_2
I1109 12:51:55.804476  1092 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1109 12:51:55.804487  1092 net.cpp:96] Setting up relu4_2
I1109 12:51:55.804497  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:55.804504  1092 layer_factory.hpp:78] Creating layer conv4_3
I1109 12:51:55.804517  1092 net.cpp:67] Creating Layer conv4_3
I1109 12:51:55.804523  1092 net.cpp:394] conv4_3 <- conv4_2
I1109 12:51:55.804533  1092 net.cpp:356] conv4_3 -> conv4_3
I1109 12:51:55.804543  1092 net.cpp:96] Setting up conv4_3
I1109 12:51:55.918442  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:55.918483  1092 layer_factory.hpp:78] Creating layer relu4_3
I1109 12:51:55.918496  1092 net.cpp:67] Creating Layer relu4_3
I1109 12:51:55.918503  1092 net.cpp:394] relu4_3 <- conv4_3
I1109 12:51:55.918516  1092 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1109 12:51:55.918529  1092 net.cpp:96] Setting up relu4_3
I1109 12:51:55.918539  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:51:55.918545  1092 layer_factory.hpp:78] Creating layer pool4
I1109 12:51:55.918555  1092 net.cpp:67] Creating Layer pool4
I1109 12:51:55.918560  1092 net.cpp:394] pool4 <- conv4_3
I1109 12:51:55.918567  1092 net.cpp:356] pool4 -> pool4
I1109 12:51:55.918576  1092 net.cpp:96] Setting up pool4
I1109 12:51:55.918588  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:55.918594  1092 layer_factory.hpp:78] Creating layer conv5_1
I1109 12:51:55.918607  1092 net.cpp:67] Creating Layer conv5_1
I1109 12:51:55.918613  1092 net.cpp:394] conv5_1 <- pool4
I1109 12:51:55.918624  1092 net.cpp:356] conv5_1 -> conv5_1
I1109 12:51:55.918638  1092 net.cpp:96] Setting up conv5_1
I1109 12:51:56.032820  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:56.032863  1092 layer_factory.hpp:78] Creating layer relu5_1
I1109 12:51:56.032877  1092 net.cpp:67] Creating Layer relu5_1
I1109 12:51:56.032884  1092 net.cpp:394] relu5_1 <- conv5_1
I1109 12:51:56.032902  1092 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1109 12:51:56.032915  1092 net.cpp:96] Setting up relu5_1
I1109 12:51:56.032925  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:56.032932  1092 layer_factory.hpp:78] Creating layer conv5_2
I1109 12:51:56.032943  1092 net.cpp:67] Creating Layer conv5_2
I1109 12:51:56.032948  1092 net.cpp:394] conv5_2 <- conv5_1
I1109 12:51:56.032961  1092 net.cpp:356] conv5_2 -> conv5_2
I1109 12:51:56.032974  1092 net.cpp:96] Setting up conv5_2
I1109 12:51:56.146785  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:56.146828  1092 layer_factory.hpp:78] Creating layer relu5_2
I1109 12:51:56.146842  1092 net.cpp:67] Creating Layer relu5_2
I1109 12:51:56.146849  1092 net.cpp:394] relu5_2 <- conv5_2
I1109 12:51:56.146862  1092 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1109 12:51:56.146873  1092 net.cpp:96] Setting up relu5_2
I1109 12:51:56.146884  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:56.146890  1092 layer_factory.hpp:78] Creating layer conv5_3
I1109 12:51:56.146900  1092 net.cpp:67] Creating Layer conv5_3
I1109 12:51:56.146905  1092 net.cpp:394] conv5_3 <- conv5_2
I1109 12:51:56.146914  1092 net.cpp:356] conv5_3 -> conv5_3
I1109 12:51:56.146924  1092 net.cpp:96] Setting up conv5_3
I1109 12:51:56.261095  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:56.261154  1092 layer_factory.hpp:78] Creating layer relu5_3
I1109 12:51:56.261169  1092 net.cpp:67] Creating Layer relu5_3
I1109 12:51:56.261178  1092 net.cpp:394] relu5_3 <- conv5_3
I1109 12:51:56.261190  1092 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1109 12:51:56.261203  1092 net.cpp:96] Setting up relu5_3
I1109 12:51:56.261214  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:51:56.261220  1092 layer_factory.hpp:78] Creating layer pool5
I1109 12:51:56.261243  1092 net.cpp:67] Creating Layer pool5
I1109 12:51:56.261250  1092 net.cpp:394] pool5 <- conv5_3
I1109 12:51:56.261261  1092 net.cpp:356] pool5 -> pool5
I1109 12:51:56.261272  1092 net.cpp:96] Setting up pool5
I1109 12:51:56.261286  1092 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1109 12:51:56.261291  1092 layer_factory.hpp:78] Creating layer fc6
I1109 12:51:56.261312  1092 net.cpp:67] Creating Layer fc6
I1109 12:51:56.261317  1092 net.cpp:394] fc6 <- pool5
I1109 12:51:56.261329  1092 net.cpp:356] fc6 -> fc6
I1109 12:51:56.261349  1092 net.cpp:96] Setting up fc6
I1109 12:52:01.172871  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:01.172916  1092 layer_factory.hpp:78] Creating layer relu6
I1109 12:52:01.172933  1092 net.cpp:67] Creating Layer relu6
I1109 12:52:01.172941  1092 net.cpp:394] relu6 <- fc6
I1109 12:52:01.172952  1092 net.cpp:345] relu6 -> fc6 (in-place)
I1109 12:52:01.172963  1092 net.cpp:96] Setting up relu6
I1109 12:52:01.172986  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:01.172993  1092 layer_factory.hpp:78] Creating layer drop6
I1109 12:52:01.173007  1092 net.cpp:67] Creating Layer drop6
I1109 12:52:01.173012  1092 net.cpp:394] drop6 <- fc6
I1109 12:52:01.173020  1092 net.cpp:345] drop6 -> fc6 (in-place)
I1109 12:52:01.173029  1092 net.cpp:96] Setting up drop6
I1109 12:52:01.173038  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:01.173043  1092 layer_factory.hpp:78] Creating layer fc7
I1109 12:52:01.173056  1092 net.cpp:67] Creating Layer fc7
I1109 12:52:01.173063  1092 net.cpp:394] fc7 <- fc6
I1109 12:52:01.173071  1092 net.cpp:356] fc7 -> fc7
I1109 12:52:01.173081  1092 net.cpp:96] Setting up fc7
I1109 12:52:01.974753  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:01.974795  1092 layer_factory.hpp:78] Creating layer relu7
I1109 12:52:01.974808  1092 net.cpp:67] Creating Layer relu7
I1109 12:52:01.974817  1092 net.cpp:394] relu7 <- fc7
I1109 12:52:01.974827  1092 net.cpp:345] relu7 -> fc7 (in-place)
I1109 12:52:01.974838  1092 net.cpp:96] Setting up relu7
I1109 12:52:01.974858  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:01.974864  1092 layer_factory.hpp:78] Creating layer drop7
I1109 12:52:01.974872  1092 net.cpp:67] Creating Layer drop7
I1109 12:52:01.974877  1092 net.cpp:394] drop7 <- fc7
I1109 12:52:01.974889  1092 net.cpp:345] drop7 -> fc7 (in-place)
I1109 12:52:01.974897  1092 net.cpp:96] Setting up drop7
I1109 12:52:01.974905  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:01.974910  1092 layer_factory.hpp:78] Creating layer fc8_2
I1109 12:52:01.974920  1092 net.cpp:67] Creating Layer fc8_2
I1109 12:52:01.974925  1092 net.cpp:394] fc8_2 <- fc7
I1109 12:52:01.974939  1092 net.cpp:356] fc8_2 -> fc8_2
I1109 12:52:01.974951  1092 net.cpp:96] Setting up fc8_2
I1109 12:52:01.975363  1092 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:52:01.975379  1092 layer_factory.hpp:78] Creating layer loss
I1109 12:52:01.975396  1092 net.cpp:67] Creating Layer loss
I1109 12:52:01.975404  1092 net.cpp:394] loss <- fc8_2
I1109 12:52:01.975410  1092 net.cpp:394] loss <- label
I1109 12:52:01.975421  1092 net.cpp:356] loss -> (automatic)
I1109 12:52:01.975430  1092 net.cpp:96] Setting up loss
I1109 12:52:01.975442  1092 net.cpp:103] Top shape: 1 1 1 1 (1)
I1109 12:52:01.975448  1092 net.cpp:109]     with loss weight 1
I1109 12:52:01.975491  1092 net.cpp:170] loss needs backward computation.
I1109 12:52:01.975497  1092 net.cpp:170] fc8_2 needs backward computation.
I1109 12:52:01.975502  1092 net.cpp:170] drop7 needs backward computation.
I1109 12:52:01.975507  1092 net.cpp:170] relu7 needs backward computation.
I1109 12:52:01.975512  1092 net.cpp:170] fc7 needs backward computation.
I1109 12:52:01.975517  1092 net.cpp:170] drop6 needs backward computation.
I1109 12:52:01.975522  1092 net.cpp:170] relu6 needs backward computation.
I1109 12:52:01.975528  1092 net.cpp:170] fc6 needs backward computation.
I1109 12:52:01.975533  1092 net.cpp:170] pool5 needs backward computation.
I1109 12:52:01.975543  1092 net.cpp:170] relu5_3 needs backward computation.
I1109 12:52:01.975559  1092 net.cpp:170] conv5_3 needs backward computation.
I1109 12:52:01.975565  1092 net.cpp:170] relu5_2 needs backward computation.
I1109 12:52:01.975571  1092 net.cpp:170] conv5_2 needs backward computation.
I1109 12:52:01.975576  1092 net.cpp:170] relu5_1 needs backward computation.
I1109 12:52:01.975581  1092 net.cpp:170] conv5_1 needs backward computation.
I1109 12:52:01.975587  1092 net.cpp:170] pool4 needs backward computation.
I1109 12:52:01.975594  1092 net.cpp:170] relu4_3 needs backward computation.
I1109 12:52:01.975599  1092 net.cpp:170] conv4_3 needs backward computation.
I1109 12:52:01.975605  1092 net.cpp:170] relu4_2 needs backward computation.
I1109 12:52:01.975610  1092 net.cpp:170] conv4_2 needs backward computation.
I1109 12:52:01.975615  1092 net.cpp:170] relu4_1 needs backward computation.
I1109 12:52:01.975620  1092 net.cpp:170] conv4_1 needs backward computation.
I1109 12:52:01.975626  1092 net.cpp:170] pool3 needs backward computation.
I1109 12:52:01.975631  1092 net.cpp:170] relu3_3 needs backward computation.
I1109 12:52:01.975637  1092 net.cpp:170] conv3_3 needs backward computation.
I1109 12:52:01.975643  1092 net.cpp:170] relu3_2 needs backward computation.
I1109 12:52:01.975648  1092 net.cpp:170] conv3_2 needs backward computation.
I1109 12:52:01.975654  1092 net.cpp:170] relu3_1 needs backward computation.
I1109 12:52:01.975659  1092 net.cpp:170] conv3_1 needs backward computation.
I1109 12:52:01.975664  1092 net.cpp:170] pool2 needs backward computation.
I1109 12:52:01.975671  1092 net.cpp:170] relu2_2 needs backward computation.
I1109 12:52:01.975675  1092 net.cpp:170] conv2_2 needs backward computation.
I1109 12:52:01.975682  1092 net.cpp:170] relu2_1 needs backward computation.
I1109 12:52:01.975687  1092 net.cpp:170] conv2_1 needs backward computation.
I1109 12:52:01.975692  1092 net.cpp:170] pool1 needs backward computation.
I1109 12:52:01.975697  1092 net.cpp:170] relu1_2 needs backward computation.
I1109 12:52:01.975703  1092 net.cpp:170] conv1_2 needs backward computation.
I1109 12:52:01.975708  1092 net.cpp:170] relu1_1 needs backward computation.
I1109 12:52:01.975713  1092 net.cpp:170] conv1_1 needs backward computation.
I1109 12:52:01.975719  1092 net.cpp:172] data does not need backward computation.
I1109 12:52:01.975750  1092 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1109 12:52:01.975769  1092 net.cpp:219] Network initialization done.
I1109 12:52:01.975775  1092 net.cpp:220] Memory required for data: 921616484
I1109 12:52:01.977277  1092 solver.cpp:151] Creating test net (#0) specified by net file: task/inadcl_o/train_val.prototxt
I1109 12:52:01.977366  1092 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1109 12:52:01.977752  1092 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/inadcl_o/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1109 12:52:01.977993  1092 layer_factory.hpp:78] Creating layer data
I1109 12:52:01.978010  1092 net.cpp:67] Creating Layer data
I1109 12:52:01.978018  1092 net.cpp:356] data -> data
I1109 12:52:01.978030  1092 net.cpp:356] data -> label
I1109 12:52:01.978041  1092 net.cpp:96] Setting up data
I1109 12:52:01.978049  1092 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/inadcl_o/val.txt
I1109 12:52:01.978293  1092 image_data_layer.cpp:49] A total of 315 images.
I1109 12:52:01.993093  1092 image_data_layer.cpp:78] output data size: 8,3,224,224
I1109 12:52:01.994989  1092 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1109 12:52:01.995013  1092 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:52:01.995021  1092 layer_factory.hpp:78] Creating layer label_data_1_split
I1109 12:52:01.995041  1092 net.cpp:67] Creating Layer label_data_1_split
I1109 12:52:01.995048  1092 net.cpp:394] label_data_1_split <- label
I1109 12:52:01.995059  1092 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1109 12:52:01.995074  1092 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1109 12:52:01.995084  1092 net.cpp:96] Setting up label_data_1_split
I1109 12:52:01.995093  1092 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:52:01.995100  1092 net.cpp:103] Top shape: 8 1 1 1 (8)
I1109 12:52:01.995106  1092 layer_factory.hpp:78] Creating layer conv1_1
I1109 12:52:01.995117  1092 net.cpp:67] Creating Layer conv1_1
I1109 12:52:01.995123  1092 net.cpp:394] conv1_1 <- data
I1109 12:52:01.995132  1092 net.cpp:356] conv1_1 -> conv1_1
I1109 12:52:01.995142  1092 net.cpp:96] Setting up conv1_1
I1109 12:52:01.995434  1092 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:52:01.995460  1092 layer_factory.hpp:78] Creating layer relu1_1
I1109 12:52:01.995471  1092 net.cpp:67] Creating Layer relu1_1
I1109 12:52:01.995476  1092 net.cpp:394] relu1_1 <- conv1_1
I1109 12:52:01.995484  1092 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1109 12:52:01.995493  1092 net.cpp:96] Setting up relu1_1
I1109 12:52:01.995503  1092 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:52:01.995522  1092 layer_factory.hpp:78] Creating layer conv1_2
I1109 12:52:01.995533  1092 net.cpp:67] Creating Layer conv1_2
I1109 12:52:01.995538  1092 net.cpp:394] conv1_2 <- conv1_1
I1109 12:52:01.995548  1092 net.cpp:356] conv1_2 -> conv1_2
I1109 12:52:01.995556  1092 net.cpp:96] Setting up conv1_2
I1109 12:52:01.997490  1092 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:52:01.997515  1092 layer_factory.hpp:78] Creating layer relu1_2
I1109 12:52:01.997525  1092 net.cpp:67] Creating Layer relu1_2
I1109 12:52:01.997531  1092 net.cpp:394] relu1_2 <- conv1_2
I1109 12:52:01.997539  1092 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1109 12:52:01.997548  1092 net.cpp:96] Setting up relu1_2
I1109 12:52:01.997558  1092 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1109 12:52:01.997565  1092 layer_factory.hpp:78] Creating layer pool1
I1109 12:52:01.997573  1092 net.cpp:67] Creating Layer pool1
I1109 12:52:01.997578  1092 net.cpp:394] pool1 <- conv1_2
I1109 12:52:01.997586  1092 net.cpp:356] pool1 -> pool1
I1109 12:52:01.997594  1092 net.cpp:96] Setting up pool1
I1109 12:52:01.997606  1092 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1109 12:52:01.997612  1092 layer_factory.hpp:78] Creating layer conv2_1
I1109 12:52:01.997622  1092 net.cpp:67] Creating Layer conv2_1
I1109 12:52:01.997627  1092 net.cpp:394] conv2_1 <- pool1
I1109 12:52:01.997635  1092 net.cpp:356] conv2_1 -> conv2_1
I1109 12:52:01.997644  1092 net.cpp:96] Setting up conv2_1
I1109 12:52:02.001492  1092 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:52:02.001518  1092 layer_factory.hpp:78] Creating layer relu2_1
I1109 12:52:02.001529  1092 net.cpp:67] Creating Layer relu2_1
I1109 12:52:02.001535  1092 net.cpp:394] relu2_1 <- conv2_1
I1109 12:52:02.001543  1092 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1109 12:52:02.001551  1092 net.cpp:96] Setting up relu2_1
I1109 12:52:02.001561  1092 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:52:02.001567  1092 layer_factory.hpp:78] Creating layer conv2_2
I1109 12:52:02.001577  1092 net.cpp:67] Creating Layer conv2_2
I1109 12:52:02.001582  1092 net.cpp:394] conv2_2 <- conv2_1
I1109 12:52:02.001590  1092 net.cpp:356] conv2_2 -> conv2_2
I1109 12:52:02.001600  1092 net.cpp:96] Setting up conv2_2
I1109 12:52:02.008716  1092 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:52:02.008740  1092 layer_factory.hpp:78] Creating layer relu2_2
I1109 12:52:02.008750  1092 net.cpp:67] Creating Layer relu2_2
I1109 12:52:02.008756  1092 net.cpp:394] relu2_2 <- conv2_2
I1109 12:52:02.008765  1092 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1109 12:52:02.008774  1092 net.cpp:96] Setting up relu2_2
I1109 12:52:02.008783  1092 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1109 12:52:02.008790  1092 layer_factory.hpp:78] Creating layer pool2
I1109 12:52:02.008798  1092 net.cpp:67] Creating Layer pool2
I1109 12:52:02.008803  1092 net.cpp:394] pool2 <- conv2_2
I1109 12:52:02.008811  1092 net.cpp:356] pool2 -> pool2
I1109 12:52:02.008821  1092 net.cpp:96] Setting up pool2
I1109 12:52:02.008831  1092 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1109 12:52:02.008837  1092 layer_factory.hpp:78] Creating layer conv3_1
I1109 12:52:02.008846  1092 net.cpp:67] Creating Layer conv3_1
I1109 12:52:02.008852  1092 net.cpp:394] conv3_1 <- pool2
I1109 12:52:02.008860  1092 net.cpp:356] conv3_1 -> conv3_1
I1109 12:52:02.008869  1092 net.cpp:96] Setting up conv3_1
I1109 12:52:02.023047  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:52:02.023082  1092 layer_factory.hpp:78] Creating layer relu3_1
I1109 12:52:02.023093  1092 net.cpp:67] Creating Layer relu3_1
I1109 12:52:02.023100  1092 net.cpp:394] relu3_1 <- conv3_1
I1109 12:52:02.023110  1092 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1109 12:52:02.023119  1092 net.cpp:96] Setting up relu3_1
I1109 12:52:02.023129  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:52:02.023138  1092 layer_factory.hpp:78] Creating layer conv3_2
I1109 12:52:02.023147  1092 net.cpp:67] Creating Layer conv3_2
I1109 12:52:02.023152  1092 net.cpp:394] conv3_2 <- conv3_1
I1109 12:52:02.023179  1092 net.cpp:356] conv3_2 -> conv3_2
I1109 12:52:02.023190  1092 net.cpp:96] Setting up conv3_2
I1109 12:52:02.051988  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:52:02.052026  1092 layer_factory.hpp:78] Creating layer relu3_2
I1109 12:52:02.052042  1092 net.cpp:67] Creating Layer relu3_2
I1109 12:52:02.052050  1092 net.cpp:394] relu3_2 <- conv3_2
I1109 12:52:02.052060  1092 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1109 12:52:02.052072  1092 net.cpp:96] Setting up relu3_2
I1109 12:52:02.052081  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:52:02.052088  1092 layer_factory.hpp:78] Creating layer conv3_3
I1109 12:52:02.052103  1092 net.cpp:67] Creating Layer conv3_3
I1109 12:52:02.052109  1092 net.cpp:394] conv3_3 <- conv3_2
I1109 12:52:02.052119  1092 net.cpp:356] conv3_3 -> conv3_3
I1109 12:52:02.052129  1092 net.cpp:96] Setting up conv3_3
I1109 12:52:02.081002  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:52:02.081039  1092 layer_factory.hpp:78] Creating layer relu3_3
I1109 12:52:02.081053  1092 net.cpp:67] Creating Layer relu3_3
I1109 12:52:02.081059  1092 net.cpp:394] relu3_3 <- conv3_3
I1109 12:52:02.081069  1092 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1109 12:52:02.081080  1092 net.cpp:96] Setting up relu3_3
I1109 12:52:02.081090  1092 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1109 12:52:02.081096  1092 layer_factory.hpp:78] Creating layer pool3
I1109 12:52:02.081111  1092 net.cpp:67] Creating Layer pool3
I1109 12:52:02.081118  1092 net.cpp:394] pool3 <- conv3_3
I1109 12:52:02.081126  1092 net.cpp:356] pool3 -> pool3
I1109 12:52:02.081159  1092 net.cpp:96] Setting up pool3
I1109 12:52:02.081173  1092 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1109 12:52:02.081181  1092 layer_factory.hpp:78] Creating layer conv4_1
I1109 12:52:02.081194  1092 net.cpp:67] Creating Layer conv4_1
I1109 12:52:02.081200  1092 net.cpp:394] conv4_1 <- pool3
I1109 12:52:02.081209  1092 net.cpp:356] conv4_1 -> conv4_1
I1109 12:52:02.081219  1092 net.cpp:96] Setting up conv4_1
I1109 12:52:02.138696  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:52:02.138736  1092 layer_factory.hpp:78] Creating layer relu4_1
I1109 12:52:02.138748  1092 net.cpp:67] Creating Layer relu4_1
I1109 12:52:02.138756  1092 net.cpp:394] relu4_1 <- conv4_1
I1109 12:52:02.138767  1092 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1109 12:52:02.138777  1092 net.cpp:96] Setting up relu4_1
I1109 12:52:02.138787  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:52:02.138794  1092 layer_factory.hpp:78] Creating layer conv4_2
I1109 12:52:02.138813  1092 net.cpp:67] Creating Layer conv4_2
I1109 12:52:02.138818  1092 net.cpp:394] conv4_2 <- conv4_1
I1109 12:52:02.138830  1092 net.cpp:356] conv4_2 -> conv4_2
I1109 12:52:02.138841  1092 net.cpp:96] Setting up conv4_2
I1109 12:52:02.252027  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:52:02.252079  1092 layer_factory.hpp:78] Creating layer relu4_2
I1109 12:52:02.252099  1092 net.cpp:67] Creating Layer relu4_2
I1109 12:52:02.252107  1092 net.cpp:394] relu4_2 <- conv4_2
I1109 12:52:02.252117  1092 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1109 12:52:02.252127  1092 net.cpp:96] Setting up relu4_2
I1109 12:52:02.252138  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:52:02.252145  1092 layer_factory.hpp:78] Creating layer conv4_3
I1109 12:52:02.252156  1092 net.cpp:67] Creating Layer conv4_3
I1109 12:52:02.252162  1092 net.cpp:394] conv4_3 <- conv4_2
I1109 12:52:02.252171  1092 net.cpp:356] conv4_3 -> conv4_3
I1109 12:52:02.252183  1092 net.cpp:96] Setting up conv4_3
I1109 12:52:02.365633  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:52:02.365676  1092 layer_factory.hpp:78] Creating layer relu4_3
I1109 12:52:02.365692  1092 net.cpp:67] Creating Layer relu4_3
I1109 12:52:02.365700  1092 net.cpp:394] relu4_3 <- conv4_3
I1109 12:52:02.365710  1092 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1109 12:52:02.365721  1092 net.cpp:96] Setting up relu4_3
I1109 12:52:02.365731  1092 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1109 12:52:02.365752  1092 layer_factory.hpp:78] Creating layer pool4
I1109 12:52:02.365766  1092 net.cpp:67] Creating Layer pool4
I1109 12:52:02.365772  1092 net.cpp:394] pool4 <- conv4_3
I1109 12:52:02.365779  1092 net.cpp:356] pool4 -> pool4
I1109 12:52:02.365789  1092 net.cpp:96] Setting up pool4
I1109 12:52:02.365803  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:52:02.365808  1092 layer_factory.hpp:78] Creating layer conv5_1
I1109 12:52:02.365823  1092 net.cpp:67] Creating Layer conv5_1
I1109 12:52:02.365829  1092 net.cpp:394] conv5_1 <- pool4
I1109 12:52:02.365839  1092 net.cpp:356] conv5_1 -> conv5_1
I1109 12:52:02.365849  1092 net.cpp:96] Setting up conv5_1
I1109 12:52:02.479013  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:52:02.479055  1092 layer_factory.hpp:78] Creating layer relu5_1
I1109 12:52:02.479068  1092 net.cpp:67] Creating Layer relu5_1
I1109 12:52:02.479076  1092 net.cpp:394] relu5_1 <- conv5_1
I1109 12:52:02.479089  1092 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1109 12:52:02.479101  1092 net.cpp:96] Setting up relu5_1
I1109 12:52:02.479112  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:52:02.479118  1092 layer_factory.hpp:78] Creating layer conv5_2
I1109 12:52:02.479128  1092 net.cpp:67] Creating Layer conv5_2
I1109 12:52:02.479133  1092 net.cpp:394] conv5_2 <- conv5_1
I1109 12:52:02.479142  1092 net.cpp:356] conv5_2 -> conv5_2
I1109 12:52:02.479152  1092 net.cpp:96] Setting up conv5_2
I1109 12:52:02.592676  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:52:02.592721  1092 layer_factory.hpp:78] Creating layer relu5_2
I1109 12:52:02.592735  1092 net.cpp:67] Creating Layer relu5_2
I1109 12:52:02.592741  1092 net.cpp:394] relu5_2 <- conv5_2
I1109 12:52:02.592752  1092 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1109 12:52:02.592762  1092 net.cpp:96] Setting up relu5_2
I1109 12:52:02.592773  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:52:02.592779  1092 layer_factory.hpp:78] Creating layer conv5_3
I1109 12:52:02.592792  1092 net.cpp:67] Creating Layer conv5_3
I1109 12:52:02.592798  1092 net.cpp:394] conv5_3 <- conv5_2
I1109 12:52:02.592808  1092 net.cpp:356] conv5_3 -> conv5_3
I1109 12:52:02.592818  1092 net.cpp:96] Setting up conv5_3
I1109 12:52:02.706154  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:52:02.706205  1092 layer_factory.hpp:78] Creating layer relu5_3
I1109 12:52:02.706219  1092 net.cpp:67] Creating Layer relu5_3
I1109 12:52:02.706228  1092 net.cpp:394] relu5_3 <- conv5_3
I1109 12:52:02.706238  1092 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1109 12:52:02.706248  1092 net.cpp:96] Setting up relu5_3
I1109 12:52:02.706259  1092 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1109 12:52:02.706266  1092 layer_factory.hpp:78] Creating layer pool5
I1109 12:52:02.706284  1092 net.cpp:67] Creating Layer pool5
I1109 12:52:02.706290  1092 net.cpp:394] pool5 <- conv5_3
I1109 12:52:02.706298  1092 net.cpp:356] pool5 -> pool5
I1109 12:52:02.706308  1092 net.cpp:96] Setting up pool5
I1109 12:52:02.706321  1092 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1109 12:52:02.706327  1092 layer_factory.hpp:78] Creating layer fc6
I1109 12:52:02.706339  1092 net.cpp:67] Creating Layer fc6
I1109 12:52:02.706346  1092 net.cpp:394] fc6 <- pool5
I1109 12:52:02.706353  1092 net.cpp:356] fc6 -> fc6
I1109 12:52:02.706363  1092 net.cpp:96] Setting up fc6
I1109 12:52:07.609874  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:07.609920  1092 layer_factory.hpp:78] Creating layer relu6
I1109 12:52:07.609938  1092 net.cpp:67] Creating Layer relu6
I1109 12:52:07.609948  1092 net.cpp:394] relu6 <- fc6
I1109 12:52:07.609959  1092 net.cpp:345] relu6 -> fc6 (in-place)
I1109 12:52:07.609971  1092 net.cpp:96] Setting up relu6
I1109 12:52:07.609990  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:07.609997  1092 layer_factory.hpp:78] Creating layer drop6
I1109 12:52:07.610008  1092 net.cpp:67] Creating Layer drop6
I1109 12:52:07.610014  1092 net.cpp:394] drop6 <- fc6
I1109 12:52:07.610023  1092 net.cpp:345] drop6 -> fc6 (in-place)
I1109 12:52:07.610046  1092 net.cpp:96] Setting up drop6
I1109 12:52:07.610054  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:07.610059  1092 layer_factory.hpp:78] Creating layer fc7
I1109 12:52:07.610069  1092 net.cpp:67] Creating Layer fc7
I1109 12:52:07.610074  1092 net.cpp:394] fc7 <- fc6
I1109 12:52:07.610085  1092 net.cpp:356] fc7 -> fc7
I1109 12:52:07.610095  1092 net.cpp:96] Setting up fc7
I1109 12:52:08.412701  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:08.412744  1092 layer_factory.hpp:78] Creating layer relu7
I1109 12:52:08.412756  1092 net.cpp:67] Creating Layer relu7
I1109 12:52:08.412763  1092 net.cpp:394] relu7 <- fc7
I1109 12:52:08.412777  1092 net.cpp:345] relu7 -> fc7 (in-place)
I1109 12:52:08.412788  1092 net.cpp:96] Setting up relu7
I1109 12:52:08.412809  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:08.412817  1092 layer_factory.hpp:78] Creating layer drop7
I1109 12:52:08.412825  1092 net.cpp:67] Creating Layer drop7
I1109 12:52:08.412830  1092 net.cpp:394] drop7 <- fc7
I1109 12:52:08.412838  1092 net.cpp:345] drop7 -> fc7 (in-place)
I1109 12:52:08.412847  1092 net.cpp:96] Setting up drop7
I1109 12:52:08.412853  1092 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1109 12:52:08.412865  1092 layer_factory.hpp:78] Creating layer fc8_2
I1109 12:52:08.412875  1092 net.cpp:67] Creating Layer fc8_2
I1109 12:52:08.412880  1092 net.cpp:394] fc8_2 <- fc7
I1109 12:52:08.412892  1092 net.cpp:356] fc8_2 -> fc8_2
I1109 12:52:08.412904  1092 net.cpp:96] Setting up fc8_2
I1109 12:52:08.413319  1092 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:52:08.413337  1092 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1109 12:52:08.413348  1092 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1109 12:52:08.413355  1092 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1109 12:52:08.413363  1092 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1109 12:52:08.413373  1092 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1109 12:52:08.413383  1092 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1109 12:52:08.413389  1092 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:52:08.413395  1092 net.cpp:103] Top shape: 8 2 1 1 (16)
I1109 12:52:08.413401  1092 layer_factory.hpp:78] Creating layer loss
I1109 12:52:08.413413  1092 net.cpp:67] Creating Layer loss
I1109 12:52:08.413419  1092 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1109 12:52:08.413425  1092 net.cpp:394] loss <- label_data_1_split_0
I1109 12:52:08.413434  1092 net.cpp:356] loss -> (automatic)
I1109 12:52:08.413440  1092 net.cpp:96] Setting up loss
I1109 12:52:08.413451  1092 net.cpp:103] Top shape: 1 1 1 1 (1)
I1109 12:52:08.413467  1092 net.cpp:109]     with loss weight 1
I1109 12:52:08.413487  1092 layer_factory.hpp:78] Creating layer accuracy
I1109 12:52:08.413501  1092 net.cpp:67] Creating Layer accuracy
I1109 12:52:08.413507  1092 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1109 12:52:08.413514  1092 net.cpp:394] accuracy <- label_data_1_split_1
I1109 12:52:08.413523  1092 net.cpp:356] accuracy -> accuracy
I1109 12:52:08.413532  1092 net.cpp:96] Setting up accuracy
I1109 12:52:08.413545  1092 net.cpp:103] Top shape: 1 1 1 4 (4)
I1109 12:52:08.413552  1092 net.cpp:172] accuracy does not need backward computation.
I1109 12:52:08.413558  1092 net.cpp:170] loss needs backward computation.
I1109 12:52:08.413563  1092 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1109 12:52:08.413568  1092 net.cpp:170] fc8_2 needs backward computation.
I1109 12:52:08.413581  1092 net.cpp:170] drop7 needs backward computation.
I1109 12:52:08.413588  1092 net.cpp:170] relu7 needs backward computation.
I1109 12:52:08.413593  1092 net.cpp:170] fc7 needs backward computation.
I1109 12:52:08.413597  1092 net.cpp:170] drop6 needs backward computation.
I1109 12:52:08.413604  1092 net.cpp:170] relu6 needs backward computation.
I1109 12:52:08.413609  1092 net.cpp:170] fc6 needs backward computation.
I1109 12:52:08.413614  1092 net.cpp:170] pool5 needs backward computation.
I1109 12:52:08.413630  1092 net.cpp:170] relu5_3 needs backward computation.
I1109 12:52:08.413636  1092 net.cpp:170] conv5_3 needs backward computation.
I1109 12:52:08.413642  1092 net.cpp:170] relu5_2 needs backward computation.
I1109 12:52:08.413647  1092 net.cpp:170] conv5_2 needs backward computation.
I1109 12:52:08.413653  1092 net.cpp:170] relu5_1 needs backward computation.
I1109 12:52:08.413658  1092 net.cpp:170] conv5_1 needs backward computation.
I1109 12:52:08.413666  1092 net.cpp:170] pool4 needs backward computation.
I1109 12:52:08.413671  1092 net.cpp:170] relu4_3 needs backward computation.
I1109 12:52:08.413676  1092 net.cpp:170] conv4_3 needs backward computation.
I1109 12:52:08.413681  1092 net.cpp:170] relu4_2 needs backward computation.
I1109 12:52:08.413687  1092 net.cpp:170] conv4_2 needs backward computation.
I1109 12:52:08.413702  1092 net.cpp:170] relu4_1 needs backward computation.
I1109 12:52:08.413707  1092 net.cpp:170] conv4_1 needs backward computation.
I1109 12:52:08.413713  1092 net.cpp:170] pool3 needs backward computation.
I1109 12:52:08.413719  1092 net.cpp:170] relu3_3 needs backward computation.
I1109 12:52:08.413724  1092 net.cpp:170] conv3_3 needs backward computation.
I1109 12:52:08.413730  1092 net.cpp:170] relu3_2 needs backward computation.
I1109 12:52:08.413735  1092 net.cpp:170] conv3_2 needs backward computation.
I1109 12:52:08.413740  1092 net.cpp:170] relu3_1 needs backward computation.
I1109 12:52:08.413746  1092 net.cpp:170] conv3_1 needs backward computation.
I1109 12:52:08.413753  1092 net.cpp:170] pool2 needs backward computation.
I1109 12:52:08.413758  1092 net.cpp:170] relu2_2 needs backward computation.
I1109 12:52:08.413763  1092 net.cpp:170] conv2_2 needs backward computation.
I1109 12:52:08.413769  1092 net.cpp:170] relu2_1 needs backward computation.
I1109 12:52:08.413774  1092 net.cpp:170] conv2_1 needs backward computation.
I1109 12:52:08.413780  1092 net.cpp:170] pool1 needs backward computation.
I1109 12:52:08.413791  1092 net.cpp:170] relu1_2 needs backward computation.
I1109 12:52:08.413797  1092 net.cpp:170] conv1_2 needs backward computation.
I1109 12:52:08.413802  1092 net.cpp:170] relu1_1 needs backward computation.
I1109 12:52:08.413808  1092 net.cpp:170] conv1_1 needs backward computation.
I1109 12:52:08.413813  1092 net.cpp:172] label_data_1_split does not need backward computation.
I1109 12:52:08.413820  1092 net.cpp:172] data does not need backward computation.
I1109 12:52:08.413825  1092 net.cpp:208] This network produces output accuracy
I1109 12:52:08.413859  1092 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1109 12:52:08.413875  1092 net.cpp:219] Network initialization done.
I1109 12:52:08.413882  1092 net.cpp:220] Memory required for data: 921616692
I1109 12:52:08.414067  1092 solver.cpp:41] Solver scaffolding done.
I1109 12:52:08.414080  1092 caffe.cpp:115] Finetuning from task/inadcl_o/none/_iter_3000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077499
I1109 12:52:10.845633  1092 solver.cpp:160] Solving small
I1109 12:52:10.845670  1092 solver.cpp:161] Learning Rate Policy: step
I1109 12:52:12.191898  1092 solver.cpp:339] Snapshotting to _iter_0.caffemodel
I1109 12:52:14.519816  1092 solver.cpp:347] Snapshotting solver state to _iter_0.solverstate
I1109 12:52:17.353309  1092 solver.cpp:246] Iteration 0, loss = 0.568052
I1109 12:52:17.353366  1092 solver.cpp:264] Iteration 0, Testing net (#0)
I1109 12:52:22.519274  1092 solver.cpp:305] Test loss: 0.534175
I1109 12:52:22.519332  1092 solver.cpp:320]     Test net output #0: accuracy = 0.77069
I1109 12:52:22.519345  1092 solver.cpp:320]     Test net output #1: accuracy = 0.678161
I1109 12:52:22.519352  1092 solver.cpp:320]     Test net output #2: accuracy = 0.724425
I1109 12:52:22.519361  1092 solver.cpp:320]     Test net output #3: accuracy = 0.741379
I1109 12:52:22.519369  1092 solver.cpp:251] Optimization Done.
I1109 12:52:22.519376  1092 caffe.cpp:121] Optimization Done.
