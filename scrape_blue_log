I1202 02:07:15.062911 22909 caffe.cpp:99] Use GPU with device ID 0
I1202 02:07:15.256134 22909 caffe.cpp:107] Starting Optimization
I1202 02:07:15.256228 22909 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:07:15.256253 22909 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:07:15.257030 22909 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:07:15.257060 22909 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:07:15.257261 22909 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:07:15.257386 22909 layer_factory.hpp:78] Creating layer data
I1202 02:07:15.257407 22909 net.cpp:67] Creating Layer data
I1202 02:07:15.257414 22909 net.cpp:356] data -> data
I1202 02:07:15.257432 22909 net.cpp:356] data -> label
I1202 02:07:15.257441 22909 net.cpp:96] Setting up data
I1202 02:07:15.257446 22909 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:07:15.271684 22909 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:07:15.282215 22909 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:07:15.284958 22909 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:07:15.284981 22909 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:07:15.284986 22909 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:07:15.285001 22909 net.cpp:67] Creating Layer conv1_1
I1202 02:07:15.285006 22909 net.cpp:394] conv1_1 <- data
I1202 02:07:15.285018 22909 net.cpp:356] conv1_1 -> conv1_1
I1202 02:07:15.285028 22909 net.cpp:96] Setting up conv1_1
I1202 02:07:15.427433 22909 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:07:15.427474 22909 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:07:15.427486 22909 net.cpp:67] Creating Layer relu1_1
I1202 02:07:15.427491 22909 net.cpp:394] relu1_1 <- conv1_1
I1202 02:07:15.427497 22909 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:07:15.427505 22909 net.cpp:96] Setting up relu1_1
I1202 02:07:15.427515 22909 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:07:15.427518 22909 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:07:15.427525 22909 net.cpp:67] Creating Layer conv1_2
I1202 02:07:15.427528 22909 net.cpp:394] conv1_2 <- conv1_1
I1202 02:07:15.427532 22909 net.cpp:356] conv1_2 -> conv1_2
I1202 02:07:15.427539 22909 net.cpp:96] Setting up conv1_2
I1202 02:07:15.428606 22909 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:07:15.428618 22909 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:07:15.428623 22909 net.cpp:67] Creating Layer relu1_2
I1202 02:07:15.428627 22909 net.cpp:394] relu1_2 <- conv1_2
I1202 02:07:15.428632 22909 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:07:15.428637 22909 net.cpp:96] Setting up relu1_2
I1202 02:07:15.428642 22909 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:07:15.428644 22909 layer_factory.hpp:78] Creating layer pool1
I1202 02:07:15.428653 22909 net.cpp:67] Creating Layer pool1
I1202 02:07:15.428657 22909 net.cpp:394] pool1 <- conv1_2
I1202 02:07:15.428661 22909 net.cpp:356] pool1 -> pool1
I1202 02:07:15.428666 22909 net.cpp:96] Setting up pool1
I1202 02:07:15.428683 22909 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:07:15.428686 22909 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:07:15.428692 22909 net.cpp:67] Creating Layer conv2_1
I1202 02:07:15.428696 22909 net.cpp:394] conv2_1 <- pool1
I1202 02:07:15.428700 22909 net.cpp:356] conv2_1 -> conv2_1
I1202 02:07:15.428705 22909 net.cpp:96] Setting up conv2_1
I1202 02:07:15.430627 22909 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:07:15.430641 22909 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:07:15.430646 22909 net.cpp:67] Creating Layer relu2_1
I1202 02:07:15.430649 22909 net.cpp:394] relu2_1 <- conv2_1
I1202 02:07:15.430654 22909 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:07:15.430658 22909 net.cpp:96] Setting up relu2_1
I1202 02:07:15.430663 22909 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:07:15.430666 22909 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:07:15.430673 22909 net.cpp:67] Creating Layer conv2_2
I1202 02:07:15.430676 22909 net.cpp:394] conv2_2 <- conv2_1
I1202 02:07:15.430681 22909 net.cpp:356] conv2_2 -> conv2_2
I1202 02:07:15.430686 22909 net.cpp:96] Setting up conv2_2
I1202 02:07:15.434453 22909 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:07:15.434465 22909 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:07:15.434470 22909 net.cpp:67] Creating Layer relu2_2
I1202 02:07:15.434474 22909 net.cpp:394] relu2_2 <- conv2_2
I1202 02:07:15.434478 22909 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:07:15.434483 22909 net.cpp:96] Setting up relu2_2
I1202 02:07:15.434489 22909 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:07:15.434499 22909 layer_factory.hpp:78] Creating layer pool2
I1202 02:07:15.434505 22909 net.cpp:67] Creating Layer pool2
I1202 02:07:15.434509 22909 net.cpp:394] pool2 <- conv2_2
I1202 02:07:15.434514 22909 net.cpp:356] pool2 -> pool2
I1202 02:07:15.434517 22909 net.cpp:96] Setting up pool2
I1202 02:07:15.434523 22909 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:07:15.434526 22909 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:07:15.434532 22909 net.cpp:67] Creating Layer conv3_1
I1202 02:07:15.434535 22909 net.cpp:394] conv3_1 <- pool2
I1202 02:07:15.434540 22909 net.cpp:356] conv3_1 -> conv3_1
I1202 02:07:15.434545 22909 net.cpp:96] Setting up conv3_1
I1202 02:07:15.441953 22909 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:07:15.441969 22909 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:07:15.441974 22909 net.cpp:67] Creating Layer relu3_1
I1202 02:07:15.441977 22909 net.cpp:394] relu3_1 <- conv3_1
I1202 02:07:15.441982 22909 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:07:15.441987 22909 net.cpp:96] Setting up relu3_1
I1202 02:07:15.441992 22909 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:07:15.441994 22909 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:07:15.441999 22909 net.cpp:67] Creating Layer conv3_2
I1202 02:07:15.442003 22909 net.cpp:394] conv3_2 <- conv3_1
I1202 02:07:15.442008 22909 net.cpp:356] conv3_2 -> conv3_2
I1202 02:07:15.442013 22909 net.cpp:96] Setting up conv3_2
I1202 02:07:15.456938 22909 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:07:15.456962 22909 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:07:15.456972 22909 net.cpp:67] Creating Layer relu3_2
I1202 02:07:15.456977 22909 net.cpp:394] relu3_2 <- conv3_2
I1202 02:07:15.456984 22909 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:07:15.456990 22909 net.cpp:96] Setting up relu3_2
I1202 02:07:15.456995 22909 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:07:15.456998 22909 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:07:15.457006 22909 net.cpp:67] Creating Layer conv3_3
I1202 02:07:15.457010 22909 net.cpp:394] conv3_3 <- conv3_2
I1202 02:07:15.457015 22909 net.cpp:356] conv3_3 -> conv3_3
I1202 02:07:15.457020 22909 net.cpp:96] Setting up conv3_3
I1202 02:07:15.471758 22909 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:07:15.471773 22909 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:07:15.471783 22909 net.cpp:67] Creating Layer relu3_3
I1202 02:07:15.471786 22909 net.cpp:394] relu3_3 <- conv3_3
I1202 02:07:15.471791 22909 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:07:15.471797 22909 net.cpp:96] Setting up relu3_3
I1202 02:07:15.471802 22909 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:07:15.471806 22909 layer_factory.hpp:78] Creating layer pool3
I1202 02:07:15.471812 22909 net.cpp:67] Creating Layer pool3
I1202 02:07:15.471815 22909 net.cpp:394] pool3 <- conv3_3
I1202 02:07:15.471819 22909 net.cpp:356] pool3 -> pool3
I1202 02:07:15.471824 22909 net.cpp:96] Setting up pool3
I1202 02:07:15.471832 22909 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:07:15.471835 22909 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:07:15.471843 22909 net.cpp:67] Creating Layer conv4_1
I1202 02:07:15.471845 22909 net.cpp:394] conv4_1 <- pool3
I1202 02:07:15.471850 22909 net.cpp:356] conv4_1 -> conv4_1
I1202 02:07:15.471855 22909 net.cpp:96] Setting up conv4_1
I1202 02:07:15.501040 22909 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:07:15.501063 22909 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:07:15.501071 22909 net.cpp:67] Creating Layer relu4_1
I1202 02:07:15.501075 22909 net.cpp:394] relu4_1 <- conv4_1
I1202 02:07:15.501083 22909 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:07:15.501091 22909 net.cpp:96] Setting up relu4_1
I1202 02:07:15.501096 22909 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:07:15.501101 22909 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:07:15.501106 22909 net.cpp:67] Creating Layer conv4_2
I1202 02:07:15.501109 22909 net.cpp:394] conv4_2 <- conv4_1
I1202 02:07:15.501126 22909 net.cpp:356] conv4_2 -> conv4_2
I1202 02:07:15.501132 22909 net.cpp:96] Setting up conv4_2
I1202 02:07:15.559136 22909 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:07:15.559165 22909 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:07:15.559173 22909 net.cpp:67] Creating Layer relu4_2
I1202 02:07:15.559178 22909 net.cpp:394] relu4_2 <- conv4_2
I1202 02:07:15.559185 22909 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:07:15.559191 22909 net.cpp:96] Setting up relu4_2
I1202 02:07:15.559197 22909 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:07:15.559201 22909 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:07:15.559208 22909 net.cpp:67] Creating Layer conv4_3
I1202 02:07:15.559211 22909 net.cpp:394] conv4_3 <- conv4_2
I1202 02:07:15.559216 22909 net.cpp:356] conv4_3 -> conv4_3
I1202 02:07:15.559221 22909 net.cpp:96] Setting up conv4_3
I1202 02:07:15.617912 22909 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:07:15.617933 22909 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:07:15.617941 22909 net.cpp:67] Creating Layer relu4_3
I1202 02:07:15.617945 22909 net.cpp:394] relu4_3 <- conv4_3
I1202 02:07:15.617954 22909 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:07:15.617960 22909 net.cpp:96] Setting up relu4_3
I1202 02:07:15.617966 22909 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:07:15.617969 22909 layer_factory.hpp:78] Creating layer pool4
I1202 02:07:15.617975 22909 net.cpp:67] Creating Layer pool4
I1202 02:07:15.617979 22909 net.cpp:394] pool4 <- conv4_3
I1202 02:07:15.617983 22909 net.cpp:356] pool4 -> pool4
I1202 02:07:15.617988 22909 net.cpp:96] Setting up pool4
I1202 02:07:15.617996 22909 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:07:15.618000 22909 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:07:15.618006 22909 net.cpp:67] Creating Layer conv5_1
I1202 02:07:15.618010 22909 net.cpp:394] conv5_1 <- pool4
I1202 02:07:15.618016 22909 net.cpp:356] conv5_1 -> conv5_1
I1202 02:07:15.618023 22909 net.cpp:96] Setting up conv5_1
I1202 02:07:15.675993 22909 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:07:15.676017 22909 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:07:15.676025 22909 net.cpp:67] Creating Layer relu5_1
I1202 02:07:15.676030 22909 net.cpp:394] relu5_1 <- conv5_1
I1202 02:07:15.676043 22909 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:07:15.676050 22909 net.cpp:96] Setting up relu5_1
I1202 02:07:15.676055 22909 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:07:15.676059 22909 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:07:15.676065 22909 net.cpp:67] Creating Layer conv5_2
I1202 02:07:15.676069 22909 net.cpp:394] conv5_2 <- conv5_1
I1202 02:07:15.676074 22909 net.cpp:356] conv5_2 -> conv5_2
I1202 02:07:15.676080 22909 net.cpp:96] Setting up conv5_2
I1202 02:07:15.733723 22909 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:07:15.733749 22909 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:07:15.733757 22909 net.cpp:67] Creating Layer relu5_2
I1202 02:07:15.733762 22909 net.cpp:394] relu5_2 <- conv5_2
I1202 02:07:15.733770 22909 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:07:15.733777 22909 net.cpp:96] Setting up relu5_2
I1202 02:07:15.733783 22909 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:07:15.733785 22909 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:07:15.733790 22909 net.cpp:67] Creating Layer conv5_3
I1202 02:07:15.733793 22909 net.cpp:394] conv5_3 <- conv5_2
I1202 02:07:15.733798 22909 net.cpp:356] conv5_3 -> conv5_3
I1202 02:07:15.733804 22909 net.cpp:96] Setting up conv5_3
I1202 02:07:15.791523 22909 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:07:15.791548 22909 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:07:15.791556 22909 net.cpp:67] Creating Layer relu5_3
I1202 02:07:15.791560 22909 net.cpp:394] relu5_3 <- conv5_3
I1202 02:07:15.791570 22909 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:07:15.791578 22909 net.cpp:96] Setting up relu5_3
I1202 02:07:15.791584 22909 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:07:15.791596 22909 layer_factory.hpp:78] Creating layer pool5
I1202 02:07:15.791602 22909 net.cpp:67] Creating Layer pool5
I1202 02:07:15.791605 22909 net.cpp:394] pool5 <- conv5_3
I1202 02:07:15.791611 22909 net.cpp:356] pool5 -> pool5
I1202 02:07:15.791616 22909 net.cpp:96] Setting up pool5
I1202 02:07:15.791625 22909 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:07:15.791627 22909 layer_factory.hpp:78] Creating layer fc6
I1202 02:07:15.791641 22909 net.cpp:67] Creating Layer fc6
I1202 02:07:15.791645 22909 net.cpp:394] fc6 <- pool5
I1202 02:07:15.791651 22909 net.cpp:356] fc6 -> fc6
I1202 02:07:15.791656 22909 net.cpp:96] Setting up fc6
I1202 02:07:18.290818 22909 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:07:18.290848 22909 layer_factory.hpp:78] Creating layer relu6
I1202 02:07:18.290858 22909 net.cpp:67] Creating Layer relu6
I1202 02:07:18.290863 22909 net.cpp:394] relu6 <- fc6
I1202 02:07:18.290870 22909 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:07:18.290876 22909 net.cpp:96] Setting up relu6
I1202 02:07:18.290891 22909 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:07:18.290894 22909 layer_factory.hpp:78] Creating layer drop6
I1202 02:07:18.290901 22909 net.cpp:67] Creating Layer drop6
I1202 02:07:18.290904 22909 net.cpp:394] drop6 <- fc6
I1202 02:07:18.290909 22909 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:07:18.290913 22909 net.cpp:96] Setting up drop6
I1202 02:07:18.290917 22909 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:07:18.290920 22909 layer_factory.hpp:78] Creating layer fc7
I1202 02:07:18.290926 22909 net.cpp:67] Creating Layer fc7
I1202 02:07:18.290930 22909 net.cpp:394] fc7 <- fc6
I1202 02:07:18.290935 22909 net.cpp:356] fc7 -> fc7
I1202 02:07:18.290940 22909 net.cpp:96] Setting up fc7
I1202 02:07:18.699445 22909 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:07:18.699477 22909 layer_factory.hpp:78] Creating layer relu7
I1202 02:07:18.699486 22909 net.cpp:67] Creating Layer relu7
I1202 02:07:18.699489 22909 net.cpp:394] relu7 <- fc7
I1202 02:07:18.699496 22909 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:07:18.699503 22909 net.cpp:96] Setting up relu7
I1202 02:07:18.699517 22909 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:07:18.699520 22909 layer_factory.hpp:78] Creating layer drop7
I1202 02:07:18.699527 22909 net.cpp:67] Creating Layer drop7
I1202 02:07:18.699532 22909 net.cpp:394] drop7 <- fc7
I1202 02:07:18.699535 22909 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:07:18.699540 22909 net.cpp:96] Setting up drop7
I1202 02:07:18.699543 22909 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:07:18.699547 22909 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:07:18.699551 22909 net.cpp:67] Creating Layer fc8_2
I1202 02:07:18.699554 22909 net.cpp:394] fc8_2 <- fc7
I1202 02:07:18.699560 22909 net.cpp:356] fc8_2 -> fc8_2
I1202 02:07:18.699566 22909 net.cpp:96] Setting up fc8_2
I1202 02:07:18.699786 22909 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:07:18.699795 22909 layer_factory.hpp:78] Creating layer loss
I1202 02:07:18.699802 22909 net.cpp:67] Creating Layer loss
I1202 02:07:18.699805 22909 net.cpp:394] loss <- fc8_2
I1202 02:07:18.699810 22909 net.cpp:394] loss <- label
I1202 02:07:18.699818 22909 net.cpp:356] loss -> (automatic)
I1202 02:07:18.699822 22909 net.cpp:96] Setting up loss
I1202 02:07:18.699831 22909 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:07:18.699834 22909 net.cpp:109]     with loss weight 1
I1202 02:07:18.699869 22909 net.cpp:170] loss needs backward computation.
I1202 02:07:18.699873 22909 net.cpp:170] fc8_2 needs backward computation.
I1202 02:07:18.699878 22909 net.cpp:170] drop7 needs backward computation.
I1202 02:07:18.699880 22909 net.cpp:170] relu7 needs backward computation.
I1202 02:07:18.699883 22909 net.cpp:170] fc7 needs backward computation.
I1202 02:07:18.699885 22909 net.cpp:170] drop6 needs backward computation.
I1202 02:07:18.699888 22909 net.cpp:170] relu6 needs backward computation.
I1202 02:07:18.699892 22909 net.cpp:170] fc6 needs backward computation.
I1202 02:07:18.699903 22909 net.cpp:170] pool5 needs backward computation.
I1202 02:07:18.699909 22909 net.cpp:170] relu5_3 needs backward computation.
I1202 02:07:18.699913 22909 net.cpp:170] conv5_3 needs backward computation.
I1202 02:07:18.699915 22909 net.cpp:170] relu5_2 needs backward computation.
I1202 02:07:18.699918 22909 net.cpp:170] conv5_2 needs backward computation.
I1202 02:07:18.699921 22909 net.cpp:170] relu5_1 needs backward computation.
I1202 02:07:18.699924 22909 net.cpp:170] conv5_1 needs backward computation.
I1202 02:07:18.699928 22909 net.cpp:170] pool4 needs backward computation.
I1202 02:07:18.699930 22909 net.cpp:170] relu4_3 needs backward computation.
I1202 02:07:18.699934 22909 net.cpp:170] conv4_3 needs backward computation.
I1202 02:07:18.699936 22909 net.cpp:170] relu4_2 needs backward computation.
I1202 02:07:18.699939 22909 net.cpp:170] conv4_2 needs backward computation.
I1202 02:07:18.699941 22909 net.cpp:170] relu4_1 needs backward computation.
I1202 02:07:18.699944 22909 net.cpp:170] conv4_1 needs backward computation.
I1202 02:07:18.699947 22909 net.cpp:170] pool3 needs backward computation.
I1202 02:07:18.699950 22909 net.cpp:170] relu3_3 needs backward computation.
I1202 02:07:18.699952 22909 net.cpp:170] conv3_3 needs backward computation.
I1202 02:07:18.699955 22909 net.cpp:170] relu3_2 needs backward computation.
I1202 02:07:18.699959 22909 net.cpp:170] conv3_2 needs backward computation.
I1202 02:07:18.699961 22909 net.cpp:170] relu3_1 needs backward computation.
I1202 02:07:18.699964 22909 net.cpp:170] conv3_1 needs backward computation.
I1202 02:07:18.699966 22909 net.cpp:170] pool2 needs backward computation.
I1202 02:07:18.699970 22909 net.cpp:170] relu2_2 needs backward computation.
I1202 02:07:18.699972 22909 net.cpp:170] conv2_2 needs backward computation.
I1202 02:07:18.699975 22909 net.cpp:170] relu2_1 needs backward computation.
I1202 02:07:18.699977 22909 net.cpp:170] conv2_1 needs backward computation.
I1202 02:07:18.699980 22909 net.cpp:170] pool1 needs backward computation.
I1202 02:07:18.699983 22909 net.cpp:170] relu1_2 needs backward computation.
I1202 02:07:18.699986 22909 net.cpp:170] conv1_2 needs backward computation.
I1202 02:07:18.699988 22909 net.cpp:170] relu1_1 needs backward computation.
I1202 02:07:18.699991 22909 net.cpp:170] conv1_1 needs backward computation.
I1202 02:07:18.699995 22909 net.cpp:172] data does not need backward computation.
I1202 02:07:18.700012 22909 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:07:18.700019 22909 net.cpp:219] Network initialization done.
I1202 02:07:18.700022 22909 net.cpp:220] Memory required for data: 3686465924
I1202 02:07:18.700867 22909 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:07:18.700911 22909 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:07:18.701122 22909 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:07:18.701267 22909 layer_factory.hpp:78] Creating layer data
I1202 02:07:18.701277 22909 net.cpp:67] Creating Layer data
I1202 02:07:18.701280 22909 net.cpp:356] data -> data
I1202 02:07:18.701288 22909 net.cpp:356] data -> label
I1202 02:07:18.701293 22909 net.cpp:96] Setting up data
I1202 02:07:18.701297 22909 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:07:18.702867 22909 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:07:18.709892 22909 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:07:18.710794 22909 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:07:18.710803 22909 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:07:18.710808 22909 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:07:18.710819 22909 net.cpp:67] Creating Layer label_data_1_split
I1202 02:07:18.710824 22909 net.cpp:394] label_data_1_split <- label
I1202 02:07:18.710830 22909 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:07:18.710839 22909 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:07:18.710844 22909 net.cpp:96] Setting up label_data_1_split
I1202 02:07:18.710849 22909 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:07:18.710851 22909 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:07:18.710855 22909 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:07:18.710860 22909 net.cpp:67] Creating Layer conv1_1
I1202 02:07:18.710863 22909 net.cpp:394] conv1_1 <- data
I1202 02:07:18.710868 22909 net.cpp:356] conv1_1 -> conv1_1
I1202 02:07:18.710875 22909 net.cpp:96] Setting up conv1_1
I1202 02:07:18.711036 22909 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:07:18.711050 22909 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:07:18.711055 22909 net.cpp:67] Creating Layer relu1_1
I1202 02:07:18.711058 22909 net.cpp:394] relu1_1 <- conv1_1
I1202 02:07:18.711063 22909 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:07:18.711074 22909 net.cpp:96] Setting up relu1_1
I1202 02:07:18.711081 22909 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:07:18.711083 22909 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:07:18.711089 22909 net.cpp:67] Creating Layer conv1_2
I1202 02:07:18.711092 22909 net.cpp:394] conv1_2 <- conv1_1
I1202 02:07:18.711097 22909 net.cpp:356] conv1_2 -> conv1_2
I1202 02:07:18.711102 22909 net.cpp:96] Setting up conv1_2
I1202 02:07:18.712105 22909 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:07:18.712117 22909 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:07:18.712122 22909 net.cpp:67] Creating Layer relu1_2
I1202 02:07:18.712126 22909 net.cpp:394] relu1_2 <- conv1_2
I1202 02:07:18.712129 22909 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:07:18.712134 22909 net.cpp:96] Setting up relu1_2
I1202 02:07:18.712139 22909 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:07:18.712142 22909 layer_factory.hpp:78] Creating layer pool1
I1202 02:07:18.712147 22909 net.cpp:67] Creating Layer pool1
I1202 02:07:18.712151 22909 net.cpp:394] pool1 <- conv1_2
I1202 02:07:18.712154 22909 net.cpp:356] pool1 -> pool1
I1202 02:07:18.712159 22909 net.cpp:96] Setting up pool1
I1202 02:07:18.712167 22909 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:07:18.712169 22909 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:07:18.712173 22909 net.cpp:67] Creating Layer conv2_1
I1202 02:07:18.712177 22909 net.cpp:394] conv2_1 <- pool1
I1202 02:07:18.712182 22909 net.cpp:356] conv2_1 -> conv2_1
I1202 02:07:18.712185 22909 net.cpp:96] Setting up conv2_1
I1202 02:07:18.714190 22909 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:07:18.714203 22909 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:07:18.714210 22909 net.cpp:67] Creating Layer relu2_1
I1202 02:07:18.714213 22909 net.cpp:394] relu2_1 <- conv2_1
I1202 02:07:18.714217 22909 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:07:18.714222 22909 net.cpp:96] Setting up relu2_1
I1202 02:07:18.714227 22909 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:07:18.714231 22909 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:07:18.714236 22909 net.cpp:67] Creating Layer conv2_2
I1202 02:07:18.714238 22909 net.cpp:394] conv2_2 <- conv2_1
I1202 02:07:18.714242 22909 net.cpp:356] conv2_2 -> conv2_2
I1202 02:07:18.714248 22909 net.cpp:96] Setting up conv2_2
I1202 02:07:18.717895 22909 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:07:18.717906 22909 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:07:18.717911 22909 net.cpp:67] Creating Layer relu2_2
I1202 02:07:18.717914 22909 net.cpp:394] relu2_2 <- conv2_2
I1202 02:07:18.717918 22909 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:07:18.717923 22909 net.cpp:96] Setting up relu2_2
I1202 02:07:18.717927 22909 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:07:18.717931 22909 layer_factory.hpp:78] Creating layer pool2
I1202 02:07:18.717936 22909 net.cpp:67] Creating Layer pool2
I1202 02:07:18.717938 22909 net.cpp:394] pool2 <- conv2_2
I1202 02:07:18.717942 22909 net.cpp:356] pool2 -> pool2
I1202 02:07:18.717947 22909 net.cpp:96] Setting up pool2
I1202 02:07:18.717952 22909 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:07:18.717955 22909 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:07:18.717960 22909 net.cpp:67] Creating Layer conv3_1
I1202 02:07:18.717963 22909 net.cpp:394] conv3_1 <- pool2
I1202 02:07:18.717968 22909 net.cpp:356] conv3_1 -> conv3_1
I1202 02:07:18.717973 22909 net.cpp:96] Setting up conv3_1
I1202 02:07:18.725209 22909 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:07:18.725224 22909 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:07:18.725229 22909 net.cpp:67] Creating Layer relu3_1
I1202 02:07:18.725232 22909 net.cpp:394] relu3_1 <- conv3_1
I1202 02:07:18.725236 22909 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:07:18.725241 22909 net.cpp:96] Setting up relu3_1
I1202 02:07:18.725246 22909 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:07:18.725250 22909 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:07:18.725260 22909 net.cpp:67] Creating Layer conv3_2
I1202 02:07:18.725263 22909 net.cpp:394] conv3_2 <- conv3_1
I1202 02:07:18.725268 22909 net.cpp:356] conv3_2 -> conv3_2
I1202 02:07:18.725273 22909 net.cpp:96] Setting up conv3_2
I1202 02:07:18.739917 22909 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:07:18.739941 22909 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:07:18.739949 22909 net.cpp:67] Creating Layer relu3_2
I1202 02:07:18.739954 22909 net.cpp:394] relu3_2 <- conv3_2
I1202 02:07:18.739959 22909 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:07:18.739966 22909 net.cpp:96] Setting up relu3_2
I1202 02:07:18.739971 22909 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:07:18.739975 22909 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:07:18.739984 22909 net.cpp:67] Creating Layer conv3_3
I1202 02:07:18.739987 22909 net.cpp:394] conv3_3 <- conv3_2
I1202 02:07:18.739992 22909 net.cpp:356] conv3_3 -> conv3_3
I1202 02:07:18.739998 22909 net.cpp:96] Setting up conv3_3
I1202 02:07:18.754780 22909 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:07:18.754796 22909 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:07:18.754803 22909 net.cpp:67] Creating Layer relu3_3
I1202 02:07:18.754807 22909 net.cpp:394] relu3_3 <- conv3_3
I1202 02:07:18.754812 22909 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:07:18.754818 22909 net.cpp:96] Setting up relu3_3
I1202 02:07:18.754823 22909 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:07:18.754827 22909 layer_factory.hpp:78] Creating layer pool3
I1202 02:07:18.754833 22909 net.cpp:67] Creating Layer pool3
I1202 02:07:18.754837 22909 net.cpp:394] pool3 <- conv3_3
I1202 02:07:18.754842 22909 net.cpp:356] pool3 -> pool3
I1202 02:07:18.754847 22909 net.cpp:96] Setting up pool3
I1202 02:07:18.754853 22909 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:07:18.754856 22909 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:07:18.754861 22909 net.cpp:67] Creating Layer conv4_1
I1202 02:07:18.754864 22909 net.cpp:394] conv4_1 <- pool3
I1202 02:07:18.754870 22909 net.cpp:356] conv4_1 -> conv4_1
I1202 02:07:18.754875 22909 net.cpp:96] Setting up conv4_1
I1202 02:07:18.784207 22909 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:07:18.784230 22909 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:07:18.784240 22909 net.cpp:67] Creating Layer relu4_1
I1202 02:07:18.784245 22909 net.cpp:394] relu4_1 <- conv4_1
I1202 02:07:18.784250 22909 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:07:18.784257 22909 net.cpp:96] Setting up relu4_1
I1202 02:07:18.784263 22909 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:07:18.784266 22909 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:07:18.784273 22909 net.cpp:67] Creating Layer conv4_2
I1202 02:07:18.784276 22909 net.cpp:394] conv4_2 <- conv4_1
I1202 02:07:18.784281 22909 net.cpp:356] conv4_2 -> conv4_2
I1202 02:07:18.784287 22909 net.cpp:96] Setting up conv4_2
I1202 02:07:18.842049 22909 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:07:18.842079 22909 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:07:18.842088 22909 net.cpp:67] Creating Layer relu4_2
I1202 02:07:18.842092 22909 net.cpp:394] relu4_2 <- conv4_2
I1202 02:07:18.842098 22909 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:07:18.842104 22909 net.cpp:96] Setting up relu4_2
I1202 02:07:18.842110 22909 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:07:18.842113 22909 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:07:18.842119 22909 net.cpp:67] Creating Layer conv4_3
I1202 02:07:18.842123 22909 net.cpp:394] conv4_3 <- conv4_2
I1202 02:07:18.842129 22909 net.cpp:356] conv4_3 -> conv4_3
I1202 02:07:18.842136 22909 net.cpp:96] Setting up conv4_3
I1202 02:07:18.900018 22909 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:07:18.900043 22909 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:07:18.900051 22909 net.cpp:67] Creating Layer relu4_3
I1202 02:07:18.900056 22909 net.cpp:394] relu4_3 <- conv4_3
I1202 02:07:18.900063 22909 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:07:18.900077 22909 net.cpp:96] Setting up relu4_3
I1202 02:07:18.900084 22909 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:07:18.900087 22909 layer_factory.hpp:78] Creating layer pool4
I1202 02:07:18.900092 22909 net.cpp:67] Creating Layer pool4
I1202 02:07:18.900095 22909 net.cpp:394] pool4 <- conv4_3
I1202 02:07:18.900101 22909 net.cpp:356] pool4 -> pool4
I1202 02:07:18.900107 22909 net.cpp:96] Setting up pool4
I1202 02:07:18.900115 22909 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:07:18.900118 22909 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:07:18.900123 22909 net.cpp:67] Creating Layer conv5_1
I1202 02:07:18.900126 22909 net.cpp:394] conv5_1 <- pool4
I1202 02:07:18.900132 22909 net.cpp:356] conv5_1 -> conv5_1
I1202 02:07:18.900137 22909 net.cpp:96] Setting up conv5_1
I1202 02:07:18.957769 22909 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:07:18.957795 22909 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:07:18.957803 22909 net.cpp:67] Creating Layer relu5_1
I1202 02:07:18.957808 22909 net.cpp:394] relu5_1 <- conv5_1
I1202 02:07:18.957814 22909 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:07:18.957820 22909 net.cpp:96] Setting up relu5_1
I1202 02:07:18.957826 22909 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:07:18.957829 22909 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:07:18.957836 22909 net.cpp:67] Creating Layer conv5_2
I1202 02:07:18.957839 22909 net.cpp:394] conv5_2 <- conv5_1
I1202 02:07:18.957844 22909 net.cpp:356] conv5_2 -> conv5_2
I1202 02:07:18.957850 22909 net.cpp:96] Setting up conv5_2
I1202 02:07:19.015744 22909 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:07:19.015769 22909 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:07:19.015777 22909 net.cpp:67] Creating Layer relu5_2
I1202 02:07:19.015781 22909 net.cpp:394] relu5_2 <- conv5_2
I1202 02:07:19.015789 22909 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:07:19.015796 22909 net.cpp:96] Setting up relu5_2
I1202 02:07:19.015801 22909 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:07:19.015805 22909 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:07:19.015810 22909 net.cpp:67] Creating Layer conv5_3
I1202 02:07:19.015813 22909 net.cpp:394] conv5_3 <- conv5_2
I1202 02:07:19.015818 22909 net.cpp:356] conv5_3 -> conv5_3
I1202 02:07:19.015825 22909 net.cpp:96] Setting up conv5_3
I1202 02:07:19.073603 22909 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:07:19.073629 22909 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:07:19.073637 22909 net.cpp:67] Creating Layer relu5_3
I1202 02:07:19.073642 22909 net.cpp:394] relu5_3 <- conv5_3
I1202 02:07:19.073650 22909 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:07:19.073658 22909 net.cpp:96] Setting up relu5_3
I1202 02:07:19.073663 22909 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:07:19.073668 22909 layer_factory.hpp:78] Creating layer pool5
I1202 02:07:19.073678 22909 net.cpp:67] Creating Layer pool5
I1202 02:07:19.073680 22909 net.cpp:394] pool5 <- conv5_3
I1202 02:07:19.073685 22909 net.cpp:356] pool5 -> pool5
I1202 02:07:19.073690 22909 net.cpp:96] Setting up pool5
I1202 02:07:19.073698 22909 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:07:19.073703 22909 layer_factory.hpp:78] Creating layer fc6
I1202 02:07:19.073707 22909 net.cpp:67] Creating Layer fc6
I1202 02:07:19.073710 22909 net.cpp:394] fc6 <- pool5
I1202 02:07:19.073716 22909 net.cpp:356] fc6 -> fc6
I1202 02:07:19.073722 22909 net.cpp:96] Setting up fc6
I1202 02:07:21.572788 22909 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:07:21.572815 22909 layer_factory.hpp:78] Creating layer relu6
I1202 02:07:21.572824 22909 net.cpp:67] Creating Layer relu6
I1202 02:07:21.572830 22909 net.cpp:394] relu6 <- fc6
I1202 02:07:21.572837 22909 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:07:21.572844 22909 net.cpp:96] Setting up relu6
I1202 02:07:21.572857 22909 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:07:21.572861 22909 layer_factory.hpp:78] Creating layer drop6
I1202 02:07:21.572877 22909 net.cpp:67] Creating Layer drop6
I1202 02:07:21.572880 22909 net.cpp:394] drop6 <- fc6
I1202 02:07:21.572885 22909 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:07:21.572888 22909 net.cpp:96] Setting up drop6
I1202 02:07:21.572892 22909 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:07:21.572896 22909 layer_factory.hpp:78] Creating layer fc7
I1202 02:07:21.572906 22909 net.cpp:67] Creating Layer fc7
I1202 02:07:21.572908 22909 net.cpp:394] fc7 <- fc6
I1202 02:07:21.572913 22909 net.cpp:356] fc7 -> fc7
I1202 02:07:21.572919 22909 net.cpp:96] Setting up fc7
I1202 02:07:21.981528 22909 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:07:21.981556 22909 layer_factory.hpp:78] Creating layer relu7
I1202 02:07:21.981564 22909 net.cpp:67] Creating Layer relu7
I1202 02:07:21.981570 22909 net.cpp:394] relu7 <- fc7
I1202 02:07:21.981575 22909 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:07:21.981582 22909 net.cpp:96] Setting up relu7
I1202 02:07:21.981596 22909 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:07:21.981600 22909 layer_factory.hpp:78] Creating layer drop7
I1202 02:07:21.981606 22909 net.cpp:67] Creating Layer drop7
I1202 02:07:21.981608 22909 net.cpp:394] drop7 <- fc7
I1202 02:07:21.981614 22909 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:07:21.981618 22909 net.cpp:96] Setting up drop7
I1202 02:07:21.981622 22909 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:07:21.981626 22909 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:07:21.981631 22909 net.cpp:67] Creating Layer fc8_2
I1202 02:07:21.981633 22909 net.cpp:394] fc8_2 <- fc7
I1202 02:07:21.981639 22909 net.cpp:356] fc8_2 -> fc8_2
I1202 02:07:21.981647 22909 net.cpp:96] Setting up fc8_2
I1202 02:07:21.981869 22909 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:07:21.981878 22909 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:07:21.981883 22909 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:07:21.981885 22909 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:07:21.981890 22909 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:07:21.981896 22909 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:07:21.981901 22909 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:07:21.981909 22909 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:07:21.981912 22909 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:07:21.981915 22909 layer_factory.hpp:78] Creating layer loss
I1202 02:07:21.981921 22909 net.cpp:67] Creating Layer loss
I1202 02:07:21.981925 22909 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:07:21.981928 22909 net.cpp:394] loss <- label_data_1_split_0
I1202 02:07:21.981933 22909 net.cpp:356] loss -> (automatic)
I1202 02:07:21.981937 22909 net.cpp:96] Setting up loss
I1202 02:07:21.981950 22909 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:07:21.981953 22909 net.cpp:109]     with loss weight 1
I1202 02:07:21.981967 22909 layer_factory.hpp:78] Creating layer accuracy
I1202 02:07:21.981974 22909 net.cpp:67] Creating Layer accuracy
I1202 02:07:21.981977 22909 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:07:21.981981 22909 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:07:21.981986 22909 net.cpp:356] accuracy -> accuracy
I1202 02:07:21.981997 22909 net.cpp:96] Setting up accuracy
I1202 02:07:21.982007 22909 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:07:21.982012 22909 net.cpp:172] accuracy does not need backward computation.
I1202 02:07:21.982013 22909 net.cpp:170] loss needs backward computation.
I1202 02:07:21.982017 22909 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:07:21.982019 22909 net.cpp:170] fc8_2 needs backward computation.
I1202 02:07:21.982023 22909 net.cpp:170] drop7 needs backward computation.
I1202 02:07:21.982025 22909 net.cpp:170] relu7 needs backward computation.
I1202 02:07:21.982028 22909 net.cpp:170] fc7 needs backward computation.
I1202 02:07:21.982030 22909 net.cpp:170] drop6 needs backward computation.
I1202 02:07:21.982033 22909 net.cpp:170] relu6 needs backward computation.
I1202 02:07:21.982043 22909 net.cpp:170] fc6 needs backward computation.
I1202 02:07:21.982046 22909 net.cpp:170] pool5 needs backward computation.
I1202 02:07:21.982049 22909 net.cpp:170] relu5_3 needs backward computation.
I1202 02:07:21.982053 22909 net.cpp:170] conv5_3 needs backward computation.
I1202 02:07:21.982055 22909 net.cpp:170] relu5_2 needs backward computation.
I1202 02:07:21.982058 22909 net.cpp:170] conv5_2 needs backward computation.
I1202 02:07:21.982060 22909 net.cpp:170] relu5_1 needs backward computation.
I1202 02:07:21.982064 22909 net.cpp:170] conv5_1 needs backward computation.
I1202 02:07:21.982066 22909 net.cpp:170] pool4 needs backward computation.
I1202 02:07:21.982069 22909 net.cpp:170] relu4_3 needs backward computation.
I1202 02:07:21.982072 22909 net.cpp:170] conv4_3 needs backward computation.
I1202 02:07:21.982074 22909 net.cpp:170] relu4_2 needs backward computation.
I1202 02:07:21.982077 22909 net.cpp:170] conv4_2 needs backward computation.
I1202 02:07:21.982080 22909 net.cpp:170] relu4_1 needs backward computation.
I1202 02:07:21.982082 22909 net.cpp:170] conv4_1 needs backward computation.
I1202 02:07:21.982085 22909 net.cpp:170] pool3 needs backward computation.
I1202 02:07:21.982089 22909 net.cpp:170] relu3_3 needs backward computation.
I1202 02:07:21.982091 22909 net.cpp:170] conv3_3 needs backward computation.
I1202 02:07:21.982095 22909 net.cpp:170] relu3_2 needs backward computation.
I1202 02:07:21.982096 22909 net.cpp:170] conv3_2 needs backward computation.
I1202 02:07:21.982100 22909 net.cpp:170] relu3_1 needs backward computation.
I1202 02:07:21.982102 22909 net.cpp:170] conv3_1 needs backward computation.
I1202 02:07:21.982105 22909 net.cpp:170] pool2 needs backward computation.
I1202 02:07:21.982110 22909 net.cpp:170] relu2_2 needs backward computation.
I1202 02:07:21.982112 22909 net.cpp:170] conv2_2 needs backward computation.
I1202 02:07:21.982115 22909 net.cpp:170] relu2_1 needs backward computation.
I1202 02:07:21.982118 22909 net.cpp:170] conv2_1 needs backward computation.
I1202 02:07:21.982121 22909 net.cpp:170] pool1 needs backward computation.
I1202 02:07:21.982125 22909 net.cpp:170] relu1_2 needs backward computation.
I1202 02:07:21.982127 22909 net.cpp:170] conv1_2 needs backward computation.
I1202 02:07:21.982131 22909 net.cpp:170] relu1_1 needs backward computation.
I1202 02:07:21.982132 22909 net.cpp:170] conv1_1 needs backward computation.
I1202 02:07:21.982136 22909 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:07:21.982138 22909 net.cpp:172] data does not need backward computation.
I1202 02:07:21.982141 22909 net.cpp:208] This network produces output accuracy
I1202 02:07:21.982161 22909 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:07:21.982169 22909 net.cpp:219] Network initialization done.
I1202 02:07:21.982172 22909 net.cpp:220] Memory required for data: 921616692
I1202 02:07:21.982271 22909 solver.cpp:41] Solver scaffolding done.
I1202 02:07:21.982277 22909 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_1.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:07:25.316603 22909 solver.cpp:160] Solving small
I1202 02:07:25.316632 22909 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:07:25.316679 22909 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:08:45.465167 22909 solver.cpp:305] Test loss: 1.07846
I1202 02:08:45.465250 22909 solver.cpp:318] mean_score = test_score[0] { = 992} / test_score[1] { = 3570 }
I1202 02:08:45.465258 22909 solver.cpp:319]            = 0.277871
I1202 02:08:45.465267 22909 solver.cpp:328]     Test net output #0: accuracy = 0.277871
I1202 02:08:45.465272 22909 solver.cpp:318] mean_score = test_score[2] { = 254} / test_score[3] { = 398 }
I1202 02:08:45.465277 22909 solver.cpp:319]            = 0.638191
I1202 02:08:45.465281 22909 solver.cpp:328]     Test net output #1: accuracy = 0.638191
I1202 02:08:45.465291 22909 solver.cpp:332]     Test net output #2: accuracy = 0.314012
I1202 02:08:45.465296 22909 solver.cpp:334]     Test net output #3: accuracy = 0.458031
I1202 02:08:46.142421 22909 solver.cpp:209] Iteration 0, loss = 0.798511
I1202 02:08:46.142449 22909 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:08:48.425711 22909 solver.cpp:209] Iteration 1, loss = 1.22314
I1202 02:08:48.425740 22909 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:08:50.382586 22909 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:08:51.406025 22909 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:08:52.615836 22909 solver.cpp:246] Iteration 2, loss = 0.944576
I1202 02:08:52.615869 22909 solver.cpp:251] Optimization Done.
I1202 02:08:52.615874 22909 caffe.cpp:121] Optimization Done.
I1202 02:08:52.757709 23462 caffe.cpp:99] Use GPU with device ID 0
I1202 02:08:52.934705 23462 caffe.cpp:107] Starting Optimization
I1202 02:08:52.934811 23462 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:08:52.934844 23462 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:08:52.935685 23462 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:08:52.935716 23462 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:08:52.935933 23462 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:08:52.936132 23462 layer_factory.hpp:78] Creating layer data
I1202 02:08:52.936157 23462 net.cpp:67] Creating Layer data
I1202 02:08:52.936171 23462 net.cpp:356] data -> data
I1202 02:08:52.936198 23462 net.cpp:356] data -> label
I1202 02:08:52.936213 23462 net.cpp:96] Setting up data
I1202 02:08:52.936223 23462 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:08:52.950783 23462 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:08:52.960614 23462 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:08:52.963577 23462 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:08:52.963599 23462 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:08:52.963604 23462 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:08:52.963623 23462 net.cpp:67] Creating Layer conv1_1
I1202 02:08:52.963628 23462 net.cpp:394] conv1_1 <- data
I1202 02:08:52.963641 23462 net.cpp:356] conv1_1 -> conv1_1
I1202 02:08:52.963651 23462 net.cpp:96] Setting up conv1_1
I1202 02:08:53.106807 23462 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:08:53.106842 23462 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:08:53.106854 23462 net.cpp:67] Creating Layer relu1_1
I1202 02:08:53.106858 23462 net.cpp:394] relu1_1 <- conv1_1
I1202 02:08:53.106865 23462 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:08:53.106873 23462 net.cpp:96] Setting up relu1_1
I1202 02:08:53.106884 23462 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:08:53.106886 23462 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:08:53.106894 23462 net.cpp:67] Creating Layer conv1_2
I1202 02:08:53.106896 23462 net.cpp:394] conv1_2 <- conv1_1
I1202 02:08:53.106902 23462 net.cpp:356] conv1_2 -> conv1_2
I1202 02:08:53.106909 23462 net.cpp:96] Setting up conv1_2
I1202 02:08:53.107985 23462 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:08:53.107998 23462 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:08:53.108006 23462 net.cpp:67] Creating Layer relu1_2
I1202 02:08:53.108011 23462 net.cpp:394] relu1_2 <- conv1_2
I1202 02:08:53.108016 23462 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:08:53.108019 23462 net.cpp:96] Setting up relu1_2
I1202 02:08:53.108026 23462 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:08:53.108028 23462 layer_factory.hpp:78] Creating layer pool1
I1202 02:08:53.108036 23462 net.cpp:67] Creating Layer pool1
I1202 02:08:53.108039 23462 net.cpp:394] pool1 <- conv1_2
I1202 02:08:53.108043 23462 net.cpp:356] pool1 -> pool1
I1202 02:08:53.108048 23462 net.cpp:96] Setting up pool1
I1202 02:08:53.108067 23462 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:08:53.108070 23462 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:08:53.108077 23462 net.cpp:67] Creating Layer conv2_1
I1202 02:08:53.108079 23462 net.cpp:394] conv2_1 <- pool1
I1202 02:08:53.108085 23462 net.cpp:356] conv2_1 -> conv2_1
I1202 02:08:53.108091 23462 net.cpp:96] Setting up conv2_1
I1202 02:08:53.110029 23462 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:08:53.110043 23462 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:08:53.110047 23462 net.cpp:67] Creating Layer relu2_1
I1202 02:08:53.110050 23462 net.cpp:394] relu2_1 <- conv2_1
I1202 02:08:53.110056 23462 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:08:53.110061 23462 net.cpp:96] Setting up relu2_1
I1202 02:08:53.110066 23462 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:08:53.110070 23462 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:08:53.110076 23462 net.cpp:67] Creating Layer conv2_2
I1202 02:08:53.110079 23462 net.cpp:394] conv2_2 <- conv2_1
I1202 02:08:53.110083 23462 net.cpp:356] conv2_2 -> conv2_2
I1202 02:08:53.110088 23462 net.cpp:96] Setting up conv2_2
I1202 02:08:53.113878 23462 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:08:53.113891 23462 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:08:53.113896 23462 net.cpp:67] Creating Layer relu2_2
I1202 02:08:53.113900 23462 net.cpp:394] relu2_2 <- conv2_2
I1202 02:08:53.113906 23462 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:08:53.113911 23462 net.cpp:96] Setting up relu2_2
I1202 02:08:53.113916 23462 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:08:53.113927 23462 layer_factory.hpp:78] Creating layer pool2
I1202 02:08:53.113932 23462 net.cpp:67] Creating Layer pool2
I1202 02:08:53.113935 23462 net.cpp:394] pool2 <- conv2_2
I1202 02:08:53.113940 23462 net.cpp:356] pool2 -> pool2
I1202 02:08:53.113945 23462 net.cpp:96] Setting up pool2
I1202 02:08:53.113950 23462 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:08:53.113955 23462 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:08:53.113960 23462 net.cpp:67] Creating Layer conv3_1
I1202 02:08:53.113965 23462 net.cpp:394] conv3_1 <- pool2
I1202 02:08:53.113970 23462 net.cpp:356] conv3_1 -> conv3_1
I1202 02:08:53.113976 23462 net.cpp:96] Setting up conv3_1
I1202 02:08:53.121398 23462 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:08:53.121413 23462 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:08:53.121419 23462 net.cpp:67] Creating Layer relu3_1
I1202 02:08:53.121423 23462 net.cpp:394] relu3_1 <- conv3_1
I1202 02:08:53.121426 23462 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:08:53.121431 23462 net.cpp:96] Setting up relu3_1
I1202 02:08:53.121436 23462 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:08:53.121440 23462 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:08:53.121446 23462 net.cpp:67] Creating Layer conv3_2
I1202 02:08:53.121449 23462 net.cpp:394] conv3_2 <- conv3_1
I1202 02:08:53.121454 23462 net.cpp:356] conv3_2 -> conv3_2
I1202 02:08:53.121459 23462 net.cpp:96] Setting up conv3_2
I1202 02:08:53.136384 23462 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:08:53.136406 23462 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:08:53.136415 23462 net.cpp:67] Creating Layer relu3_2
I1202 02:08:53.136420 23462 net.cpp:394] relu3_2 <- conv3_2
I1202 02:08:53.136426 23462 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:08:53.136433 23462 net.cpp:96] Setting up relu3_2
I1202 02:08:53.136438 23462 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:08:53.136441 23462 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:08:53.136448 23462 net.cpp:67] Creating Layer conv3_3
I1202 02:08:53.136451 23462 net.cpp:394] conv3_3 <- conv3_2
I1202 02:08:53.136457 23462 net.cpp:356] conv3_3 -> conv3_3
I1202 02:08:53.136463 23462 net.cpp:96] Setting up conv3_3
I1202 02:08:53.151252 23462 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:08:53.151271 23462 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:08:53.151279 23462 net.cpp:67] Creating Layer relu3_3
I1202 02:08:53.151283 23462 net.cpp:394] relu3_3 <- conv3_3
I1202 02:08:53.151290 23462 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:08:53.151296 23462 net.cpp:96] Setting up relu3_3
I1202 02:08:53.151301 23462 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:08:53.151305 23462 layer_factory.hpp:78] Creating layer pool3
I1202 02:08:53.151310 23462 net.cpp:67] Creating Layer pool3
I1202 02:08:53.151314 23462 net.cpp:394] pool3 <- conv3_3
I1202 02:08:53.151319 23462 net.cpp:356] pool3 -> pool3
I1202 02:08:53.151324 23462 net.cpp:96] Setting up pool3
I1202 02:08:53.151332 23462 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:08:53.151335 23462 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:08:53.151341 23462 net.cpp:67] Creating Layer conv4_1
I1202 02:08:53.151345 23462 net.cpp:394] conv4_1 <- pool3
I1202 02:08:53.151350 23462 net.cpp:356] conv4_1 -> conv4_1
I1202 02:08:53.151355 23462 net.cpp:96] Setting up conv4_1
I1202 02:08:53.183048 23462 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:08:53.183073 23462 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:08:53.183082 23462 net.cpp:67] Creating Layer relu4_1
I1202 02:08:53.183086 23462 net.cpp:394] relu4_1 <- conv4_1
I1202 02:08:53.183094 23462 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:08:53.183100 23462 net.cpp:96] Setting up relu4_1
I1202 02:08:53.183105 23462 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:08:53.183109 23462 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:08:53.183115 23462 net.cpp:67] Creating Layer conv4_2
I1202 02:08:53.183118 23462 net.cpp:394] conv4_2 <- conv4_1
I1202 02:08:53.183133 23462 net.cpp:356] conv4_2 -> conv4_2
I1202 02:08:53.183140 23462 net.cpp:96] Setting up conv4_2
I1202 02:08:53.240913 23462 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:08:53.240942 23462 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:08:53.240950 23462 net.cpp:67] Creating Layer relu4_2
I1202 02:08:53.240955 23462 net.cpp:394] relu4_2 <- conv4_2
I1202 02:08:53.240964 23462 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:08:53.240972 23462 net.cpp:96] Setting up relu4_2
I1202 02:08:53.240978 23462 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:08:53.240981 23462 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:08:53.240988 23462 net.cpp:67] Creating Layer conv4_3
I1202 02:08:53.240991 23462 net.cpp:394] conv4_3 <- conv4_2
I1202 02:08:53.240998 23462 net.cpp:356] conv4_3 -> conv4_3
I1202 02:08:53.241004 23462 net.cpp:96] Setting up conv4_3
I1202 02:08:53.298863 23462 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:08:53.298887 23462 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:08:53.298897 23462 net.cpp:67] Creating Layer relu4_3
I1202 02:08:53.298902 23462 net.cpp:394] relu4_3 <- conv4_3
I1202 02:08:53.298908 23462 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:08:53.298915 23462 net.cpp:96] Setting up relu4_3
I1202 02:08:53.298921 23462 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:08:53.298924 23462 layer_factory.hpp:78] Creating layer pool4
I1202 02:08:53.298931 23462 net.cpp:67] Creating Layer pool4
I1202 02:08:53.298934 23462 net.cpp:394] pool4 <- conv4_3
I1202 02:08:53.298939 23462 net.cpp:356] pool4 -> pool4
I1202 02:08:53.298945 23462 net.cpp:96] Setting up pool4
I1202 02:08:53.298952 23462 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:08:53.298956 23462 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:08:53.298961 23462 net.cpp:67] Creating Layer conv5_1
I1202 02:08:53.298964 23462 net.cpp:394] conv5_1 <- pool4
I1202 02:08:53.298971 23462 net.cpp:356] conv5_1 -> conv5_1
I1202 02:08:53.298979 23462 net.cpp:96] Setting up conv5_1
I1202 02:08:53.356808 23462 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:08:53.356835 23462 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:08:53.356843 23462 net.cpp:67] Creating Layer relu5_1
I1202 02:08:53.356848 23462 net.cpp:394] relu5_1 <- conv5_1
I1202 02:08:53.356855 23462 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:08:53.356861 23462 net.cpp:96] Setting up relu5_1
I1202 02:08:53.356868 23462 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:08:53.356870 23462 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:08:53.356884 23462 net.cpp:67] Creating Layer conv5_2
I1202 02:08:53.356887 23462 net.cpp:394] conv5_2 <- conv5_1
I1202 02:08:53.356892 23462 net.cpp:356] conv5_2 -> conv5_2
I1202 02:08:53.356899 23462 net.cpp:96] Setting up conv5_2
I1202 02:08:53.414803 23462 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:08:53.414827 23462 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:08:53.414835 23462 net.cpp:67] Creating Layer relu5_2
I1202 02:08:53.414839 23462 net.cpp:394] relu5_2 <- conv5_2
I1202 02:08:53.414849 23462 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:08:53.414855 23462 net.cpp:96] Setting up relu5_2
I1202 02:08:53.414860 23462 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:08:53.414865 23462 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:08:53.414870 23462 net.cpp:67] Creating Layer conv5_3
I1202 02:08:53.414872 23462 net.cpp:394] conv5_3 <- conv5_2
I1202 02:08:53.414878 23462 net.cpp:356] conv5_3 -> conv5_3
I1202 02:08:53.414885 23462 net.cpp:96] Setting up conv5_3
I1202 02:08:53.472504 23462 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:08:53.472530 23462 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:08:53.472538 23462 net.cpp:67] Creating Layer relu5_3
I1202 02:08:53.472543 23462 net.cpp:394] relu5_3 <- conv5_3
I1202 02:08:53.472549 23462 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:08:53.472555 23462 net.cpp:96] Setting up relu5_3
I1202 02:08:53.472561 23462 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:08:53.472575 23462 layer_factory.hpp:78] Creating layer pool5
I1202 02:08:53.472581 23462 net.cpp:67] Creating Layer pool5
I1202 02:08:53.472584 23462 net.cpp:394] pool5 <- conv5_3
I1202 02:08:53.472590 23462 net.cpp:356] pool5 -> pool5
I1202 02:08:53.472596 23462 net.cpp:96] Setting up pool5
I1202 02:08:53.472604 23462 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:08:53.472607 23462 layer_factory.hpp:78] Creating layer fc6
I1202 02:08:53.472622 23462 net.cpp:67] Creating Layer fc6
I1202 02:08:53.472625 23462 net.cpp:394] fc6 <- pool5
I1202 02:08:53.472630 23462 net.cpp:356] fc6 -> fc6
I1202 02:08:53.472636 23462 net.cpp:96] Setting up fc6
I1202 02:08:55.975118 23462 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:08:55.975148 23462 layer_factory.hpp:78] Creating layer relu6
I1202 02:08:55.975158 23462 net.cpp:67] Creating Layer relu6
I1202 02:08:55.975163 23462 net.cpp:394] relu6 <- fc6
I1202 02:08:55.975172 23462 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:08:55.975178 23462 net.cpp:96] Setting up relu6
I1202 02:08:55.975193 23462 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:08:55.975196 23462 layer_factory.hpp:78] Creating layer drop6
I1202 02:08:55.975204 23462 net.cpp:67] Creating Layer drop6
I1202 02:08:55.975208 23462 net.cpp:394] drop6 <- fc6
I1202 02:08:55.975214 23462 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:08:55.975217 23462 net.cpp:96] Setting up drop6
I1202 02:08:55.975221 23462 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:08:55.975224 23462 layer_factory.hpp:78] Creating layer fc7
I1202 02:08:55.975229 23462 net.cpp:67] Creating Layer fc7
I1202 02:08:55.975232 23462 net.cpp:394] fc7 <- fc6
I1202 02:08:55.975239 23462 net.cpp:356] fc7 -> fc7
I1202 02:08:55.975245 23462 net.cpp:96] Setting up fc7
I1202 02:08:56.384281 23462 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:08:56.384311 23462 layer_factory.hpp:78] Creating layer relu7
I1202 02:08:56.384320 23462 net.cpp:67] Creating Layer relu7
I1202 02:08:56.384325 23462 net.cpp:394] relu7 <- fc7
I1202 02:08:56.384335 23462 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:08:56.384341 23462 net.cpp:96] Setting up relu7
I1202 02:08:56.384356 23462 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:08:56.384361 23462 layer_factory.hpp:78] Creating layer drop7
I1202 02:08:56.384366 23462 net.cpp:67] Creating Layer drop7
I1202 02:08:56.384368 23462 net.cpp:394] drop7 <- fc7
I1202 02:08:56.384372 23462 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:08:56.384377 23462 net.cpp:96] Setting up drop7
I1202 02:08:56.384382 23462 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:08:56.384384 23462 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:08:56.384392 23462 net.cpp:67] Creating Layer fc8_2
I1202 02:08:56.384394 23462 net.cpp:394] fc8_2 <- fc7
I1202 02:08:56.384399 23462 net.cpp:356] fc8_2 -> fc8_2
I1202 02:08:56.384405 23462 net.cpp:96] Setting up fc8_2
I1202 02:08:56.384629 23462 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:08:56.384637 23462 layer_factory.hpp:78] Creating layer loss
I1202 02:08:56.384642 23462 net.cpp:67] Creating Layer loss
I1202 02:08:56.384646 23462 net.cpp:394] loss <- fc8_2
I1202 02:08:56.384649 23462 net.cpp:394] loss <- label
I1202 02:08:56.384660 23462 net.cpp:356] loss -> (automatic)
I1202 02:08:56.384665 23462 net.cpp:96] Setting up loss
I1202 02:08:56.384673 23462 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:08:56.384677 23462 net.cpp:109]     with loss weight 1
I1202 02:08:56.384712 23462 net.cpp:170] loss needs backward computation.
I1202 02:08:56.384716 23462 net.cpp:170] fc8_2 needs backward computation.
I1202 02:08:56.384718 23462 net.cpp:170] drop7 needs backward computation.
I1202 02:08:56.384721 23462 net.cpp:170] relu7 needs backward computation.
I1202 02:08:56.384723 23462 net.cpp:170] fc7 needs backward computation.
I1202 02:08:56.384727 23462 net.cpp:170] drop6 needs backward computation.
I1202 02:08:56.384729 23462 net.cpp:170] relu6 needs backward computation.
I1202 02:08:56.384732 23462 net.cpp:170] fc6 needs backward computation.
I1202 02:08:56.384743 23462 net.cpp:170] pool5 needs backward computation.
I1202 02:08:56.384747 23462 net.cpp:170] relu5_3 needs backward computation.
I1202 02:08:56.384750 23462 net.cpp:170] conv5_3 needs backward computation.
I1202 02:08:56.384757 23462 net.cpp:170] relu5_2 needs backward computation.
I1202 02:08:56.384760 23462 net.cpp:170] conv5_2 needs backward computation.
I1202 02:08:56.384763 23462 net.cpp:170] relu5_1 needs backward computation.
I1202 02:08:56.384766 23462 net.cpp:170] conv5_1 needs backward computation.
I1202 02:08:56.384769 23462 net.cpp:170] pool4 needs backward computation.
I1202 02:08:56.384773 23462 net.cpp:170] relu4_3 needs backward computation.
I1202 02:08:56.384775 23462 net.cpp:170] conv4_3 needs backward computation.
I1202 02:08:56.384778 23462 net.cpp:170] relu4_2 needs backward computation.
I1202 02:08:56.384781 23462 net.cpp:170] conv4_2 needs backward computation.
I1202 02:08:56.384784 23462 net.cpp:170] relu4_1 needs backward computation.
I1202 02:08:56.384788 23462 net.cpp:170] conv4_1 needs backward computation.
I1202 02:08:56.384790 23462 net.cpp:170] pool3 needs backward computation.
I1202 02:08:56.384793 23462 net.cpp:170] relu3_3 needs backward computation.
I1202 02:08:56.384796 23462 net.cpp:170] conv3_3 needs backward computation.
I1202 02:08:56.384799 23462 net.cpp:170] relu3_2 needs backward computation.
I1202 02:08:56.384801 23462 net.cpp:170] conv3_2 needs backward computation.
I1202 02:08:56.384804 23462 net.cpp:170] relu3_1 needs backward computation.
I1202 02:08:56.384807 23462 net.cpp:170] conv3_1 needs backward computation.
I1202 02:08:56.384810 23462 net.cpp:170] pool2 needs backward computation.
I1202 02:08:56.384814 23462 net.cpp:170] relu2_2 needs backward computation.
I1202 02:08:56.384816 23462 net.cpp:170] conv2_2 needs backward computation.
I1202 02:08:56.384819 23462 net.cpp:170] relu2_1 needs backward computation.
I1202 02:08:56.384822 23462 net.cpp:170] conv2_1 needs backward computation.
I1202 02:08:56.384825 23462 net.cpp:170] pool1 needs backward computation.
I1202 02:08:56.384829 23462 net.cpp:170] relu1_2 needs backward computation.
I1202 02:08:56.384831 23462 net.cpp:170] conv1_2 needs backward computation.
I1202 02:08:56.384834 23462 net.cpp:170] relu1_1 needs backward computation.
I1202 02:08:56.384836 23462 net.cpp:170] conv1_1 needs backward computation.
I1202 02:08:56.384840 23462 net.cpp:172] data does not need backward computation.
I1202 02:08:56.384857 23462 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:08:56.384865 23462 net.cpp:219] Network initialization done.
I1202 02:08:56.384868 23462 net.cpp:220] Memory required for data: 3686465924
I1202 02:08:56.385720 23462 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:08:56.385768 23462 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:08:56.385989 23462 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:08:56.386126 23462 layer_factory.hpp:78] Creating layer data
I1202 02:08:56.386136 23462 net.cpp:67] Creating Layer data
I1202 02:08:56.386140 23462 net.cpp:356] data -> data
I1202 02:08:56.386147 23462 net.cpp:356] data -> label
I1202 02:08:56.386153 23462 net.cpp:96] Setting up data
I1202 02:08:56.386157 23462 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:08:56.387708 23462 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:08:56.394892 23462 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:08:56.395792 23462 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:08:56.395802 23462 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:08:56.395807 23462 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:08:56.395819 23462 net.cpp:67] Creating Layer label_data_1_split
I1202 02:08:56.395823 23462 net.cpp:394] label_data_1_split <- label
I1202 02:08:56.395829 23462 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:08:56.395838 23462 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:08:56.395845 23462 net.cpp:96] Setting up label_data_1_split
I1202 02:08:56.395850 23462 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:08:56.395853 23462 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:08:56.395856 23462 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:08:56.395862 23462 net.cpp:67] Creating Layer conv1_1
I1202 02:08:56.395865 23462 net.cpp:394] conv1_1 <- data
I1202 02:08:56.395870 23462 net.cpp:356] conv1_1 -> conv1_1
I1202 02:08:56.395876 23462 net.cpp:96] Setting up conv1_1
I1202 02:08:56.396036 23462 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:08:56.396050 23462 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:08:56.396055 23462 net.cpp:67] Creating Layer relu1_1
I1202 02:08:56.396059 23462 net.cpp:394] relu1_1 <- conv1_1
I1202 02:08:56.396064 23462 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:08:56.396075 23462 net.cpp:96] Setting up relu1_1
I1202 02:08:56.396081 23462 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:08:56.396085 23462 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:08:56.396090 23462 net.cpp:67] Creating Layer conv1_2
I1202 02:08:56.396093 23462 net.cpp:394] conv1_2 <- conv1_1
I1202 02:08:56.396098 23462 net.cpp:356] conv1_2 -> conv1_2
I1202 02:08:56.396103 23462 net.cpp:96] Setting up conv1_2
I1202 02:08:56.397102 23462 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:08:56.397115 23462 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:08:56.397120 23462 net.cpp:67] Creating Layer relu1_2
I1202 02:08:56.397125 23462 net.cpp:394] relu1_2 <- conv1_2
I1202 02:08:56.397128 23462 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:08:56.397133 23462 net.cpp:96] Setting up relu1_2
I1202 02:08:56.397138 23462 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:08:56.397141 23462 layer_factory.hpp:78] Creating layer pool1
I1202 02:08:56.397147 23462 net.cpp:67] Creating Layer pool1
I1202 02:08:56.397150 23462 net.cpp:394] pool1 <- conv1_2
I1202 02:08:56.397155 23462 net.cpp:356] pool1 -> pool1
I1202 02:08:56.397160 23462 net.cpp:96] Setting up pool1
I1202 02:08:56.397166 23462 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:08:56.397169 23462 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:08:56.397174 23462 net.cpp:67] Creating Layer conv2_1
I1202 02:08:56.397177 23462 net.cpp:394] conv2_1 <- pool1
I1202 02:08:56.397181 23462 net.cpp:356] conv2_1 -> conv2_1
I1202 02:08:56.397186 23462 net.cpp:96] Setting up conv2_1
I1202 02:08:56.399183 23462 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:08:56.399197 23462 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:08:56.399204 23462 net.cpp:67] Creating Layer relu2_1
I1202 02:08:56.399207 23462 net.cpp:394] relu2_1 <- conv2_1
I1202 02:08:56.399211 23462 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:08:56.399216 23462 net.cpp:96] Setting up relu2_1
I1202 02:08:56.399221 23462 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:08:56.399224 23462 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:08:56.399230 23462 net.cpp:67] Creating Layer conv2_2
I1202 02:08:56.399232 23462 net.cpp:394] conv2_2 <- conv2_1
I1202 02:08:56.399237 23462 net.cpp:356] conv2_2 -> conv2_2
I1202 02:08:56.399243 23462 net.cpp:96] Setting up conv2_2
I1202 02:08:56.402904 23462 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:08:56.402915 23462 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:08:56.402920 23462 net.cpp:67] Creating Layer relu2_2
I1202 02:08:56.402923 23462 net.cpp:394] relu2_2 <- conv2_2
I1202 02:08:56.402928 23462 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:08:56.402932 23462 net.cpp:96] Setting up relu2_2
I1202 02:08:56.402937 23462 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:08:56.402941 23462 layer_factory.hpp:78] Creating layer pool2
I1202 02:08:56.402945 23462 net.cpp:67] Creating Layer pool2
I1202 02:08:56.402948 23462 net.cpp:394] pool2 <- conv2_2
I1202 02:08:56.402953 23462 net.cpp:356] pool2 -> pool2
I1202 02:08:56.402957 23462 net.cpp:96] Setting up pool2
I1202 02:08:56.402963 23462 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:08:56.402966 23462 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:08:56.402971 23462 net.cpp:67] Creating Layer conv3_1
I1202 02:08:56.402974 23462 net.cpp:394] conv3_1 <- pool2
I1202 02:08:56.402979 23462 net.cpp:356] conv3_1 -> conv3_1
I1202 02:08:56.402984 23462 net.cpp:96] Setting up conv3_1
I1202 02:08:56.410235 23462 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:08:56.410249 23462 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:08:56.410254 23462 net.cpp:67] Creating Layer relu3_1
I1202 02:08:56.410258 23462 net.cpp:394] relu3_1 <- conv3_1
I1202 02:08:56.410262 23462 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:08:56.410267 23462 net.cpp:96] Setting up relu3_1
I1202 02:08:56.410272 23462 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:08:56.410275 23462 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:08:56.410289 23462 net.cpp:67] Creating Layer conv3_2
I1202 02:08:56.410291 23462 net.cpp:394] conv3_2 <- conv3_1
I1202 02:08:56.410296 23462 net.cpp:356] conv3_2 -> conv3_2
I1202 02:08:56.410301 23462 net.cpp:96] Setting up conv3_2
I1202 02:08:56.424943 23462 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:08:56.424965 23462 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:08:56.424973 23462 net.cpp:67] Creating Layer relu3_2
I1202 02:08:56.424978 23462 net.cpp:394] relu3_2 <- conv3_2
I1202 02:08:56.424985 23462 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:08:56.424993 23462 net.cpp:96] Setting up relu3_2
I1202 02:08:56.424998 23462 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:08:56.425001 23462 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:08:56.425009 23462 net.cpp:67] Creating Layer conv3_3
I1202 02:08:56.425012 23462 net.cpp:394] conv3_3 <- conv3_2
I1202 02:08:56.425019 23462 net.cpp:356] conv3_3 -> conv3_3
I1202 02:08:56.425024 23462 net.cpp:96] Setting up conv3_3
I1202 02:08:56.439772 23462 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:08:56.439792 23462 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:08:56.439800 23462 net.cpp:67] Creating Layer relu3_3
I1202 02:08:56.439803 23462 net.cpp:394] relu3_3 <- conv3_3
I1202 02:08:56.439812 23462 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:08:56.439818 23462 net.cpp:96] Setting up relu3_3
I1202 02:08:56.439823 23462 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:08:56.439826 23462 layer_factory.hpp:78] Creating layer pool3
I1202 02:08:56.439832 23462 net.cpp:67] Creating Layer pool3
I1202 02:08:56.439836 23462 net.cpp:394] pool3 <- conv3_3
I1202 02:08:56.439841 23462 net.cpp:356] pool3 -> pool3
I1202 02:08:56.439846 23462 net.cpp:96] Setting up pool3
I1202 02:08:56.439852 23462 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:08:56.439857 23462 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:08:56.439863 23462 net.cpp:67] Creating Layer conv4_1
I1202 02:08:56.439867 23462 net.cpp:394] conv4_1 <- pool3
I1202 02:08:56.439872 23462 net.cpp:356] conv4_1 -> conv4_1
I1202 02:08:56.439877 23462 net.cpp:96] Setting up conv4_1
I1202 02:08:56.469163 23462 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:08:56.469187 23462 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:08:56.469195 23462 net.cpp:67] Creating Layer relu4_1
I1202 02:08:56.469199 23462 net.cpp:394] relu4_1 <- conv4_1
I1202 02:08:56.469208 23462 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:08:56.469214 23462 net.cpp:96] Setting up relu4_1
I1202 02:08:56.469220 23462 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:08:56.469223 23462 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:08:56.469230 23462 net.cpp:67] Creating Layer conv4_2
I1202 02:08:56.469233 23462 net.cpp:394] conv4_2 <- conv4_1
I1202 02:08:56.469239 23462 net.cpp:356] conv4_2 -> conv4_2
I1202 02:08:56.469245 23462 net.cpp:96] Setting up conv4_2
I1202 02:08:56.527084 23462 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:08:56.527114 23462 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:08:56.527122 23462 net.cpp:67] Creating Layer relu4_2
I1202 02:08:56.527127 23462 net.cpp:394] relu4_2 <- conv4_2
I1202 02:08:56.527134 23462 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:08:56.527140 23462 net.cpp:96] Setting up relu4_2
I1202 02:08:56.527145 23462 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:08:56.527149 23462 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:08:56.527158 23462 net.cpp:67] Creating Layer conv4_3
I1202 02:08:56.527161 23462 net.cpp:394] conv4_3 <- conv4_2
I1202 02:08:56.527166 23462 net.cpp:356] conv4_3 -> conv4_3
I1202 02:08:56.527173 23462 net.cpp:96] Setting up conv4_3
I1202 02:08:56.584816 23462 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:08:56.584842 23462 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:08:56.584849 23462 net.cpp:67] Creating Layer relu4_3
I1202 02:08:56.584854 23462 net.cpp:394] relu4_3 <- conv4_3
I1202 02:08:56.584861 23462 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:08:56.584877 23462 net.cpp:96] Setting up relu4_3
I1202 02:08:56.584883 23462 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:08:56.584887 23462 layer_factory.hpp:78] Creating layer pool4
I1202 02:08:56.584893 23462 net.cpp:67] Creating Layer pool4
I1202 02:08:56.584897 23462 net.cpp:394] pool4 <- conv4_3
I1202 02:08:56.584900 23462 net.cpp:356] pool4 -> pool4
I1202 02:08:56.584907 23462 net.cpp:96] Setting up pool4
I1202 02:08:56.584913 23462 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:08:56.584916 23462 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:08:56.584924 23462 net.cpp:67] Creating Layer conv5_1
I1202 02:08:56.584928 23462 net.cpp:394] conv5_1 <- pool4
I1202 02:08:56.584931 23462 net.cpp:356] conv5_1 -> conv5_1
I1202 02:08:56.584938 23462 net.cpp:96] Setting up conv5_1
I1202 02:08:56.642812 23462 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:08:56.642838 23462 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:08:56.642845 23462 net.cpp:67] Creating Layer relu5_1
I1202 02:08:56.642850 23462 net.cpp:394] relu5_1 <- conv5_1
I1202 02:08:56.642858 23462 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:08:56.642864 23462 net.cpp:96] Setting up relu5_1
I1202 02:08:56.642870 23462 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:08:56.642874 23462 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:08:56.642879 23462 net.cpp:67] Creating Layer conv5_2
I1202 02:08:56.642882 23462 net.cpp:394] conv5_2 <- conv5_1
I1202 02:08:56.642887 23462 net.cpp:356] conv5_2 -> conv5_2
I1202 02:08:56.642894 23462 net.cpp:96] Setting up conv5_2
I1202 02:08:56.700531 23462 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:08:56.700556 23462 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:08:56.700562 23462 net.cpp:67] Creating Layer relu5_2
I1202 02:08:56.700567 23462 net.cpp:394] relu5_2 <- conv5_2
I1202 02:08:56.700574 23462 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:08:56.700580 23462 net.cpp:96] Setting up relu5_2
I1202 02:08:56.700585 23462 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:08:56.700588 23462 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:08:56.700597 23462 net.cpp:67] Creating Layer conv5_3
I1202 02:08:56.700599 23462 net.cpp:394] conv5_3 <- conv5_2
I1202 02:08:56.700604 23462 net.cpp:356] conv5_3 -> conv5_3
I1202 02:08:56.700610 23462 net.cpp:96] Setting up conv5_3
I1202 02:08:56.758610 23462 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:08:56.758638 23462 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:08:56.758646 23462 net.cpp:67] Creating Layer relu5_3
I1202 02:08:56.758651 23462 net.cpp:394] relu5_3 <- conv5_3
I1202 02:08:56.758657 23462 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:08:56.758664 23462 net.cpp:96] Setting up relu5_3
I1202 02:08:56.758669 23462 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:08:56.758672 23462 layer_factory.hpp:78] Creating layer pool5
I1202 02:08:56.758683 23462 net.cpp:67] Creating Layer pool5
I1202 02:08:56.758687 23462 net.cpp:394] pool5 <- conv5_3
I1202 02:08:56.758692 23462 net.cpp:356] pool5 -> pool5
I1202 02:08:56.758698 23462 net.cpp:96] Setting up pool5
I1202 02:08:56.758707 23462 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:08:56.758709 23462 layer_factory.hpp:78] Creating layer fc6
I1202 02:08:56.758715 23462 net.cpp:67] Creating Layer fc6
I1202 02:08:56.758718 23462 net.cpp:394] fc6 <- pool5
I1202 02:08:56.758723 23462 net.cpp:356] fc6 -> fc6
I1202 02:08:56.758728 23462 net.cpp:96] Setting up fc6
I1202 02:08:59.268086 23462 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:08:59.268117 23462 layer_factory.hpp:78] Creating layer relu6
I1202 02:08:59.268126 23462 net.cpp:67] Creating Layer relu6
I1202 02:08:59.268132 23462 net.cpp:394] relu6 <- fc6
I1202 02:08:59.268139 23462 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:08:59.268146 23462 net.cpp:96] Setting up relu6
I1202 02:08:59.268162 23462 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:08:59.268169 23462 layer_factory.hpp:78] Creating layer drop6
I1202 02:08:59.268185 23462 net.cpp:67] Creating Layer drop6
I1202 02:08:59.268188 23462 net.cpp:394] drop6 <- fc6
I1202 02:08:59.268193 23462 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:08:59.268198 23462 net.cpp:96] Setting up drop6
I1202 02:08:59.268201 23462 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:08:59.268204 23462 layer_factory.hpp:78] Creating layer fc7
I1202 02:08:59.268210 23462 net.cpp:67] Creating Layer fc7
I1202 02:08:59.268213 23462 net.cpp:394] fc7 <- fc6
I1202 02:08:59.268219 23462 net.cpp:356] fc7 -> fc7
I1202 02:08:59.268226 23462 net.cpp:96] Setting up fc7
I1202 02:08:59.677244 23462 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:08:59.677275 23462 layer_factory.hpp:78] Creating layer relu7
I1202 02:08:59.677284 23462 net.cpp:67] Creating Layer relu7
I1202 02:08:59.677289 23462 net.cpp:394] relu7 <- fc7
I1202 02:08:59.677299 23462 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:08:59.677305 23462 net.cpp:96] Setting up relu7
I1202 02:08:59.677320 23462 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:08:59.677323 23462 layer_factory.hpp:78] Creating layer drop7
I1202 02:08:59.677328 23462 net.cpp:67] Creating Layer drop7
I1202 02:08:59.677331 23462 net.cpp:394] drop7 <- fc7
I1202 02:08:59.677335 23462 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:08:59.677340 23462 net.cpp:96] Setting up drop7
I1202 02:08:59.677345 23462 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:08:59.677347 23462 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:08:59.677355 23462 net.cpp:67] Creating Layer fc8_2
I1202 02:08:59.677357 23462 net.cpp:394] fc8_2 <- fc7
I1202 02:08:59.677362 23462 net.cpp:356] fc8_2 -> fc8_2
I1202 02:08:59.677369 23462 net.cpp:96] Setting up fc8_2
I1202 02:08:59.677579 23462 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:08:59.677589 23462 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:08:59.677594 23462 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:08:59.677597 23462 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:08:59.677603 23462 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:08:59.677608 23462 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:08:59.677613 23462 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:08:59.677618 23462 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:08:59.677619 23462 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:08:59.677623 23462 layer_factory.hpp:78] Creating layer loss
I1202 02:08:59.677628 23462 net.cpp:67] Creating Layer loss
I1202 02:08:59.677633 23462 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:08:59.677636 23462 net.cpp:394] loss <- label_data_1_split_0
I1202 02:08:59.677641 23462 net.cpp:356] loss -> (automatic)
I1202 02:08:59.677644 23462 net.cpp:96] Setting up loss
I1202 02:08:59.677652 23462 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:08:59.677655 23462 net.cpp:109]     with loss weight 1
I1202 02:08:59.677669 23462 layer_factory.hpp:78] Creating layer accuracy
I1202 02:08:59.677673 23462 net.cpp:67] Creating Layer accuracy
I1202 02:08:59.677676 23462 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:08:59.677680 23462 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:08:59.677685 23462 net.cpp:356] accuracy -> accuracy
I1202 02:08:59.677690 23462 net.cpp:96] Setting up accuracy
I1202 02:08:59.677698 23462 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:08:59.677702 23462 net.cpp:172] accuracy does not need backward computation.
I1202 02:08:59.677705 23462 net.cpp:170] loss needs backward computation.
I1202 02:08:59.677707 23462 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:08:59.677711 23462 net.cpp:170] fc8_2 needs backward computation.
I1202 02:08:59.677713 23462 net.cpp:170] drop7 needs backward computation.
I1202 02:08:59.677716 23462 net.cpp:170] relu7 needs backward computation.
I1202 02:08:59.677718 23462 net.cpp:170] fc7 needs backward computation.
I1202 02:08:59.677721 23462 net.cpp:170] drop6 needs backward computation.
I1202 02:08:59.677724 23462 net.cpp:170] relu6 needs backward computation.
I1202 02:08:59.677734 23462 net.cpp:170] fc6 needs backward computation.
I1202 02:08:59.677742 23462 net.cpp:170] pool5 needs backward computation.
I1202 02:08:59.677745 23462 net.cpp:170] relu5_3 needs backward computation.
I1202 02:08:59.677748 23462 net.cpp:170] conv5_3 needs backward computation.
I1202 02:08:59.677752 23462 net.cpp:170] relu5_2 needs backward computation.
I1202 02:08:59.677754 23462 net.cpp:170] conv5_2 needs backward computation.
I1202 02:08:59.677757 23462 net.cpp:170] relu5_1 needs backward computation.
I1202 02:08:59.677760 23462 net.cpp:170] conv5_1 needs backward computation.
I1202 02:08:59.677763 23462 net.cpp:170] pool4 needs backward computation.
I1202 02:08:59.677767 23462 net.cpp:170] relu4_3 needs backward computation.
I1202 02:08:59.677769 23462 net.cpp:170] conv4_3 needs backward computation.
I1202 02:08:59.677772 23462 net.cpp:170] relu4_2 needs backward computation.
I1202 02:08:59.677775 23462 net.cpp:170] conv4_2 needs backward computation.
I1202 02:08:59.677778 23462 net.cpp:170] relu4_1 needs backward computation.
I1202 02:08:59.677781 23462 net.cpp:170] conv4_1 needs backward computation.
I1202 02:08:59.677784 23462 net.cpp:170] pool3 needs backward computation.
I1202 02:08:59.677788 23462 net.cpp:170] relu3_3 needs backward computation.
I1202 02:08:59.677790 23462 net.cpp:170] conv3_3 needs backward computation.
I1202 02:08:59.677793 23462 net.cpp:170] relu3_2 needs backward computation.
I1202 02:08:59.677796 23462 net.cpp:170] conv3_2 needs backward computation.
I1202 02:08:59.677799 23462 net.cpp:170] relu3_1 needs backward computation.
I1202 02:08:59.677803 23462 net.cpp:170] conv3_1 needs backward computation.
I1202 02:08:59.677805 23462 net.cpp:170] pool2 needs backward computation.
I1202 02:08:59.677809 23462 net.cpp:170] relu2_2 needs backward computation.
I1202 02:08:59.677811 23462 net.cpp:170] conv2_2 needs backward computation.
I1202 02:08:59.677814 23462 net.cpp:170] relu2_1 needs backward computation.
I1202 02:08:59.677816 23462 net.cpp:170] conv2_1 needs backward computation.
I1202 02:08:59.677819 23462 net.cpp:170] pool1 needs backward computation.
I1202 02:08:59.677822 23462 net.cpp:170] relu1_2 needs backward computation.
I1202 02:08:59.677825 23462 net.cpp:170] conv1_2 needs backward computation.
I1202 02:08:59.677829 23462 net.cpp:170] relu1_1 needs backward computation.
I1202 02:08:59.677831 23462 net.cpp:170] conv1_1 needs backward computation.
I1202 02:08:59.677834 23462 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:08:59.677837 23462 net.cpp:172] data does not need backward computation.
I1202 02:08:59.677839 23462 net.cpp:208] This network produces output accuracy
I1202 02:08:59.677860 23462 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:08:59.677870 23462 net.cpp:219] Network initialization done.
I1202 02:08:59.677876 23462 net.cpp:220] Memory required for data: 921616692
I1202 02:08:59.677976 23462 solver.cpp:41] Solver scaffolding done.
I1202 02:08:59.677983 23462 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_2000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:09:07.496130 23462 solver.cpp:160] Solving small
I1202 02:09:07.496158 23462 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:09:07.496204 23462 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:10:31.579964 23462 solver.cpp:305] Test loss: 0.478697
I1202 02:10:31.580049 23462 solver.cpp:318] mean_score = test_score[0] { = 2889} / test_score[1] { = 3570 }
I1202 02:10:31.580060 23462 solver.cpp:319]            = 0.809244
I1202 02:10:31.580068 23462 solver.cpp:328]     Test net output #0: accuracy = 0.809244
I1202 02:10:31.580073 23462 solver.cpp:318] mean_score = test_score[2] { = 245} / test_score[3] { = 398 }
I1202 02:10:31.580078 23462 solver.cpp:319]            = 0.615578
I1202 02:10:31.580085 23462 solver.cpp:328]     Test net output #1: accuracy = 0.615578
I1202 02:10:31.580095 23462 solver.cpp:332]     Test net output #2: accuracy = 0.789819
I1202 02:10:31.580099 23462 solver.cpp:334]     Test net output #3: accuracy = 0.712411
I1202 02:10:32.275768 23462 solver.cpp:209] Iteration 0, loss = 0.390033
I1202 02:10:32.275796 23462 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:10:34.629055 23462 solver.cpp:209] Iteration 1, loss = 0.446667
I1202 02:10:34.629083 23462 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:10:36.640525 23462 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:10:40.759302 23462 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:10:44.806879 23462 solver.cpp:246] Iteration 2, loss = 0.463154
I1202 02:10:44.806913 23462 solver.cpp:251] Optimization Done.
I1202 02:10:44.806917 23462 caffe.cpp:121] Optimization Done.
I1202 02:10:44.949867 24039 caffe.cpp:99] Use GPU with device ID 0
I1202 02:10:45.137285 24039 caffe.cpp:107] Starting Optimization
I1202 02:10:45.137382 24039 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:10:45.137405 24039 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:10:45.138218 24039 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:10:45.138248 24039 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:10:45.138440 24039 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:10:45.138566 24039 layer_factory.hpp:78] Creating layer data
I1202 02:10:45.138587 24039 net.cpp:67] Creating Layer data
I1202 02:10:45.138593 24039 net.cpp:356] data -> data
I1202 02:10:45.138612 24039 net.cpp:356] data -> label
I1202 02:10:45.138619 24039 net.cpp:96] Setting up data
I1202 02:10:45.138625 24039 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:10:45.152659 24039 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:10:45.163496 24039 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:10:45.166301 24039 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:10:45.166326 24039 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:10:45.166332 24039 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:10:45.166364 24039 net.cpp:67] Creating Layer conv1_1
I1202 02:10:45.166369 24039 net.cpp:394] conv1_1 <- data
I1202 02:10:45.166383 24039 net.cpp:356] conv1_1 -> conv1_1
I1202 02:10:45.166393 24039 net.cpp:96] Setting up conv1_1
I1202 02:10:45.312471 24039 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:10:45.312507 24039 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:10:45.312518 24039 net.cpp:67] Creating Layer relu1_1
I1202 02:10:45.312522 24039 net.cpp:394] relu1_1 <- conv1_1
I1202 02:10:45.312530 24039 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:10:45.312536 24039 net.cpp:96] Setting up relu1_1
I1202 02:10:45.312546 24039 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:10:45.312549 24039 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:10:45.312556 24039 net.cpp:67] Creating Layer conv1_2
I1202 02:10:45.312559 24039 net.cpp:394] conv1_2 <- conv1_1
I1202 02:10:45.312566 24039 net.cpp:356] conv1_2 -> conv1_2
I1202 02:10:45.312572 24039 net.cpp:96] Setting up conv1_2
I1202 02:10:45.313647 24039 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:10:45.313662 24039 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:10:45.313668 24039 net.cpp:67] Creating Layer relu1_2
I1202 02:10:45.313670 24039 net.cpp:394] relu1_2 <- conv1_2
I1202 02:10:45.313675 24039 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:10:45.313680 24039 net.cpp:96] Setting up relu1_2
I1202 02:10:45.313685 24039 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:10:45.313689 24039 layer_factory.hpp:78] Creating layer pool1
I1202 02:10:45.313696 24039 net.cpp:67] Creating Layer pool1
I1202 02:10:45.313699 24039 net.cpp:394] pool1 <- conv1_2
I1202 02:10:45.313705 24039 net.cpp:356] pool1 -> pool1
I1202 02:10:45.313710 24039 net.cpp:96] Setting up pool1
I1202 02:10:45.313727 24039 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:10:45.313731 24039 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:10:45.313737 24039 net.cpp:67] Creating Layer conv2_1
I1202 02:10:45.313740 24039 net.cpp:394] conv2_1 <- pool1
I1202 02:10:45.313745 24039 net.cpp:356] conv2_1 -> conv2_1
I1202 02:10:45.313750 24039 net.cpp:96] Setting up conv2_1
I1202 02:10:45.315672 24039 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:10:45.315685 24039 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:10:45.315691 24039 net.cpp:67] Creating Layer relu2_1
I1202 02:10:45.315695 24039 net.cpp:394] relu2_1 <- conv2_1
I1202 02:10:45.315700 24039 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:10:45.315703 24039 net.cpp:96] Setting up relu2_1
I1202 02:10:45.315708 24039 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:10:45.315712 24039 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:10:45.315717 24039 net.cpp:67] Creating Layer conv2_2
I1202 02:10:45.315721 24039 net.cpp:394] conv2_2 <- conv2_1
I1202 02:10:45.315726 24039 net.cpp:356] conv2_2 -> conv2_2
I1202 02:10:45.315732 24039 net.cpp:96] Setting up conv2_2
I1202 02:10:45.319634 24039 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:10:45.319650 24039 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:10:45.319658 24039 net.cpp:67] Creating Layer relu2_2
I1202 02:10:45.319663 24039 net.cpp:394] relu2_2 <- conv2_2
I1202 02:10:45.319668 24039 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:10:45.319672 24039 net.cpp:96] Setting up relu2_2
I1202 02:10:45.319677 24039 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:10:45.319689 24039 layer_factory.hpp:78] Creating layer pool2
I1202 02:10:45.319694 24039 net.cpp:67] Creating Layer pool2
I1202 02:10:45.319696 24039 net.cpp:394] pool2 <- conv2_2
I1202 02:10:45.319702 24039 net.cpp:356] pool2 -> pool2
I1202 02:10:45.319707 24039 net.cpp:96] Setting up pool2
I1202 02:10:45.319713 24039 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:10:45.319716 24039 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:10:45.319722 24039 net.cpp:67] Creating Layer conv3_1
I1202 02:10:45.319725 24039 net.cpp:394] conv3_1 <- pool2
I1202 02:10:45.319731 24039 net.cpp:356] conv3_1 -> conv3_1
I1202 02:10:45.319743 24039 net.cpp:96] Setting up conv3_1
I1202 02:10:45.327158 24039 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:10:45.327175 24039 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:10:45.327182 24039 net.cpp:67] Creating Layer relu3_1
I1202 02:10:45.327184 24039 net.cpp:394] relu3_1 <- conv3_1
I1202 02:10:45.327190 24039 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:10:45.327195 24039 net.cpp:96] Setting up relu3_1
I1202 02:10:45.327200 24039 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:10:45.327203 24039 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:10:45.327208 24039 net.cpp:67] Creating Layer conv3_2
I1202 02:10:45.327211 24039 net.cpp:394] conv3_2 <- conv3_1
I1202 02:10:45.327217 24039 net.cpp:356] conv3_2 -> conv3_2
I1202 02:10:45.327224 24039 net.cpp:96] Setting up conv3_2
I1202 02:10:45.342126 24039 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:10:45.342146 24039 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:10:45.342154 24039 net.cpp:67] Creating Layer relu3_2
I1202 02:10:45.342157 24039 net.cpp:394] relu3_2 <- conv3_2
I1202 02:10:45.342165 24039 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:10:45.342171 24039 net.cpp:96] Setting up relu3_2
I1202 02:10:45.342177 24039 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:10:45.342180 24039 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:10:45.342185 24039 net.cpp:67] Creating Layer conv3_3
I1202 02:10:45.342188 24039 net.cpp:394] conv3_3 <- conv3_2
I1202 02:10:45.342195 24039 net.cpp:356] conv3_3 -> conv3_3
I1202 02:10:45.342200 24039 net.cpp:96] Setting up conv3_3
I1202 02:10:45.356961 24039 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:10:45.356981 24039 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:10:45.356992 24039 net.cpp:67] Creating Layer relu3_3
I1202 02:10:45.356997 24039 net.cpp:394] relu3_3 <- conv3_3
I1202 02:10:45.357002 24039 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:10:45.357008 24039 net.cpp:96] Setting up relu3_3
I1202 02:10:45.357013 24039 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:10:45.357017 24039 layer_factory.hpp:78] Creating layer pool3
I1202 02:10:45.357023 24039 net.cpp:67] Creating Layer pool3
I1202 02:10:45.357025 24039 net.cpp:394] pool3 <- conv3_3
I1202 02:10:45.357031 24039 net.cpp:356] pool3 -> pool3
I1202 02:10:45.357036 24039 net.cpp:96] Setting up pool3
I1202 02:10:45.357043 24039 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:10:45.357048 24039 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:10:45.357053 24039 net.cpp:67] Creating Layer conv4_1
I1202 02:10:45.357055 24039 net.cpp:394] conv4_1 <- pool3
I1202 02:10:45.357061 24039 net.cpp:356] conv4_1 -> conv4_1
I1202 02:10:45.357066 24039 net.cpp:96] Setting up conv4_1
I1202 02:10:45.386216 24039 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:10:45.386240 24039 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:10:45.386248 24039 net.cpp:67] Creating Layer relu4_1
I1202 02:10:45.386253 24039 net.cpp:394] relu4_1 <- conv4_1
I1202 02:10:45.386260 24039 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:10:45.386266 24039 net.cpp:96] Setting up relu4_1
I1202 02:10:45.386271 24039 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:10:45.386275 24039 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:10:45.386283 24039 net.cpp:67] Creating Layer conv4_2
I1202 02:10:45.386286 24039 net.cpp:394] conv4_2 <- conv4_1
I1202 02:10:45.386298 24039 net.cpp:356] conv4_2 -> conv4_2
I1202 02:10:45.386304 24039 net.cpp:96] Setting up conv4_2
I1202 02:10:45.444350 24039 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:10:45.444377 24039 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:10:45.444387 24039 net.cpp:67] Creating Layer relu4_2
I1202 02:10:45.444391 24039 net.cpp:394] relu4_2 <- conv4_2
I1202 02:10:45.444398 24039 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:10:45.444406 24039 net.cpp:96] Setting up relu4_2
I1202 02:10:45.444411 24039 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:10:45.444416 24039 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:10:45.444424 24039 net.cpp:67] Creating Layer conv4_3
I1202 02:10:45.444427 24039 net.cpp:394] conv4_3 <- conv4_2
I1202 02:10:45.444432 24039 net.cpp:356] conv4_3 -> conv4_3
I1202 02:10:45.444438 24039 net.cpp:96] Setting up conv4_3
I1202 02:10:45.502189 24039 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:10:45.502213 24039 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:10:45.502220 24039 net.cpp:67] Creating Layer relu4_3
I1202 02:10:45.502225 24039 net.cpp:394] relu4_3 <- conv4_3
I1202 02:10:45.502231 24039 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:10:45.502238 24039 net.cpp:96] Setting up relu4_3
I1202 02:10:45.502243 24039 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:10:45.502246 24039 layer_factory.hpp:78] Creating layer pool4
I1202 02:10:45.502254 24039 net.cpp:67] Creating Layer pool4
I1202 02:10:45.502256 24039 net.cpp:394] pool4 <- conv4_3
I1202 02:10:45.502261 24039 net.cpp:356] pool4 -> pool4
I1202 02:10:45.502266 24039 net.cpp:96] Setting up pool4
I1202 02:10:45.502274 24039 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:10:45.502277 24039 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:10:45.502285 24039 net.cpp:67] Creating Layer conv5_1
I1202 02:10:45.502288 24039 net.cpp:394] conv5_1 <- pool4
I1202 02:10:45.502292 24039 net.cpp:356] conv5_1 -> conv5_1
I1202 02:10:45.502301 24039 net.cpp:96] Setting up conv5_1
I1202 02:10:45.560377 24039 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:10:45.560403 24039 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:10:45.560411 24039 net.cpp:67] Creating Layer relu5_1
I1202 02:10:45.560415 24039 net.cpp:394] relu5_1 <- conv5_1
I1202 02:10:45.560423 24039 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:10:45.560430 24039 net.cpp:96] Setting up relu5_1
I1202 02:10:45.560436 24039 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:10:45.560438 24039 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:10:45.560452 24039 net.cpp:67] Creating Layer conv5_2
I1202 02:10:45.560456 24039 net.cpp:394] conv5_2 <- conv5_1
I1202 02:10:45.560462 24039 net.cpp:356] conv5_2 -> conv5_2
I1202 02:10:45.560468 24039 net.cpp:96] Setting up conv5_2
I1202 02:10:45.619148 24039 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:10:45.619189 24039 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:10:45.619199 24039 net.cpp:67] Creating Layer relu5_2
I1202 02:10:45.619204 24039 net.cpp:394] relu5_2 <- conv5_2
I1202 02:10:45.619210 24039 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:10:45.619216 24039 net.cpp:96] Setting up relu5_2
I1202 02:10:45.619222 24039 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:10:45.619225 24039 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:10:45.619232 24039 net.cpp:67] Creating Layer conv5_3
I1202 02:10:45.619235 24039 net.cpp:394] conv5_3 <- conv5_2
I1202 02:10:45.619240 24039 net.cpp:356] conv5_3 -> conv5_3
I1202 02:10:45.619246 24039 net.cpp:96] Setting up conv5_3
I1202 02:10:45.676861 24039 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:10:45.676884 24039 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:10:45.676892 24039 net.cpp:67] Creating Layer relu5_3
I1202 02:10:45.676897 24039 net.cpp:394] relu5_3 <- conv5_3
I1202 02:10:45.676903 24039 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:10:45.676908 24039 net.cpp:96] Setting up relu5_3
I1202 02:10:45.676913 24039 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:10:45.676925 24039 layer_factory.hpp:78] Creating layer pool5
I1202 02:10:45.676933 24039 net.cpp:67] Creating Layer pool5
I1202 02:10:45.676936 24039 net.cpp:394] pool5 <- conv5_3
I1202 02:10:45.676940 24039 net.cpp:356] pool5 -> pool5
I1202 02:10:45.676946 24039 net.cpp:96] Setting up pool5
I1202 02:10:45.676954 24039 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:10:45.676956 24039 layer_factory.hpp:78] Creating layer fc6
I1202 02:10:45.676971 24039 net.cpp:67] Creating Layer fc6
I1202 02:10:45.676975 24039 net.cpp:394] fc6 <- pool5
I1202 02:10:45.676980 24039 net.cpp:356] fc6 -> fc6
I1202 02:10:45.676985 24039 net.cpp:96] Setting up fc6
I1202 02:10:48.175168 24039 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:10:48.175199 24039 layer_factory.hpp:78] Creating layer relu6
I1202 02:10:48.175207 24039 net.cpp:67] Creating Layer relu6
I1202 02:10:48.175211 24039 net.cpp:394] relu6 <- fc6
I1202 02:10:48.175220 24039 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:10:48.175227 24039 net.cpp:96] Setting up relu6
I1202 02:10:48.175241 24039 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:10:48.175246 24039 layer_factory.hpp:78] Creating layer drop6
I1202 02:10:48.175252 24039 net.cpp:67] Creating Layer drop6
I1202 02:10:48.175256 24039 net.cpp:394] drop6 <- fc6
I1202 02:10:48.175259 24039 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:10:48.175264 24039 net.cpp:96] Setting up drop6
I1202 02:10:48.175267 24039 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:10:48.175271 24039 layer_factory.hpp:78] Creating layer fc7
I1202 02:10:48.175276 24039 net.cpp:67] Creating Layer fc7
I1202 02:10:48.175278 24039 net.cpp:394] fc7 <- fc6
I1202 02:10:48.175286 24039 net.cpp:356] fc7 -> fc7
I1202 02:10:48.175292 24039 net.cpp:96] Setting up fc7
I1202 02:10:48.583781 24039 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:10:48.583813 24039 layer_factory.hpp:78] Creating layer relu7
I1202 02:10:48.583822 24039 net.cpp:67] Creating Layer relu7
I1202 02:10:48.583827 24039 net.cpp:394] relu7 <- fc7
I1202 02:10:48.583833 24039 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:10:48.583839 24039 net.cpp:96] Setting up relu7
I1202 02:10:48.583854 24039 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:10:48.583858 24039 layer_factory.hpp:78] Creating layer drop7
I1202 02:10:48.583863 24039 net.cpp:67] Creating Layer drop7
I1202 02:10:48.583866 24039 net.cpp:394] drop7 <- fc7
I1202 02:10:48.583871 24039 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:10:48.583876 24039 net.cpp:96] Setting up drop7
I1202 02:10:48.583880 24039 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:10:48.583884 24039 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:10:48.583889 24039 net.cpp:67] Creating Layer fc8_2
I1202 02:10:48.583891 24039 net.cpp:394] fc8_2 <- fc7
I1202 02:10:48.583897 24039 net.cpp:356] fc8_2 -> fc8_2
I1202 02:10:48.583904 24039 net.cpp:96] Setting up fc8_2
I1202 02:10:48.584125 24039 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:10:48.584132 24039 layer_factory.hpp:78] Creating layer loss
I1202 02:10:48.584137 24039 net.cpp:67] Creating Layer loss
I1202 02:10:48.584141 24039 net.cpp:394] loss <- fc8_2
I1202 02:10:48.584146 24039 net.cpp:394] loss <- label
I1202 02:10:48.584156 24039 net.cpp:356] loss -> (automatic)
I1202 02:10:48.584159 24039 net.cpp:96] Setting up loss
I1202 02:10:48.584168 24039 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:10:48.584172 24039 net.cpp:109]     with loss weight 1
I1202 02:10:48.584206 24039 net.cpp:170] loss needs backward computation.
I1202 02:10:48.584210 24039 net.cpp:170] fc8_2 needs backward computation.
I1202 02:10:48.584213 24039 net.cpp:170] drop7 needs backward computation.
I1202 02:10:48.584215 24039 net.cpp:170] relu7 needs backward computation.
I1202 02:10:48.584218 24039 net.cpp:170] fc7 needs backward computation.
I1202 02:10:48.584221 24039 net.cpp:170] drop6 needs backward computation.
I1202 02:10:48.584223 24039 net.cpp:170] relu6 needs backward computation.
I1202 02:10:48.584226 24039 net.cpp:170] fc6 needs backward computation.
I1202 02:10:48.584238 24039 net.cpp:170] pool5 needs backward computation.
I1202 02:10:48.584240 24039 net.cpp:170] relu5_3 needs backward computation.
I1202 02:10:48.584249 24039 net.cpp:170] conv5_3 needs backward computation.
I1202 02:10:48.584251 24039 net.cpp:170] relu5_2 needs backward computation.
I1202 02:10:48.584254 24039 net.cpp:170] conv5_2 needs backward computation.
I1202 02:10:48.584256 24039 net.cpp:170] relu5_1 needs backward computation.
I1202 02:10:48.584259 24039 net.cpp:170] conv5_1 needs backward computation.
I1202 02:10:48.584262 24039 net.cpp:170] pool4 needs backward computation.
I1202 02:10:48.584265 24039 net.cpp:170] relu4_3 needs backward computation.
I1202 02:10:48.584269 24039 net.cpp:170] conv4_3 needs backward computation.
I1202 02:10:48.584271 24039 net.cpp:170] relu4_2 needs backward computation.
I1202 02:10:48.584275 24039 net.cpp:170] conv4_2 needs backward computation.
I1202 02:10:48.584277 24039 net.cpp:170] relu4_1 needs backward computation.
I1202 02:10:48.584280 24039 net.cpp:170] conv4_1 needs backward computation.
I1202 02:10:48.584282 24039 net.cpp:170] pool3 needs backward computation.
I1202 02:10:48.584285 24039 net.cpp:170] relu3_3 needs backward computation.
I1202 02:10:48.584288 24039 net.cpp:170] conv3_3 needs backward computation.
I1202 02:10:48.584291 24039 net.cpp:170] relu3_2 needs backward computation.
I1202 02:10:48.584295 24039 net.cpp:170] conv3_2 needs backward computation.
I1202 02:10:48.584298 24039 net.cpp:170] relu3_1 needs backward computation.
I1202 02:10:48.584301 24039 net.cpp:170] conv3_1 needs backward computation.
I1202 02:10:48.584305 24039 net.cpp:170] pool2 needs backward computation.
I1202 02:10:48.584307 24039 net.cpp:170] relu2_2 needs backward computation.
I1202 02:10:48.584311 24039 net.cpp:170] conv2_2 needs backward computation.
I1202 02:10:48.584313 24039 net.cpp:170] relu2_1 needs backward computation.
I1202 02:10:48.584316 24039 net.cpp:170] conv2_1 needs backward computation.
I1202 02:10:48.584318 24039 net.cpp:170] pool1 needs backward computation.
I1202 02:10:48.584321 24039 net.cpp:170] relu1_2 needs backward computation.
I1202 02:10:48.584324 24039 net.cpp:170] conv1_2 needs backward computation.
I1202 02:10:48.584327 24039 net.cpp:170] relu1_1 needs backward computation.
I1202 02:10:48.584329 24039 net.cpp:170] conv1_1 needs backward computation.
I1202 02:10:48.584332 24039 net.cpp:172] data does not need backward computation.
I1202 02:10:48.584350 24039 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:10:48.584357 24039 net.cpp:219] Network initialization done.
I1202 02:10:48.584360 24039 net.cpp:220] Memory required for data: 3686465924
I1202 02:10:48.585227 24039 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:10:48.585268 24039 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:10:48.585484 24039 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:10:48.585630 24039 layer_factory.hpp:78] Creating layer data
I1202 02:10:48.585640 24039 net.cpp:67] Creating Layer data
I1202 02:10:48.585645 24039 net.cpp:356] data -> data
I1202 02:10:48.585652 24039 net.cpp:356] data -> label
I1202 02:10:48.585659 24039 net.cpp:96] Setting up data
I1202 02:10:48.585662 24039 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:10:48.587162 24039 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:10:48.594635 24039 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:10:48.595533 24039 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:10:48.595543 24039 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:10:48.595547 24039 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:10:48.595561 24039 net.cpp:67] Creating Layer label_data_1_split
I1202 02:10:48.595564 24039 net.cpp:394] label_data_1_split <- label
I1202 02:10:48.595571 24039 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:10:48.595579 24039 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:10:48.595584 24039 net.cpp:96] Setting up label_data_1_split
I1202 02:10:48.595588 24039 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:10:48.595592 24039 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:10:48.595594 24039 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:10:48.595602 24039 net.cpp:67] Creating Layer conv1_1
I1202 02:10:48.595604 24039 net.cpp:394] conv1_1 <- data
I1202 02:10:48.595609 24039 net.cpp:356] conv1_1 -> conv1_1
I1202 02:10:48.595615 24039 net.cpp:96] Setting up conv1_1
I1202 02:10:48.595780 24039 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:10:48.595794 24039 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:10:48.595799 24039 net.cpp:67] Creating Layer relu1_1
I1202 02:10:48.595803 24039 net.cpp:394] relu1_1 <- conv1_1
I1202 02:10:48.595808 24039 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:10:48.595819 24039 net.cpp:96] Setting up relu1_1
I1202 02:10:48.595825 24039 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:10:48.595829 24039 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:10:48.595834 24039 net.cpp:67] Creating Layer conv1_2
I1202 02:10:48.595837 24039 net.cpp:394] conv1_2 <- conv1_1
I1202 02:10:48.595841 24039 net.cpp:356] conv1_2 -> conv1_2
I1202 02:10:48.595846 24039 net.cpp:96] Setting up conv1_2
I1202 02:10:48.596848 24039 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:10:48.596861 24039 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:10:48.596866 24039 net.cpp:67] Creating Layer relu1_2
I1202 02:10:48.596869 24039 net.cpp:394] relu1_2 <- conv1_2
I1202 02:10:48.596873 24039 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:10:48.596879 24039 net.cpp:96] Setting up relu1_2
I1202 02:10:48.596884 24039 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:10:48.596886 24039 layer_factory.hpp:78] Creating layer pool1
I1202 02:10:48.596891 24039 net.cpp:67] Creating Layer pool1
I1202 02:10:48.596894 24039 net.cpp:394] pool1 <- conv1_2
I1202 02:10:48.596899 24039 net.cpp:356] pool1 -> pool1
I1202 02:10:48.596902 24039 net.cpp:96] Setting up pool1
I1202 02:10:48.596909 24039 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:10:48.596912 24039 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:10:48.596917 24039 net.cpp:67] Creating Layer conv2_1
I1202 02:10:48.596920 24039 net.cpp:394] conv2_1 <- pool1
I1202 02:10:48.596925 24039 net.cpp:356] conv2_1 -> conv2_1
I1202 02:10:48.596930 24039 net.cpp:96] Setting up conv2_1
I1202 02:10:48.598927 24039 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:10:48.598940 24039 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:10:48.598947 24039 net.cpp:67] Creating Layer relu2_1
I1202 02:10:48.598949 24039 net.cpp:394] relu2_1 <- conv2_1
I1202 02:10:48.598954 24039 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:10:48.598959 24039 net.cpp:96] Setting up relu2_1
I1202 02:10:48.598964 24039 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:10:48.598968 24039 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:10:48.598973 24039 net.cpp:67] Creating Layer conv2_2
I1202 02:10:48.598975 24039 net.cpp:394] conv2_2 <- conv2_1
I1202 02:10:48.598980 24039 net.cpp:356] conv2_2 -> conv2_2
I1202 02:10:48.598985 24039 net.cpp:96] Setting up conv2_2
I1202 02:10:48.602648 24039 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:10:48.602658 24039 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:10:48.602663 24039 net.cpp:67] Creating Layer relu2_2
I1202 02:10:48.602668 24039 net.cpp:394] relu2_2 <- conv2_2
I1202 02:10:48.602671 24039 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:10:48.602675 24039 net.cpp:96] Setting up relu2_2
I1202 02:10:48.602680 24039 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:10:48.602684 24039 layer_factory.hpp:78] Creating layer pool2
I1202 02:10:48.602689 24039 net.cpp:67] Creating Layer pool2
I1202 02:10:48.602690 24039 net.cpp:394] pool2 <- conv2_2
I1202 02:10:48.602694 24039 net.cpp:356] pool2 -> pool2
I1202 02:10:48.602699 24039 net.cpp:96] Setting up pool2
I1202 02:10:48.602705 24039 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:10:48.602709 24039 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:10:48.602713 24039 net.cpp:67] Creating Layer conv3_1
I1202 02:10:48.602716 24039 net.cpp:394] conv3_1 <- pool2
I1202 02:10:48.602721 24039 net.cpp:356] conv3_1 -> conv3_1
I1202 02:10:48.602726 24039 net.cpp:96] Setting up conv3_1
I1202 02:10:48.609974 24039 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:10:48.609992 24039 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:10:48.609998 24039 net.cpp:67] Creating Layer relu3_1
I1202 02:10:48.610002 24039 net.cpp:394] relu3_1 <- conv3_1
I1202 02:10:48.610008 24039 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:10:48.610013 24039 net.cpp:96] Setting up relu3_1
I1202 02:10:48.610018 24039 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:10:48.610020 24039 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:10:48.610034 24039 net.cpp:67] Creating Layer conv3_2
I1202 02:10:48.610038 24039 net.cpp:394] conv3_2 <- conv3_1
I1202 02:10:48.610043 24039 net.cpp:356] conv3_2 -> conv3_2
I1202 02:10:48.610047 24039 net.cpp:96] Setting up conv3_2
I1202 02:10:48.624676 24039 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:10:48.624696 24039 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:10:48.624702 24039 net.cpp:67] Creating Layer relu3_2
I1202 02:10:48.624706 24039 net.cpp:394] relu3_2 <- conv3_2
I1202 02:10:48.624713 24039 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:10:48.624719 24039 net.cpp:96] Setting up relu3_2
I1202 02:10:48.624725 24039 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:10:48.624728 24039 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:10:48.624737 24039 net.cpp:67] Creating Layer conv3_3
I1202 02:10:48.624739 24039 net.cpp:394] conv3_3 <- conv3_2
I1202 02:10:48.624745 24039 net.cpp:356] conv3_3 -> conv3_3
I1202 02:10:48.624750 24039 net.cpp:96] Setting up conv3_3
I1202 02:10:48.639555 24039 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:10:48.639575 24039 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:10:48.639585 24039 net.cpp:67] Creating Layer relu3_3
I1202 02:10:48.639588 24039 net.cpp:394] relu3_3 <- conv3_3
I1202 02:10:48.639600 24039 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:10:48.639606 24039 net.cpp:96] Setting up relu3_3
I1202 02:10:48.639611 24039 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:10:48.639616 24039 layer_factory.hpp:78] Creating layer pool3
I1202 02:10:48.639621 24039 net.cpp:67] Creating Layer pool3
I1202 02:10:48.639623 24039 net.cpp:394] pool3 <- conv3_3
I1202 02:10:48.639629 24039 net.cpp:356] pool3 -> pool3
I1202 02:10:48.639634 24039 net.cpp:96] Setting up pool3
I1202 02:10:48.639642 24039 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:10:48.639646 24039 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:10:48.639652 24039 net.cpp:67] Creating Layer conv4_1
I1202 02:10:48.639654 24039 net.cpp:394] conv4_1 <- pool3
I1202 02:10:48.639660 24039 net.cpp:356] conv4_1 -> conv4_1
I1202 02:10:48.639665 24039 net.cpp:96] Setting up conv4_1
I1202 02:10:48.668978 24039 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:10:48.669003 24039 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:10:48.669011 24039 net.cpp:67] Creating Layer relu4_1
I1202 02:10:48.669016 24039 net.cpp:394] relu4_1 <- conv4_1
I1202 02:10:48.669023 24039 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:10:48.669029 24039 net.cpp:96] Setting up relu4_1
I1202 02:10:48.669034 24039 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:10:48.669039 24039 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:10:48.669044 24039 net.cpp:67] Creating Layer conv4_2
I1202 02:10:48.669049 24039 net.cpp:394] conv4_2 <- conv4_1
I1202 02:10:48.669054 24039 net.cpp:356] conv4_2 -> conv4_2
I1202 02:10:48.669059 24039 net.cpp:96] Setting up conv4_2
I1202 02:10:48.726636 24039 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:10:48.726671 24039 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:10:48.726680 24039 net.cpp:67] Creating Layer relu4_2
I1202 02:10:48.726685 24039 net.cpp:394] relu4_2 <- conv4_2
I1202 02:10:48.726691 24039 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:10:48.726698 24039 net.cpp:96] Setting up relu4_2
I1202 02:10:48.726703 24039 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:10:48.726706 24039 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:10:48.726713 24039 net.cpp:67] Creating Layer conv4_3
I1202 02:10:48.726716 24039 net.cpp:394] conv4_3 <- conv4_2
I1202 02:10:48.726721 24039 net.cpp:356] conv4_3 -> conv4_3
I1202 02:10:48.726729 24039 net.cpp:96] Setting up conv4_3
I1202 02:10:48.784601 24039 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:10:48.784627 24039 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:10:48.784634 24039 net.cpp:67] Creating Layer relu4_3
I1202 02:10:48.784638 24039 net.cpp:394] relu4_3 <- conv4_3
I1202 02:10:48.784646 24039 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:10:48.784662 24039 net.cpp:96] Setting up relu4_3
I1202 02:10:48.784667 24039 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:10:48.784672 24039 layer_factory.hpp:78] Creating layer pool4
I1202 02:10:48.784677 24039 net.cpp:67] Creating Layer pool4
I1202 02:10:48.784679 24039 net.cpp:394] pool4 <- conv4_3
I1202 02:10:48.784684 24039 net.cpp:356] pool4 -> pool4
I1202 02:10:48.784689 24039 net.cpp:96] Setting up pool4
I1202 02:10:48.784696 24039 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:10:48.784699 24039 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:10:48.784708 24039 net.cpp:67] Creating Layer conv5_1
I1202 02:10:48.784713 24039 net.cpp:394] conv5_1 <- pool4
I1202 02:10:48.784716 24039 net.cpp:356] conv5_1 -> conv5_1
I1202 02:10:48.784721 24039 net.cpp:96] Setting up conv5_1
I1202 02:10:48.842492 24039 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:10:48.842519 24039 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:10:48.842527 24039 net.cpp:67] Creating Layer relu5_1
I1202 02:10:48.842532 24039 net.cpp:394] relu5_1 <- conv5_1
I1202 02:10:48.842538 24039 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:10:48.842545 24039 net.cpp:96] Setting up relu5_1
I1202 02:10:48.842550 24039 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:10:48.842553 24039 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:10:48.842560 24039 net.cpp:67] Creating Layer conv5_2
I1202 02:10:48.842562 24039 net.cpp:394] conv5_2 <- conv5_1
I1202 02:10:48.842568 24039 net.cpp:356] conv5_2 -> conv5_2
I1202 02:10:48.842574 24039 net.cpp:96] Setting up conv5_2
I1202 02:10:48.900431 24039 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:10:48.900456 24039 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:10:48.900463 24039 net.cpp:67] Creating Layer relu5_2
I1202 02:10:48.900468 24039 net.cpp:394] relu5_2 <- conv5_2
I1202 02:10:48.900475 24039 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:10:48.900480 24039 net.cpp:96] Setting up relu5_2
I1202 02:10:48.900485 24039 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:10:48.900490 24039 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:10:48.900496 24039 net.cpp:67] Creating Layer conv5_3
I1202 02:10:48.900499 24039 net.cpp:394] conv5_3 <- conv5_2
I1202 02:10:48.900506 24039 net.cpp:356] conv5_3 -> conv5_3
I1202 02:10:48.900511 24039 net.cpp:96] Setting up conv5_3
I1202 02:10:48.958418 24039 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:10:48.958446 24039 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:10:48.958456 24039 net.cpp:67] Creating Layer relu5_3
I1202 02:10:48.958461 24039 net.cpp:394] relu5_3 <- conv5_3
I1202 02:10:48.958467 24039 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:10:48.958473 24039 net.cpp:96] Setting up relu5_3
I1202 02:10:48.958479 24039 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:10:48.958482 24039 layer_factory.hpp:78] Creating layer pool5
I1202 02:10:48.958493 24039 net.cpp:67] Creating Layer pool5
I1202 02:10:48.958497 24039 net.cpp:394] pool5 <- conv5_3
I1202 02:10:48.958503 24039 net.cpp:356] pool5 -> pool5
I1202 02:10:48.958508 24039 net.cpp:96] Setting up pool5
I1202 02:10:48.958516 24039 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:10:48.958519 24039 layer_factory.hpp:78] Creating layer fc6
I1202 02:10:48.958525 24039 net.cpp:67] Creating Layer fc6
I1202 02:10:48.958528 24039 net.cpp:394] fc6 <- pool5
I1202 02:10:48.958534 24039 net.cpp:356] fc6 -> fc6
I1202 02:10:48.958539 24039 net.cpp:96] Setting up fc6
I1202 02:10:51.457820 24039 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:10:51.457850 24039 layer_factory.hpp:78] Creating layer relu6
I1202 02:10:51.457859 24039 net.cpp:67] Creating Layer relu6
I1202 02:10:51.457864 24039 net.cpp:394] relu6 <- fc6
I1202 02:10:51.457872 24039 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:10:51.457880 24039 net.cpp:96] Setting up relu6
I1202 02:10:51.457895 24039 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:10:51.457897 24039 layer_factory.hpp:78] Creating layer drop6
I1202 02:10:51.457913 24039 net.cpp:67] Creating Layer drop6
I1202 02:10:51.457916 24039 net.cpp:394] drop6 <- fc6
I1202 02:10:51.457921 24039 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:10:51.457926 24039 net.cpp:96] Setting up drop6
I1202 02:10:51.457928 24039 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:10:51.457931 24039 layer_factory.hpp:78] Creating layer fc7
I1202 02:10:51.457938 24039 net.cpp:67] Creating Layer fc7
I1202 02:10:51.457942 24039 net.cpp:394] fc7 <- fc6
I1202 02:10:51.457947 24039 net.cpp:356] fc7 -> fc7
I1202 02:10:51.457952 24039 net.cpp:96] Setting up fc7
I1202 02:10:51.867398 24039 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:10:51.867429 24039 layer_factory.hpp:78] Creating layer relu7
I1202 02:10:51.867439 24039 net.cpp:67] Creating Layer relu7
I1202 02:10:51.867444 24039 net.cpp:394] relu7 <- fc7
I1202 02:10:51.867450 24039 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:10:51.867456 24039 net.cpp:96] Setting up relu7
I1202 02:10:51.867475 24039 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:10:51.867478 24039 layer_factory.hpp:78] Creating layer drop7
I1202 02:10:51.867485 24039 net.cpp:67] Creating Layer drop7
I1202 02:10:51.867486 24039 net.cpp:394] drop7 <- fc7
I1202 02:10:51.867492 24039 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:10:51.867497 24039 net.cpp:96] Setting up drop7
I1202 02:10:51.867501 24039 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:10:51.867504 24039 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:10:51.867509 24039 net.cpp:67] Creating Layer fc8_2
I1202 02:10:51.867512 24039 net.cpp:394] fc8_2 <- fc7
I1202 02:10:51.867517 24039 net.cpp:356] fc8_2 -> fc8_2
I1202 02:10:51.867524 24039 net.cpp:96] Setting up fc8_2
I1202 02:10:51.867749 24039 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:10:51.867758 24039 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:10:51.867763 24039 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:10:51.867765 24039 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:10:51.867770 24039 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:10:51.867775 24039 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:10:51.867780 24039 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:10:51.867784 24039 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:10:51.867787 24039 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:10:51.867790 24039 layer_factory.hpp:78] Creating layer loss
I1202 02:10:51.867796 24039 net.cpp:67] Creating Layer loss
I1202 02:10:51.867799 24039 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:10:51.867804 24039 net.cpp:394] loss <- label_data_1_split_0
I1202 02:10:51.867810 24039 net.cpp:356] loss -> (automatic)
I1202 02:10:51.867813 24039 net.cpp:96] Setting up loss
I1202 02:10:51.867820 24039 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:10:51.867822 24039 net.cpp:109]     with loss weight 1
I1202 02:10:51.867840 24039 layer_factory.hpp:78] Creating layer accuracy
I1202 02:10:51.867846 24039 net.cpp:67] Creating Layer accuracy
I1202 02:10:51.867848 24039 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:10:51.867851 24039 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:10:51.867857 24039 net.cpp:356] accuracy -> accuracy
I1202 02:10:51.867862 24039 net.cpp:96] Setting up accuracy
I1202 02:10:51.867871 24039 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:10:51.867878 24039 net.cpp:172] accuracy does not need backward computation.
I1202 02:10:51.867882 24039 net.cpp:170] loss needs backward computation.
I1202 02:10:51.867885 24039 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:10:51.867887 24039 net.cpp:170] fc8_2 needs backward computation.
I1202 02:10:51.867890 24039 net.cpp:170] drop7 needs backward computation.
I1202 02:10:51.867893 24039 net.cpp:170] relu7 needs backward computation.
I1202 02:10:51.867895 24039 net.cpp:170] fc7 needs backward computation.
I1202 02:10:51.867898 24039 net.cpp:170] drop6 needs backward computation.
I1202 02:10:51.867902 24039 net.cpp:170] relu6 needs backward computation.
I1202 02:10:51.867912 24039 net.cpp:170] fc6 needs backward computation.
I1202 02:10:51.867915 24039 net.cpp:170] pool5 needs backward computation.
I1202 02:10:51.867918 24039 net.cpp:170] relu5_3 needs backward computation.
I1202 02:10:51.867921 24039 net.cpp:170] conv5_3 needs backward computation.
I1202 02:10:51.867924 24039 net.cpp:170] relu5_2 needs backward computation.
I1202 02:10:51.867928 24039 net.cpp:170] conv5_2 needs backward computation.
I1202 02:10:51.867929 24039 net.cpp:170] relu5_1 needs backward computation.
I1202 02:10:51.867933 24039 net.cpp:170] conv5_1 needs backward computation.
I1202 02:10:51.867935 24039 net.cpp:170] pool4 needs backward computation.
I1202 02:10:51.867938 24039 net.cpp:170] relu4_3 needs backward computation.
I1202 02:10:51.867941 24039 net.cpp:170] conv4_3 needs backward computation.
I1202 02:10:51.867944 24039 net.cpp:170] relu4_2 needs backward computation.
I1202 02:10:51.867946 24039 net.cpp:170] conv4_2 needs backward computation.
I1202 02:10:51.867949 24039 net.cpp:170] relu4_1 needs backward computation.
I1202 02:10:51.867952 24039 net.cpp:170] conv4_1 needs backward computation.
I1202 02:10:51.867955 24039 net.cpp:170] pool3 needs backward computation.
I1202 02:10:51.867957 24039 net.cpp:170] relu3_3 needs backward computation.
I1202 02:10:51.867960 24039 net.cpp:170] conv3_3 needs backward computation.
I1202 02:10:51.867964 24039 net.cpp:170] relu3_2 needs backward computation.
I1202 02:10:51.867966 24039 net.cpp:170] conv3_2 needs backward computation.
I1202 02:10:51.867969 24039 net.cpp:170] relu3_1 needs backward computation.
I1202 02:10:51.867971 24039 net.cpp:170] conv3_1 needs backward computation.
I1202 02:10:51.867974 24039 net.cpp:170] pool2 needs backward computation.
I1202 02:10:51.867977 24039 net.cpp:170] relu2_2 needs backward computation.
I1202 02:10:51.867980 24039 net.cpp:170] conv2_2 needs backward computation.
I1202 02:10:51.867982 24039 net.cpp:170] relu2_1 needs backward computation.
I1202 02:10:51.867985 24039 net.cpp:170] conv2_1 needs backward computation.
I1202 02:10:51.867988 24039 net.cpp:170] pool1 needs backward computation.
I1202 02:10:51.867991 24039 net.cpp:170] relu1_2 needs backward computation.
I1202 02:10:51.867993 24039 net.cpp:170] conv1_2 needs backward computation.
I1202 02:10:51.867996 24039 net.cpp:170] relu1_1 needs backward computation.
I1202 02:10:51.868000 24039 net.cpp:170] conv1_1 needs backward computation.
I1202 02:10:51.868002 24039 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:10:51.868005 24039 net.cpp:172] data does not need backward computation.
I1202 02:10:51.868007 24039 net.cpp:208] This network produces output accuracy
I1202 02:10:51.868028 24039 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:10:51.868034 24039 net.cpp:219] Network initialization done.
I1202 02:10:51.868037 24039 net.cpp:220] Memory required for data: 921616692
I1202 02:10:51.868139 24039 solver.cpp:41] Solver scaffolding done.
I1202 02:10:51.868145 24039 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_4000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:10:56.102581 24039 solver.cpp:160] Solving small
I1202 02:10:56.102609 24039 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:10:56.102658 24039 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:12:20.758525 24039 solver.cpp:305] Test loss: 0.493079
I1202 02:12:20.758590 24039 solver.cpp:318] mean_score = test_score[0] { = 2743} / test_score[1] { = 3570 }
I1202 02:12:20.758599 24039 solver.cpp:319]            = 0.768347
I1202 02:12:20.758608 24039 solver.cpp:328]     Test net output #0: accuracy = 0.768347
I1202 02:12:20.758612 24039 solver.cpp:318] mean_score = test_score[2] { = 281} / test_score[3] { = 398 }
I1202 02:12:20.758617 24039 solver.cpp:319]            = 0.70603
I1202 02:12:20.758621 24039 solver.cpp:328]     Test net output #1: accuracy = 0.70603
I1202 02:12:20.758631 24039 solver.cpp:332]     Test net output #2: accuracy = 0.762097
I1202 02:12:20.758636 24039 solver.cpp:334]     Test net output #3: accuracy = 0.737189
I1202 02:12:21.456127 24039 solver.cpp:209] Iteration 0, loss = 0.351362
I1202 02:12:21.456157 24039 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:12:23.800758 24039 solver.cpp:209] Iteration 1, loss = 0.576874
I1202 02:12:23.800788 24039 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:12:25.782009 24039 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:12:29.620054 24039 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:12:34.269778 24039 solver.cpp:246] Iteration 2, loss = 0.473095
I1202 02:12:34.269811 24039 solver.cpp:251] Optimization Done.
I1202 02:12:34.269815 24039 caffe.cpp:121] Optimization Done.
I1202 02:12:34.413144 24599 caffe.cpp:99] Use GPU with device ID 0
I1202 02:12:34.596976 24599 caffe.cpp:107] Starting Optimization
I1202 02:12:34.597071 24599 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:12:34.597095 24599 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:12:34.597878 24599 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:12:34.597908 24599 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:12:34.598100 24599 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:12:34.598218 24599 layer_factory.hpp:78] Creating layer data
I1202 02:12:34.598243 24599 net.cpp:67] Creating Layer data
I1202 02:12:34.598258 24599 net.cpp:356] data -> data
I1202 02:12:34.598294 24599 net.cpp:356] data -> label
I1202 02:12:34.598309 24599 net.cpp:96] Setting up data
I1202 02:12:34.598320 24599 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:12:34.612371 24599 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:12:34.622961 24599 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:12:34.625797 24599 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:12:34.625823 24599 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:12:34.625828 24599 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:12:34.625844 24599 net.cpp:67] Creating Layer conv1_1
I1202 02:12:34.625848 24599 net.cpp:394] conv1_1 <- data
I1202 02:12:34.625861 24599 net.cpp:356] conv1_1 -> conv1_1
I1202 02:12:34.625879 24599 net.cpp:96] Setting up conv1_1
I1202 02:12:34.767155 24599 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:12:34.767190 24599 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:12:34.767202 24599 net.cpp:67] Creating Layer relu1_1
I1202 02:12:34.767206 24599 net.cpp:394] relu1_1 <- conv1_1
I1202 02:12:34.767213 24599 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:12:34.767220 24599 net.cpp:96] Setting up relu1_1
I1202 02:12:34.767230 24599 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:12:34.767233 24599 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:12:34.767242 24599 net.cpp:67] Creating Layer conv1_2
I1202 02:12:34.767246 24599 net.cpp:394] conv1_2 <- conv1_1
I1202 02:12:34.767251 24599 net.cpp:356] conv1_2 -> conv1_2
I1202 02:12:34.767257 24599 net.cpp:96] Setting up conv1_2
I1202 02:12:34.768339 24599 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:12:34.768355 24599 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:12:34.768362 24599 net.cpp:67] Creating Layer relu1_2
I1202 02:12:34.768364 24599 net.cpp:394] relu1_2 <- conv1_2
I1202 02:12:34.768369 24599 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:12:34.768374 24599 net.cpp:96] Setting up relu1_2
I1202 02:12:34.768379 24599 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:12:34.768383 24599 layer_factory.hpp:78] Creating layer pool1
I1202 02:12:34.768390 24599 net.cpp:67] Creating Layer pool1
I1202 02:12:34.768393 24599 net.cpp:394] pool1 <- conv1_2
I1202 02:12:34.768399 24599 net.cpp:356] pool1 -> pool1
I1202 02:12:34.768405 24599 net.cpp:96] Setting up pool1
I1202 02:12:34.768422 24599 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:12:34.768426 24599 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:12:34.768432 24599 net.cpp:67] Creating Layer conv2_1
I1202 02:12:34.768436 24599 net.cpp:394] conv2_1 <- pool1
I1202 02:12:34.768440 24599 net.cpp:356] conv2_1 -> conv2_1
I1202 02:12:34.768446 24599 net.cpp:96] Setting up conv2_1
I1202 02:12:34.770366 24599 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:12:34.770380 24599 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:12:34.770386 24599 net.cpp:67] Creating Layer relu2_1
I1202 02:12:34.770390 24599 net.cpp:394] relu2_1 <- conv2_1
I1202 02:12:34.770395 24599 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:12:34.770398 24599 net.cpp:96] Setting up relu2_1
I1202 02:12:34.770405 24599 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:12:34.770407 24599 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:12:34.770413 24599 net.cpp:67] Creating Layer conv2_2
I1202 02:12:34.770416 24599 net.cpp:394] conv2_2 <- conv2_1
I1202 02:12:34.770422 24599 net.cpp:356] conv2_2 -> conv2_2
I1202 02:12:34.770428 24599 net.cpp:96] Setting up conv2_2
I1202 02:12:34.774222 24599 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:12:34.774238 24599 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:12:34.774243 24599 net.cpp:67] Creating Layer relu2_2
I1202 02:12:34.774247 24599 net.cpp:394] relu2_2 <- conv2_2
I1202 02:12:34.774251 24599 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:12:34.774256 24599 net.cpp:96] Setting up relu2_2
I1202 02:12:34.774262 24599 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:12:34.774273 24599 layer_factory.hpp:78] Creating layer pool2
I1202 02:12:34.774279 24599 net.cpp:67] Creating Layer pool2
I1202 02:12:34.774282 24599 net.cpp:394] pool2 <- conv2_2
I1202 02:12:34.774288 24599 net.cpp:356] pool2 -> pool2
I1202 02:12:34.774293 24599 net.cpp:96] Setting up pool2
I1202 02:12:34.774299 24599 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:12:34.774303 24599 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:12:34.774310 24599 net.cpp:67] Creating Layer conv3_1
I1202 02:12:34.774313 24599 net.cpp:394] conv3_1 <- pool2
I1202 02:12:34.774317 24599 net.cpp:356] conv3_1 -> conv3_1
I1202 02:12:34.774323 24599 net.cpp:96] Setting up conv3_1
I1202 02:12:34.781745 24599 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:12:34.781760 24599 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:12:34.781769 24599 net.cpp:67] Creating Layer relu3_1
I1202 02:12:34.781771 24599 net.cpp:394] relu3_1 <- conv3_1
I1202 02:12:34.781776 24599 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:12:34.781781 24599 net.cpp:96] Setting up relu3_1
I1202 02:12:34.781786 24599 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:12:34.781790 24599 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:12:34.781795 24599 net.cpp:67] Creating Layer conv3_2
I1202 02:12:34.781798 24599 net.cpp:394] conv3_2 <- conv3_1
I1202 02:12:34.781805 24599 net.cpp:356] conv3_2 -> conv3_2
I1202 02:12:34.781810 24599 net.cpp:96] Setting up conv3_2
I1202 02:12:34.796723 24599 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:12:34.796741 24599 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:12:34.796749 24599 net.cpp:67] Creating Layer relu3_2
I1202 02:12:34.796753 24599 net.cpp:394] relu3_2 <- conv3_2
I1202 02:12:34.796759 24599 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:12:34.796766 24599 net.cpp:96] Setting up relu3_2
I1202 02:12:34.796771 24599 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:12:34.796774 24599 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:12:34.796780 24599 net.cpp:67] Creating Layer conv3_3
I1202 02:12:34.796783 24599 net.cpp:394] conv3_3 <- conv3_2
I1202 02:12:34.796788 24599 net.cpp:356] conv3_3 -> conv3_3
I1202 02:12:34.796794 24599 net.cpp:96] Setting up conv3_3
I1202 02:12:34.811512 24599 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:12:34.811534 24599 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:12:34.811543 24599 net.cpp:67] Creating Layer relu3_3
I1202 02:12:34.811547 24599 net.cpp:394] relu3_3 <- conv3_3
I1202 02:12:34.811553 24599 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:12:34.811559 24599 net.cpp:96] Setting up relu3_3
I1202 02:12:34.811565 24599 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:12:34.811568 24599 layer_factory.hpp:78] Creating layer pool3
I1202 02:12:34.811573 24599 net.cpp:67] Creating Layer pool3
I1202 02:12:34.811576 24599 net.cpp:394] pool3 <- conv3_3
I1202 02:12:34.811581 24599 net.cpp:356] pool3 -> pool3
I1202 02:12:34.811586 24599 net.cpp:96] Setting up pool3
I1202 02:12:34.811594 24599 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:12:34.811597 24599 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:12:34.811602 24599 net.cpp:67] Creating Layer conv4_1
I1202 02:12:34.811605 24599 net.cpp:394] conv4_1 <- pool3
I1202 02:12:34.811610 24599 net.cpp:356] conv4_1 -> conv4_1
I1202 02:12:34.811615 24599 net.cpp:96] Setting up conv4_1
I1202 02:12:34.840772 24599 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:12:34.840797 24599 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:12:34.840806 24599 net.cpp:67] Creating Layer relu4_1
I1202 02:12:34.840811 24599 net.cpp:394] relu4_1 <- conv4_1
I1202 02:12:34.840817 24599 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:12:34.840824 24599 net.cpp:96] Setting up relu4_1
I1202 02:12:34.840831 24599 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:12:34.840833 24599 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:12:34.840841 24599 net.cpp:67] Creating Layer conv4_2
I1202 02:12:34.840843 24599 net.cpp:394] conv4_2 <- conv4_1
I1202 02:12:34.840858 24599 net.cpp:356] conv4_2 -> conv4_2
I1202 02:12:34.840865 24599 net.cpp:96] Setting up conv4_2
I1202 02:12:34.898710 24599 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:12:34.898737 24599 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:12:34.898747 24599 net.cpp:67] Creating Layer relu4_2
I1202 02:12:34.898752 24599 net.cpp:394] relu4_2 <- conv4_2
I1202 02:12:34.898759 24599 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:12:34.898767 24599 net.cpp:96] Setting up relu4_2
I1202 02:12:34.898773 24599 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:12:34.898777 24599 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:12:34.898783 24599 net.cpp:67] Creating Layer conv4_3
I1202 02:12:34.898787 24599 net.cpp:394] conv4_3 <- conv4_2
I1202 02:12:34.898792 24599 net.cpp:356] conv4_3 -> conv4_3
I1202 02:12:34.898797 24599 net.cpp:96] Setting up conv4_3
I1202 02:12:34.956831 24599 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:12:34.956856 24599 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:12:34.956864 24599 net.cpp:67] Creating Layer relu4_3
I1202 02:12:34.956869 24599 net.cpp:394] relu4_3 <- conv4_3
I1202 02:12:34.956876 24599 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:12:34.956883 24599 net.cpp:96] Setting up relu4_3
I1202 02:12:34.956888 24599 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:12:34.956892 24599 layer_factory.hpp:78] Creating layer pool4
I1202 02:12:34.956897 24599 net.cpp:67] Creating Layer pool4
I1202 02:12:34.956900 24599 net.cpp:394] pool4 <- conv4_3
I1202 02:12:34.956905 24599 net.cpp:356] pool4 -> pool4
I1202 02:12:34.956912 24599 net.cpp:96] Setting up pool4
I1202 02:12:34.956918 24599 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:12:34.956922 24599 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:12:34.956929 24599 net.cpp:67] Creating Layer conv5_1
I1202 02:12:34.956933 24599 net.cpp:394] conv5_1 <- pool4
I1202 02:12:34.956939 24599 net.cpp:356] conv5_1 -> conv5_1
I1202 02:12:34.956946 24599 net.cpp:96] Setting up conv5_1
I1202 02:12:35.014804 24599 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:12:35.014829 24599 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:12:35.014838 24599 net.cpp:67] Creating Layer relu5_1
I1202 02:12:35.014842 24599 net.cpp:394] relu5_1 <- conv5_1
I1202 02:12:35.014857 24599 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:12:35.014864 24599 net.cpp:96] Setting up relu5_1
I1202 02:12:35.014869 24599 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:12:35.014873 24599 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:12:35.014879 24599 net.cpp:67] Creating Layer conv5_2
I1202 02:12:35.014883 24599 net.cpp:394] conv5_2 <- conv5_1
I1202 02:12:35.014889 24599 net.cpp:356] conv5_2 -> conv5_2
I1202 02:12:35.014895 24599 net.cpp:96] Setting up conv5_2
I1202 02:12:35.072638 24599 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:12:35.072664 24599 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:12:35.072674 24599 net.cpp:67] Creating Layer relu5_2
I1202 02:12:35.072679 24599 net.cpp:394] relu5_2 <- conv5_2
I1202 02:12:35.072685 24599 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:12:35.072691 24599 net.cpp:96] Setting up relu5_2
I1202 02:12:35.072697 24599 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:12:35.072700 24599 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:12:35.072707 24599 net.cpp:67] Creating Layer conv5_3
I1202 02:12:35.072711 24599 net.cpp:394] conv5_3 <- conv5_2
I1202 02:12:35.072715 24599 net.cpp:356] conv5_3 -> conv5_3
I1202 02:12:35.072722 24599 net.cpp:96] Setting up conv5_3
I1202 02:12:35.130401 24599 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:12:35.130427 24599 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:12:35.130435 24599 net.cpp:67] Creating Layer relu5_3
I1202 02:12:35.130439 24599 net.cpp:394] relu5_3 <- conv5_3
I1202 02:12:35.130446 24599 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:12:35.130453 24599 net.cpp:96] Setting up relu5_3
I1202 02:12:35.130460 24599 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:12:35.130472 24599 layer_factory.hpp:78] Creating layer pool5
I1202 02:12:35.130481 24599 net.cpp:67] Creating Layer pool5
I1202 02:12:35.130483 24599 net.cpp:394] pool5 <- conv5_3
I1202 02:12:35.130488 24599 net.cpp:356] pool5 -> pool5
I1202 02:12:35.130494 24599 net.cpp:96] Setting up pool5
I1202 02:12:35.130502 24599 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:12:35.130506 24599 layer_factory.hpp:78] Creating layer fc6
I1202 02:12:35.130519 24599 net.cpp:67] Creating Layer fc6
I1202 02:12:35.130523 24599 net.cpp:394] fc6 <- pool5
I1202 02:12:35.130529 24599 net.cpp:356] fc6 -> fc6
I1202 02:12:35.130535 24599 net.cpp:96] Setting up fc6
I1202 02:12:37.630801 24599 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:12:37.630832 24599 layer_factory.hpp:78] Creating layer relu6
I1202 02:12:37.630841 24599 net.cpp:67] Creating Layer relu6
I1202 02:12:37.630846 24599 net.cpp:394] relu6 <- fc6
I1202 02:12:37.630854 24599 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:12:37.630861 24599 net.cpp:96] Setting up relu6
I1202 02:12:37.630877 24599 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:12:37.630880 24599 layer_factory.hpp:78] Creating layer drop6
I1202 02:12:37.630887 24599 net.cpp:67] Creating Layer drop6
I1202 02:12:37.630890 24599 net.cpp:394] drop6 <- fc6
I1202 02:12:37.630895 24599 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:12:37.630899 24599 net.cpp:96] Setting up drop6
I1202 02:12:37.630903 24599 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:12:37.630906 24599 layer_factory.hpp:78] Creating layer fc7
I1202 02:12:37.630913 24599 net.cpp:67] Creating Layer fc7
I1202 02:12:37.630918 24599 net.cpp:394] fc7 <- fc6
I1202 02:12:37.630923 24599 net.cpp:356] fc7 -> fc7
I1202 02:12:37.630928 24599 net.cpp:96] Setting up fc7
I1202 02:12:38.039680 24599 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:12:38.039712 24599 layer_factory.hpp:78] Creating layer relu7
I1202 02:12:38.039721 24599 net.cpp:67] Creating Layer relu7
I1202 02:12:38.039726 24599 net.cpp:394] relu7 <- fc7
I1202 02:12:38.039732 24599 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:12:38.039739 24599 net.cpp:96] Setting up relu7
I1202 02:12:38.039753 24599 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:12:38.039757 24599 layer_factory.hpp:78] Creating layer drop7
I1202 02:12:38.039762 24599 net.cpp:67] Creating Layer drop7
I1202 02:12:38.039765 24599 net.cpp:394] drop7 <- fc7
I1202 02:12:38.039772 24599 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:12:38.039777 24599 net.cpp:96] Setting up drop7
I1202 02:12:38.039780 24599 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:12:38.039783 24599 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:12:38.039788 24599 net.cpp:67] Creating Layer fc8_2
I1202 02:12:38.039791 24599 net.cpp:394] fc8_2 <- fc7
I1202 02:12:38.039798 24599 net.cpp:356] fc8_2 -> fc8_2
I1202 02:12:38.039804 24599 net.cpp:96] Setting up fc8_2
I1202 02:12:38.040030 24599 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:12:38.040038 24599 layer_factory.hpp:78] Creating layer loss
I1202 02:12:38.040045 24599 net.cpp:67] Creating Layer loss
I1202 02:12:38.040048 24599 net.cpp:394] loss <- fc8_2
I1202 02:12:38.040052 24599 net.cpp:394] loss <- label
I1202 02:12:38.040061 24599 net.cpp:356] loss -> (automatic)
I1202 02:12:38.040066 24599 net.cpp:96] Setting up loss
I1202 02:12:38.040074 24599 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:12:38.040077 24599 net.cpp:109]     with loss weight 1
I1202 02:12:38.040113 24599 net.cpp:170] loss needs backward computation.
I1202 02:12:38.040117 24599 net.cpp:170] fc8_2 needs backward computation.
I1202 02:12:38.040120 24599 net.cpp:170] drop7 needs backward computation.
I1202 02:12:38.040122 24599 net.cpp:170] relu7 needs backward computation.
I1202 02:12:38.040125 24599 net.cpp:170] fc7 needs backward computation.
I1202 02:12:38.040128 24599 net.cpp:170] drop6 needs backward computation.
I1202 02:12:38.040132 24599 net.cpp:170] relu6 needs backward computation.
I1202 02:12:38.040133 24599 net.cpp:170] fc6 needs backward computation.
I1202 02:12:38.040145 24599 net.cpp:170] pool5 needs backward computation.
I1202 02:12:38.040148 24599 net.cpp:170] relu5_3 needs backward computation.
I1202 02:12:38.040151 24599 net.cpp:170] conv5_3 needs backward computation.
I1202 02:12:38.040158 24599 net.cpp:170] relu5_2 needs backward computation.
I1202 02:12:38.040163 24599 net.cpp:170] conv5_2 needs backward computation.
I1202 02:12:38.040165 24599 net.cpp:170] relu5_1 needs backward computation.
I1202 02:12:38.040168 24599 net.cpp:170] conv5_1 needs backward computation.
I1202 02:12:38.040171 24599 net.cpp:170] pool4 needs backward computation.
I1202 02:12:38.040176 24599 net.cpp:170] relu4_3 needs backward computation.
I1202 02:12:38.040179 24599 net.cpp:170] conv4_3 needs backward computation.
I1202 02:12:38.040182 24599 net.cpp:170] relu4_2 needs backward computation.
I1202 02:12:38.040185 24599 net.cpp:170] conv4_2 needs backward computation.
I1202 02:12:38.040189 24599 net.cpp:170] relu4_1 needs backward computation.
I1202 02:12:38.040191 24599 net.cpp:170] conv4_1 needs backward computation.
I1202 02:12:38.040194 24599 net.cpp:170] pool3 needs backward computation.
I1202 02:12:38.040197 24599 net.cpp:170] relu3_3 needs backward computation.
I1202 02:12:38.040200 24599 net.cpp:170] conv3_3 needs backward computation.
I1202 02:12:38.040204 24599 net.cpp:170] relu3_2 needs backward computation.
I1202 02:12:38.040206 24599 net.cpp:170] conv3_2 needs backward computation.
I1202 02:12:38.040210 24599 net.cpp:170] relu3_1 needs backward computation.
I1202 02:12:38.040212 24599 net.cpp:170] conv3_1 needs backward computation.
I1202 02:12:38.040215 24599 net.cpp:170] pool2 needs backward computation.
I1202 02:12:38.040218 24599 net.cpp:170] relu2_2 needs backward computation.
I1202 02:12:38.040220 24599 net.cpp:170] conv2_2 needs backward computation.
I1202 02:12:38.040225 24599 net.cpp:170] relu2_1 needs backward computation.
I1202 02:12:38.040226 24599 net.cpp:170] conv2_1 needs backward computation.
I1202 02:12:38.040230 24599 net.cpp:170] pool1 needs backward computation.
I1202 02:12:38.040232 24599 net.cpp:170] relu1_2 needs backward computation.
I1202 02:12:38.040235 24599 net.cpp:170] conv1_2 needs backward computation.
I1202 02:12:38.040238 24599 net.cpp:170] relu1_1 needs backward computation.
I1202 02:12:38.040241 24599 net.cpp:170] conv1_1 needs backward computation.
I1202 02:12:38.040244 24599 net.cpp:172] data does not need backward computation.
I1202 02:12:38.040263 24599 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:12:38.040271 24599 net.cpp:219] Network initialization done.
I1202 02:12:38.040273 24599 net.cpp:220] Memory required for data: 3686465924
I1202 02:12:38.041110 24599 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:12:38.041152 24599 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:12:38.041364 24599 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:12:38.041507 24599 layer_factory.hpp:78] Creating layer data
I1202 02:12:38.041517 24599 net.cpp:67] Creating Layer data
I1202 02:12:38.041520 24599 net.cpp:356] data -> data
I1202 02:12:38.041527 24599 net.cpp:356] data -> label
I1202 02:12:38.041533 24599 net.cpp:96] Setting up data
I1202 02:12:38.041538 24599 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:12:38.043062 24599 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:12:38.050138 24599 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:12:38.051053 24599 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:12:38.051062 24599 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:12:38.051067 24599 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:12:38.051081 24599 net.cpp:67] Creating Layer label_data_1_split
I1202 02:12:38.051085 24599 net.cpp:394] label_data_1_split <- label
I1202 02:12:38.051091 24599 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:12:38.051100 24599 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:12:38.051105 24599 net.cpp:96] Setting up label_data_1_split
I1202 02:12:38.051110 24599 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:12:38.051113 24599 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:12:38.051116 24599 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:12:38.051122 24599 net.cpp:67] Creating Layer conv1_1
I1202 02:12:38.051126 24599 net.cpp:394] conv1_1 <- data
I1202 02:12:38.051131 24599 net.cpp:356] conv1_1 -> conv1_1
I1202 02:12:38.051136 24599 net.cpp:96] Setting up conv1_1
I1202 02:12:38.051298 24599 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:12:38.051311 24599 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:12:38.051316 24599 net.cpp:67] Creating Layer relu1_1
I1202 02:12:38.051321 24599 net.cpp:394] relu1_1 <- conv1_1
I1202 02:12:38.051324 24599 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:12:38.051337 24599 net.cpp:96] Setting up relu1_1
I1202 02:12:38.051342 24599 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:12:38.051345 24599 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:12:38.051352 24599 net.cpp:67] Creating Layer conv1_2
I1202 02:12:38.051354 24599 net.cpp:394] conv1_2 <- conv1_1
I1202 02:12:38.051358 24599 net.cpp:356] conv1_2 -> conv1_2
I1202 02:12:38.051364 24599 net.cpp:96] Setting up conv1_2
I1202 02:12:38.052376 24599 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:12:38.052389 24599 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:12:38.052395 24599 net.cpp:67] Creating Layer relu1_2
I1202 02:12:38.052398 24599 net.cpp:394] relu1_2 <- conv1_2
I1202 02:12:38.052403 24599 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:12:38.052407 24599 net.cpp:96] Setting up relu1_2
I1202 02:12:38.052412 24599 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:12:38.052417 24599 layer_factory.hpp:78] Creating layer pool1
I1202 02:12:38.052422 24599 net.cpp:67] Creating Layer pool1
I1202 02:12:38.052424 24599 net.cpp:394] pool1 <- conv1_2
I1202 02:12:38.052428 24599 net.cpp:356] pool1 -> pool1
I1202 02:12:38.052433 24599 net.cpp:96] Setting up pool1
I1202 02:12:38.052440 24599 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:12:38.052444 24599 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:12:38.052449 24599 net.cpp:67] Creating Layer conv2_1
I1202 02:12:38.052453 24599 net.cpp:394] conv2_1 <- pool1
I1202 02:12:38.052456 24599 net.cpp:356] conv2_1 -> conv2_1
I1202 02:12:38.052461 24599 net.cpp:96] Setting up conv2_1
I1202 02:12:38.054464 24599 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:12:38.054477 24599 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:12:38.054484 24599 net.cpp:67] Creating Layer relu2_1
I1202 02:12:38.054487 24599 net.cpp:394] relu2_1 <- conv2_1
I1202 02:12:38.054492 24599 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:12:38.054497 24599 net.cpp:96] Setting up relu2_1
I1202 02:12:38.054502 24599 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:12:38.054505 24599 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:12:38.054510 24599 net.cpp:67] Creating Layer conv2_2
I1202 02:12:38.054513 24599 net.cpp:394] conv2_2 <- conv2_1
I1202 02:12:38.054518 24599 net.cpp:356] conv2_2 -> conv2_2
I1202 02:12:38.054524 24599 net.cpp:96] Setting up conv2_2
I1202 02:12:38.058179 24599 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:12:38.058192 24599 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:12:38.058195 24599 net.cpp:67] Creating Layer relu2_2
I1202 02:12:38.058199 24599 net.cpp:394] relu2_2 <- conv2_2
I1202 02:12:38.058204 24599 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:12:38.058208 24599 net.cpp:96] Setting up relu2_2
I1202 02:12:38.058213 24599 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:12:38.058218 24599 layer_factory.hpp:78] Creating layer pool2
I1202 02:12:38.058221 24599 net.cpp:67] Creating Layer pool2
I1202 02:12:38.058224 24599 net.cpp:394] pool2 <- conv2_2
I1202 02:12:38.058228 24599 net.cpp:356] pool2 -> pool2
I1202 02:12:38.058233 24599 net.cpp:96] Setting up pool2
I1202 02:12:38.058239 24599 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:12:38.058243 24599 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:12:38.058248 24599 net.cpp:67] Creating Layer conv3_1
I1202 02:12:38.058250 24599 net.cpp:394] conv3_1 <- pool2
I1202 02:12:38.058255 24599 net.cpp:356] conv3_1 -> conv3_1
I1202 02:12:38.058260 24599 net.cpp:96] Setting up conv3_1
I1202 02:12:38.065525 24599 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:12:38.065542 24599 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:12:38.065548 24599 net.cpp:67] Creating Layer relu3_1
I1202 02:12:38.065552 24599 net.cpp:394] relu3_1 <- conv3_1
I1202 02:12:38.065557 24599 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:12:38.065562 24599 net.cpp:96] Setting up relu3_1
I1202 02:12:38.065567 24599 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:12:38.065570 24599 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:12:38.065584 24599 net.cpp:67] Creating Layer conv3_2
I1202 02:12:38.065587 24599 net.cpp:394] conv3_2 <- conv3_1
I1202 02:12:38.065593 24599 net.cpp:356] conv3_2 -> conv3_2
I1202 02:12:38.065598 24599 net.cpp:96] Setting up conv3_2
I1202 02:12:38.080215 24599 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:12:38.080234 24599 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:12:38.080242 24599 net.cpp:67] Creating Layer relu3_2
I1202 02:12:38.080246 24599 net.cpp:394] relu3_2 <- conv3_2
I1202 02:12:38.080252 24599 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:12:38.080258 24599 net.cpp:96] Setting up relu3_2
I1202 02:12:38.080263 24599 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:12:38.080267 24599 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:12:38.080276 24599 net.cpp:67] Creating Layer conv3_3
I1202 02:12:38.080279 24599 net.cpp:394] conv3_3 <- conv3_2
I1202 02:12:38.080284 24599 net.cpp:356] conv3_3 -> conv3_3
I1202 02:12:38.080291 24599 net.cpp:96] Setting up conv3_3
I1202 02:12:38.095079 24599 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:12:38.095100 24599 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:12:38.095110 24599 net.cpp:67] Creating Layer relu3_3
I1202 02:12:38.095115 24599 net.cpp:394] relu3_3 <- conv3_3
I1202 02:12:38.095121 24599 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:12:38.095129 24599 net.cpp:96] Setting up relu3_3
I1202 02:12:38.095134 24599 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:12:38.095137 24599 layer_factory.hpp:78] Creating layer pool3
I1202 02:12:38.095144 24599 net.cpp:67] Creating Layer pool3
I1202 02:12:38.095146 24599 net.cpp:394] pool3 <- conv3_3
I1202 02:12:38.095152 24599 net.cpp:356] pool3 -> pool3
I1202 02:12:38.095159 24599 net.cpp:96] Setting up pool3
I1202 02:12:38.095165 24599 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:12:38.095168 24599 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:12:38.095173 24599 net.cpp:67] Creating Layer conv4_1
I1202 02:12:38.095176 24599 net.cpp:394] conv4_1 <- pool3
I1202 02:12:38.095182 24599 net.cpp:356] conv4_1 -> conv4_1
I1202 02:12:38.095188 24599 net.cpp:96] Setting up conv4_1
I1202 02:12:38.124471 24599 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:12:38.124493 24599 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:12:38.124503 24599 net.cpp:67] Creating Layer relu4_1
I1202 02:12:38.124508 24599 net.cpp:394] relu4_1 <- conv4_1
I1202 02:12:38.124514 24599 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:12:38.124521 24599 net.cpp:96] Setting up relu4_1
I1202 02:12:38.124527 24599 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:12:38.124531 24599 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:12:38.124537 24599 net.cpp:67] Creating Layer conv4_2
I1202 02:12:38.124541 24599 net.cpp:394] conv4_2 <- conv4_1
I1202 02:12:38.124547 24599 net.cpp:356] conv4_2 -> conv4_2
I1202 02:12:38.124552 24599 net.cpp:96] Setting up conv4_2
I1202 02:12:38.182193 24599 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:12:38.182224 24599 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:12:38.182231 24599 net.cpp:67] Creating Layer relu4_2
I1202 02:12:38.182237 24599 net.cpp:394] relu4_2 <- conv4_2
I1202 02:12:38.182245 24599 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:12:38.182251 24599 net.cpp:96] Setting up relu4_2
I1202 02:12:38.182257 24599 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:12:38.182260 24599 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:12:38.182267 24599 net.cpp:67] Creating Layer conv4_3
I1202 02:12:38.182271 24599 net.cpp:394] conv4_3 <- conv4_2
I1202 02:12:38.182276 24599 net.cpp:356] conv4_3 -> conv4_3
I1202 02:12:38.182284 24599 net.cpp:96] Setting up conv4_3
I1202 02:12:38.240224 24599 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:12:38.240248 24599 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:12:38.240257 24599 net.cpp:67] Creating Layer relu4_3
I1202 02:12:38.240262 24599 net.cpp:394] relu4_3 <- conv4_3
I1202 02:12:38.240268 24599 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:12:38.240284 24599 net.cpp:96] Setting up relu4_3
I1202 02:12:38.240290 24599 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:12:38.240293 24599 layer_factory.hpp:78] Creating layer pool4
I1202 02:12:38.240299 24599 net.cpp:67] Creating Layer pool4
I1202 02:12:38.240303 24599 net.cpp:394] pool4 <- conv4_3
I1202 02:12:38.240308 24599 net.cpp:356] pool4 -> pool4
I1202 02:12:38.240313 24599 net.cpp:96] Setting up pool4
I1202 02:12:38.240320 24599 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:12:38.240324 24599 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:12:38.240330 24599 net.cpp:67] Creating Layer conv5_1
I1202 02:12:38.240334 24599 net.cpp:394] conv5_1 <- pool4
I1202 02:12:38.240339 24599 net.cpp:356] conv5_1 -> conv5_1
I1202 02:12:38.240344 24599 net.cpp:96] Setting up conv5_1
I1202 02:12:38.298012 24599 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:12:38.298038 24599 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:12:38.298046 24599 net.cpp:67] Creating Layer relu5_1
I1202 02:12:38.298050 24599 net.cpp:394] relu5_1 <- conv5_1
I1202 02:12:38.298058 24599 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:12:38.298065 24599 net.cpp:96] Setting up relu5_1
I1202 02:12:38.298071 24599 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:12:38.298074 24599 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:12:38.298080 24599 net.cpp:67] Creating Layer conv5_2
I1202 02:12:38.298084 24599 net.cpp:394] conv5_2 <- conv5_1
I1202 02:12:38.298089 24599 net.cpp:356] conv5_2 -> conv5_2
I1202 02:12:38.298095 24599 net.cpp:96] Setting up conv5_2
I1202 02:12:38.356031 24599 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:12:38.356058 24599 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:12:38.356065 24599 net.cpp:67] Creating Layer relu5_2
I1202 02:12:38.356070 24599 net.cpp:394] relu5_2 <- conv5_2
I1202 02:12:38.356078 24599 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:12:38.356086 24599 net.cpp:96] Setting up relu5_2
I1202 02:12:38.356091 24599 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:12:38.356094 24599 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:12:38.356101 24599 net.cpp:67] Creating Layer conv5_3
I1202 02:12:38.356104 24599 net.cpp:394] conv5_3 <- conv5_2
I1202 02:12:38.356111 24599 net.cpp:356] conv5_3 -> conv5_3
I1202 02:12:38.356117 24599 net.cpp:96] Setting up conv5_3
I1202 02:12:38.413929 24599 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:12:38.413955 24599 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:12:38.413964 24599 net.cpp:67] Creating Layer relu5_3
I1202 02:12:38.413969 24599 net.cpp:394] relu5_3 <- conv5_3
I1202 02:12:38.413976 24599 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:12:38.413985 24599 net.cpp:96] Setting up relu5_3
I1202 02:12:38.413990 24599 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:12:38.413993 24599 layer_factory.hpp:78] Creating layer pool5
I1202 02:12:38.414005 24599 net.cpp:67] Creating Layer pool5
I1202 02:12:38.414007 24599 net.cpp:394] pool5 <- conv5_3
I1202 02:12:38.414012 24599 net.cpp:356] pool5 -> pool5
I1202 02:12:38.414018 24599 net.cpp:96] Setting up pool5
I1202 02:12:38.414026 24599 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:12:38.414029 24599 layer_factory.hpp:78] Creating layer fc6
I1202 02:12:38.414034 24599 net.cpp:67] Creating Layer fc6
I1202 02:12:38.414037 24599 net.cpp:394] fc6 <- pool5
I1202 02:12:38.414043 24599 net.cpp:356] fc6 -> fc6
I1202 02:12:38.414049 24599 net.cpp:96] Setting up fc6
I1202 02:12:40.913221 24599 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:12:40.913249 24599 layer_factory.hpp:78] Creating layer relu6
I1202 02:12:40.913259 24599 net.cpp:67] Creating Layer relu6
I1202 02:12:40.913264 24599 net.cpp:394] relu6 <- fc6
I1202 02:12:40.913272 24599 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:12:40.913280 24599 net.cpp:96] Setting up relu6
I1202 02:12:40.913293 24599 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:12:40.913297 24599 layer_factory.hpp:78] Creating layer drop6
I1202 02:12:40.913313 24599 net.cpp:67] Creating Layer drop6
I1202 02:12:40.913317 24599 net.cpp:394] drop6 <- fc6
I1202 02:12:40.913321 24599 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:12:40.913326 24599 net.cpp:96] Setting up drop6
I1202 02:12:40.913331 24599 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:12:40.913333 24599 layer_factory.hpp:78] Creating layer fc7
I1202 02:12:40.913341 24599 net.cpp:67] Creating Layer fc7
I1202 02:12:40.913343 24599 net.cpp:394] fc7 <- fc6
I1202 02:12:40.913348 24599 net.cpp:356] fc7 -> fc7
I1202 02:12:40.913354 24599 net.cpp:96] Setting up fc7
I1202 02:12:41.322010 24599 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:12:41.322039 24599 layer_factory.hpp:78] Creating layer relu7
I1202 02:12:41.322047 24599 net.cpp:67] Creating Layer relu7
I1202 02:12:41.322052 24599 net.cpp:394] relu7 <- fc7
I1202 02:12:41.322059 24599 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:12:41.322065 24599 net.cpp:96] Setting up relu7
I1202 02:12:41.322080 24599 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:12:41.322084 24599 layer_factory.hpp:78] Creating layer drop7
I1202 02:12:41.322089 24599 net.cpp:67] Creating Layer drop7
I1202 02:12:41.322093 24599 net.cpp:394] drop7 <- fc7
I1202 02:12:41.322098 24599 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:12:41.322103 24599 net.cpp:96] Setting up drop7
I1202 02:12:41.322108 24599 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:12:41.322110 24599 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:12:41.322115 24599 net.cpp:67] Creating Layer fc8_2
I1202 02:12:41.322118 24599 net.cpp:394] fc8_2 <- fc7
I1202 02:12:41.322127 24599 net.cpp:356] fc8_2 -> fc8_2
I1202 02:12:41.322134 24599 net.cpp:96] Setting up fc8_2
I1202 02:12:41.322352 24599 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:12:41.322361 24599 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:12:41.322366 24599 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:12:41.322370 24599 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:12:41.322373 24599 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:12:41.322381 24599 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:12:41.322386 24599 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:12:41.322391 24599 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:12:41.322393 24599 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:12:41.322396 24599 layer_factory.hpp:78] Creating layer loss
I1202 02:12:41.322402 24599 net.cpp:67] Creating Layer loss
I1202 02:12:41.322407 24599 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:12:41.322410 24599 net.cpp:394] loss <- label_data_1_split_0
I1202 02:12:41.322415 24599 net.cpp:356] loss -> (automatic)
I1202 02:12:41.322419 24599 net.cpp:96] Setting up loss
I1202 02:12:41.322432 24599 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:12:41.322434 24599 net.cpp:109]     with loss weight 1
I1202 02:12:41.322448 24599 layer_factory.hpp:78] Creating layer accuracy
I1202 02:12:41.322453 24599 net.cpp:67] Creating Layer accuracy
I1202 02:12:41.322455 24599 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:12:41.322459 24599 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:12:41.322465 24599 net.cpp:356] accuracy -> accuracy
I1202 02:12:41.322475 24599 net.cpp:96] Setting up accuracy
I1202 02:12:41.322484 24599 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:12:41.322487 24599 net.cpp:172] accuracy does not need backward computation.
I1202 02:12:41.322490 24599 net.cpp:170] loss needs backward computation.
I1202 02:12:41.322494 24599 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:12:41.322496 24599 net.cpp:170] fc8_2 needs backward computation.
I1202 02:12:41.322499 24599 net.cpp:170] drop7 needs backward computation.
I1202 02:12:41.322502 24599 net.cpp:170] relu7 needs backward computation.
I1202 02:12:41.322504 24599 net.cpp:170] fc7 needs backward computation.
I1202 02:12:41.322507 24599 net.cpp:170] drop6 needs backward computation.
I1202 02:12:41.322510 24599 net.cpp:170] relu6 needs backward computation.
I1202 02:12:41.322520 24599 net.cpp:170] fc6 needs backward computation.
I1202 02:12:41.322525 24599 net.cpp:170] pool5 needs backward computation.
I1202 02:12:41.322527 24599 net.cpp:170] relu5_3 needs backward computation.
I1202 02:12:41.322530 24599 net.cpp:170] conv5_3 needs backward computation.
I1202 02:12:41.322533 24599 net.cpp:170] relu5_2 needs backward computation.
I1202 02:12:41.322536 24599 net.cpp:170] conv5_2 needs backward computation.
I1202 02:12:41.322540 24599 net.cpp:170] relu5_1 needs backward computation.
I1202 02:12:41.322542 24599 net.cpp:170] conv5_1 needs backward computation.
I1202 02:12:41.322546 24599 net.cpp:170] pool4 needs backward computation.
I1202 02:12:41.322548 24599 net.cpp:170] relu4_3 needs backward computation.
I1202 02:12:41.322551 24599 net.cpp:170] conv4_3 needs backward computation.
I1202 02:12:41.322554 24599 net.cpp:170] relu4_2 needs backward computation.
I1202 02:12:41.322557 24599 net.cpp:170] conv4_2 needs backward computation.
I1202 02:12:41.322561 24599 net.cpp:170] relu4_1 needs backward computation.
I1202 02:12:41.322563 24599 net.cpp:170] conv4_1 needs backward computation.
I1202 02:12:41.322566 24599 net.cpp:170] pool3 needs backward computation.
I1202 02:12:41.322569 24599 net.cpp:170] relu3_3 needs backward computation.
I1202 02:12:41.322571 24599 net.cpp:170] conv3_3 needs backward computation.
I1202 02:12:41.322576 24599 net.cpp:170] relu3_2 needs backward computation.
I1202 02:12:41.322577 24599 net.cpp:170] conv3_2 needs backward computation.
I1202 02:12:41.322581 24599 net.cpp:170] relu3_1 needs backward computation.
I1202 02:12:41.322583 24599 net.cpp:170] conv3_1 needs backward computation.
I1202 02:12:41.322587 24599 net.cpp:170] pool2 needs backward computation.
I1202 02:12:41.322589 24599 net.cpp:170] relu2_2 needs backward computation.
I1202 02:12:41.322592 24599 net.cpp:170] conv2_2 needs backward computation.
I1202 02:12:41.322594 24599 net.cpp:170] relu2_1 needs backward computation.
I1202 02:12:41.322597 24599 net.cpp:170] conv2_1 needs backward computation.
I1202 02:12:41.322600 24599 net.cpp:170] pool1 needs backward computation.
I1202 02:12:41.322603 24599 net.cpp:170] relu1_2 needs backward computation.
I1202 02:12:41.322607 24599 net.cpp:170] conv1_2 needs backward computation.
I1202 02:12:41.322609 24599 net.cpp:170] relu1_1 needs backward computation.
I1202 02:12:41.322612 24599 net.cpp:170] conv1_1 needs backward computation.
I1202 02:12:41.322614 24599 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:12:41.322619 24599 net.cpp:172] data does not need backward computation.
I1202 02:12:41.322623 24599 net.cpp:208] This network produces output accuracy
I1202 02:12:41.322643 24599 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:12:41.322650 24599 net.cpp:219] Network initialization done.
I1202 02:12:41.322652 24599 net.cpp:220] Memory required for data: 921616692
I1202 02:12:41.322751 24599 solver.cpp:41] Solver scaffolding done.
I1202 02:12:41.322758 24599 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_6000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:12:44.669785 24599 solver.cpp:160] Solving small
I1202 02:12:44.669816 24599 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:12:44.669862 24599 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:14:09.260416 24599 solver.cpp:305] Test loss: 0.44709
I1202 02:14:09.260483 24599 solver.cpp:318] mean_score = test_score[0] { = 2877} / test_score[1] { = 3570 }
I1202 02:14:09.260493 24599 solver.cpp:319]            = 0.805882
I1202 02:14:09.260503 24599 solver.cpp:328]     Test net output #0: accuracy = 0.805882
I1202 02:14:09.260507 24599 solver.cpp:318] mean_score = test_score[2] { = 273} / test_score[3] { = 398 }
I1202 02:14:09.260512 24599 solver.cpp:319]            = 0.68593
I1202 02:14:09.260516 24599 solver.cpp:328]     Test net output #1: accuracy = 0.68593
I1202 02:14:09.260527 24599 solver.cpp:332]     Test net output #2: accuracy = 0.793851
I1202 02:14:09.260531 24599 solver.cpp:334]     Test net output #3: accuracy = 0.745906
I1202 02:14:09.956092 24599 solver.cpp:209] Iteration 0, loss = 0.364447
I1202 02:14:09.956122 24599 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:14:12.304376 24599 solver.cpp:209] Iteration 1, loss = 0.419246
I1202 02:14:12.304404 24599 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:14:14.338855 24599 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:14:18.260462 24599 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:14:22.601022 24599 solver.cpp:246] Iteration 2, loss = 0.538732
I1202 02:14:22.601057 24599 solver.cpp:251] Optimization Done.
I1202 02:14:22.601061 24599 caffe.cpp:121] Optimization Done.
I1202 02:14:22.744199 25152 caffe.cpp:99] Use GPU with device ID 0
I1202 02:14:22.920653 25152 caffe.cpp:107] Starting Optimization
I1202 02:14:22.920747 25152 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:14:22.920771 25152 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:14:22.921558 25152 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:14:22.921587 25152 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:14:22.921777 25152 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:14:22.921902 25152 layer_factory.hpp:78] Creating layer data
I1202 02:14:22.921923 25152 net.cpp:67] Creating Layer data
I1202 02:14:22.921931 25152 net.cpp:356] data -> data
I1202 02:14:22.921949 25152 net.cpp:356] data -> label
I1202 02:14:22.921957 25152 net.cpp:96] Setting up data
I1202 02:14:22.921962 25152 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:14:22.936074 25152 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:14:22.946642 25152 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:14:22.949491 25152 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:14:22.949517 25152 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:14:22.949522 25152 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:14:22.949538 25152 net.cpp:67] Creating Layer conv1_1
I1202 02:14:22.949543 25152 net.cpp:394] conv1_1 <- data
I1202 02:14:22.949556 25152 net.cpp:356] conv1_1 -> conv1_1
I1202 02:14:22.949568 25152 net.cpp:96] Setting up conv1_1
I1202 02:14:23.090931 25152 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:14:23.090965 25152 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:14:23.090976 25152 net.cpp:67] Creating Layer relu1_1
I1202 02:14:23.090981 25152 net.cpp:394] relu1_1 <- conv1_1
I1202 02:14:23.090988 25152 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:14:23.090996 25152 net.cpp:96] Setting up relu1_1
I1202 02:14:23.091004 25152 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:14:23.091008 25152 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:14:23.091014 25152 net.cpp:67] Creating Layer conv1_2
I1202 02:14:23.091017 25152 net.cpp:394] conv1_2 <- conv1_1
I1202 02:14:23.091022 25152 net.cpp:356] conv1_2 -> conv1_2
I1202 02:14:23.091029 25152 net.cpp:96] Setting up conv1_2
I1202 02:14:23.092160 25152 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:14:23.092174 25152 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:14:23.092180 25152 net.cpp:67] Creating Layer relu1_2
I1202 02:14:23.092182 25152 net.cpp:394] relu1_2 <- conv1_2
I1202 02:14:23.092186 25152 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:14:23.092191 25152 net.cpp:96] Setting up relu1_2
I1202 02:14:23.092197 25152 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:14:23.092200 25152 layer_factory.hpp:78] Creating layer pool1
I1202 02:14:23.092207 25152 net.cpp:67] Creating Layer pool1
I1202 02:14:23.092211 25152 net.cpp:394] pool1 <- conv1_2
I1202 02:14:23.092217 25152 net.cpp:356] pool1 -> pool1
I1202 02:14:23.092223 25152 net.cpp:96] Setting up pool1
I1202 02:14:23.092239 25152 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:14:23.092243 25152 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:14:23.092250 25152 net.cpp:67] Creating Layer conv2_1
I1202 02:14:23.092253 25152 net.cpp:394] conv2_1 <- pool1
I1202 02:14:23.092258 25152 net.cpp:356] conv2_1 -> conv2_1
I1202 02:14:23.092263 25152 net.cpp:96] Setting up conv2_1
I1202 02:14:23.094296 25152 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:14:23.094310 25152 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:14:23.094316 25152 net.cpp:67] Creating Layer relu2_1
I1202 02:14:23.094319 25152 net.cpp:394] relu2_1 <- conv2_1
I1202 02:14:23.094323 25152 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:14:23.094328 25152 net.cpp:96] Setting up relu2_1
I1202 02:14:23.094333 25152 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:14:23.094337 25152 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:14:23.094342 25152 net.cpp:67] Creating Layer conv2_2
I1202 02:14:23.094346 25152 net.cpp:394] conv2_2 <- conv2_1
I1202 02:14:23.094352 25152 net.cpp:356] conv2_2 -> conv2_2
I1202 02:14:23.094357 25152 net.cpp:96] Setting up conv2_2
I1202 02:14:23.098340 25152 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:14:23.098351 25152 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:14:23.098358 25152 net.cpp:67] Creating Layer relu2_2
I1202 02:14:23.098361 25152 net.cpp:394] relu2_2 <- conv2_2
I1202 02:14:23.098366 25152 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:14:23.098371 25152 net.cpp:96] Setting up relu2_2
I1202 02:14:23.098376 25152 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:14:23.098387 25152 layer_factory.hpp:78] Creating layer pool2
I1202 02:14:23.098392 25152 net.cpp:67] Creating Layer pool2
I1202 02:14:23.098394 25152 net.cpp:394] pool2 <- conv2_2
I1202 02:14:23.098400 25152 net.cpp:356] pool2 -> pool2
I1202 02:14:23.098405 25152 net.cpp:96] Setting up pool2
I1202 02:14:23.098412 25152 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:14:23.098415 25152 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:14:23.098420 25152 net.cpp:67] Creating Layer conv3_1
I1202 02:14:23.098423 25152 net.cpp:394] conv3_1 <- pool2
I1202 02:14:23.098428 25152 net.cpp:356] conv3_1 -> conv3_1
I1202 02:14:23.098434 25152 net.cpp:96] Setting up conv3_1
I1202 02:14:23.106297 25152 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:14:23.106313 25152 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:14:23.106319 25152 net.cpp:67] Creating Layer relu3_1
I1202 02:14:23.106323 25152 net.cpp:394] relu3_1 <- conv3_1
I1202 02:14:23.106328 25152 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:14:23.106334 25152 net.cpp:96] Setting up relu3_1
I1202 02:14:23.106339 25152 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:14:23.106343 25152 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:14:23.106348 25152 net.cpp:67] Creating Layer conv3_2
I1202 02:14:23.106351 25152 net.cpp:394] conv3_2 <- conv3_1
I1202 02:14:23.106358 25152 net.cpp:356] conv3_2 -> conv3_2
I1202 02:14:23.106362 25152 net.cpp:96] Setting up conv3_2
I1202 02:14:23.122186 25152 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:14:23.122207 25152 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:14:23.122215 25152 net.cpp:67] Creating Layer relu3_2
I1202 02:14:23.122220 25152 net.cpp:394] relu3_2 <- conv3_2
I1202 02:14:23.122227 25152 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:14:23.122233 25152 net.cpp:96] Setting up relu3_2
I1202 02:14:23.122238 25152 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:14:23.122242 25152 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:14:23.122247 25152 net.cpp:67] Creating Layer conv3_3
I1202 02:14:23.122251 25152 net.cpp:394] conv3_3 <- conv3_2
I1202 02:14:23.122256 25152 net.cpp:356] conv3_3 -> conv3_3
I1202 02:14:23.122262 25152 net.cpp:96] Setting up conv3_3
I1202 02:14:23.137923 25152 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:14:23.137944 25152 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:14:23.137955 25152 net.cpp:67] Creating Layer relu3_3
I1202 02:14:23.137960 25152 net.cpp:394] relu3_3 <- conv3_3
I1202 02:14:23.137966 25152 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:14:23.137974 25152 net.cpp:96] Setting up relu3_3
I1202 02:14:23.137979 25152 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:14:23.137982 25152 layer_factory.hpp:78] Creating layer pool3
I1202 02:14:23.137987 25152 net.cpp:67] Creating Layer pool3
I1202 02:14:23.137990 25152 net.cpp:394] pool3 <- conv3_3
I1202 02:14:23.137996 25152 net.cpp:356] pool3 -> pool3
I1202 02:14:23.138001 25152 net.cpp:96] Setting up pool3
I1202 02:14:23.138010 25152 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:14:23.138012 25152 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:14:23.138018 25152 net.cpp:67] Creating Layer conv4_1
I1202 02:14:23.138021 25152 net.cpp:394] conv4_1 <- pool3
I1202 02:14:23.138027 25152 net.cpp:356] conv4_1 -> conv4_1
I1202 02:14:23.138032 25152 net.cpp:96] Setting up conv4_1
I1202 02:14:23.168681 25152 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:14:23.168704 25152 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:14:23.168712 25152 net.cpp:67] Creating Layer relu4_1
I1202 02:14:23.168716 25152 net.cpp:394] relu4_1 <- conv4_1
I1202 02:14:23.168723 25152 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:14:23.168730 25152 net.cpp:96] Setting up relu4_1
I1202 02:14:23.168736 25152 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:14:23.168740 25152 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:14:23.168747 25152 net.cpp:67] Creating Layer conv4_2
I1202 02:14:23.168751 25152 net.cpp:394] conv4_2 <- conv4_1
I1202 02:14:23.168764 25152 net.cpp:356] conv4_2 -> conv4_2
I1202 02:14:23.168771 25152 net.cpp:96] Setting up conv4_2
I1202 02:14:23.230316 25152 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:14:23.230345 25152 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:14:23.230353 25152 net.cpp:67] Creating Layer relu4_2
I1202 02:14:23.230358 25152 net.cpp:394] relu4_2 <- conv4_2
I1202 02:14:23.230365 25152 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:14:23.230372 25152 net.cpp:96] Setting up relu4_2
I1202 02:14:23.230378 25152 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:14:23.230381 25152 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:14:23.230388 25152 net.cpp:67] Creating Layer conv4_3
I1202 02:14:23.230391 25152 net.cpp:394] conv4_3 <- conv4_2
I1202 02:14:23.230396 25152 net.cpp:356] conv4_3 -> conv4_3
I1202 02:14:23.230403 25152 net.cpp:96] Setting up conv4_3
I1202 02:14:23.291664 25152 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:14:23.291687 25152 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:14:23.291694 25152 net.cpp:67] Creating Layer relu4_3
I1202 02:14:23.291699 25152 net.cpp:394] relu4_3 <- conv4_3
I1202 02:14:23.291705 25152 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:14:23.291713 25152 net.cpp:96] Setting up relu4_3
I1202 02:14:23.291719 25152 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:14:23.291723 25152 layer_factory.hpp:78] Creating layer pool4
I1202 02:14:23.291728 25152 net.cpp:67] Creating Layer pool4
I1202 02:14:23.291731 25152 net.cpp:394] pool4 <- conv4_3
I1202 02:14:23.291736 25152 net.cpp:356] pool4 -> pool4
I1202 02:14:23.291743 25152 net.cpp:96] Setting up pool4
I1202 02:14:23.291749 25152 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:14:23.291754 25152 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:14:23.291760 25152 net.cpp:67] Creating Layer conv5_1
I1202 02:14:23.291764 25152 net.cpp:394] conv5_1 <- pool4
I1202 02:14:23.291769 25152 net.cpp:356] conv5_1 -> conv5_1
I1202 02:14:23.291777 25152 net.cpp:96] Setting up conv5_1
I1202 02:14:23.353323 25152 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:14:23.353349 25152 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:14:23.353358 25152 net.cpp:67] Creating Layer relu5_1
I1202 02:14:23.353363 25152 net.cpp:394] relu5_1 <- conv5_1
I1202 02:14:23.353368 25152 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:14:23.353374 25152 net.cpp:96] Setting up relu5_1
I1202 02:14:23.353380 25152 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:14:23.353384 25152 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:14:23.353395 25152 net.cpp:67] Creating Layer conv5_2
I1202 02:14:23.353399 25152 net.cpp:394] conv5_2 <- conv5_1
I1202 02:14:23.353405 25152 net.cpp:356] conv5_2 -> conv5_2
I1202 02:14:23.353411 25152 net.cpp:96] Setting up conv5_2
I1202 02:14:23.414595 25152 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:14:23.414621 25152 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:14:23.414630 25152 net.cpp:67] Creating Layer relu5_2
I1202 02:14:23.414634 25152 net.cpp:394] relu5_2 <- conv5_2
I1202 02:14:23.414643 25152 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:14:23.414649 25152 net.cpp:96] Setting up relu5_2
I1202 02:14:23.414654 25152 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:14:23.414657 25152 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:14:23.414665 25152 net.cpp:67] Creating Layer conv5_3
I1202 02:14:23.414669 25152 net.cpp:394] conv5_3 <- conv5_2
I1202 02:14:23.414674 25152 net.cpp:356] conv5_3 -> conv5_3
I1202 02:14:23.414680 25152 net.cpp:96] Setting up conv5_3
I1202 02:14:23.476132 25152 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:14:23.476157 25152 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:14:23.476166 25152 net.cpp:67] Creating Layer relu5_3
I1202 02:14:23.476169 25152 net.cpp:394] relu5_3 <- conv5_3
I1202 02:14:23.476176 25152 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:14:23.476182 25152 net.cpp:96] Setting up relu5_3
I1202 02:14:23.476188 25152 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:14:23.476202 25152 layer_factory.hpp:78] Creating layer pool5
I1202 02:14:23.476209 25152 net.cpp:67] Creating Layer pool5
I1202 02:14:23.476212 25152 net.cpp:394] pool5 <- conv5_3
I1202 02:14:23.476217 25152 net.cpp:356] pool5 -> pool5
I1202 02:14:23.476222 25152 net.cpp:96] Setting up pool5
I1202 02:14:23.476230 25152 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:14:23.476233 25152 layer_factory.hpp:78] Creating layer fc6
I1202 02:14:23.476248 25152 net.cpp:67] Creating Layer fc6
I1202 02:14:23.476251 25152 net.cpp:394] fc6 <- pool5
I1202 02:14:23.476256 25152 net.cpp:356] fc6 -> fc6
I1202 02:14:23.476263 25152 net.cpp:96] Setting up fc6
I1202 02:14:26.140893 25152 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:14:26.140923 25152 layer_factory.hpp:78] Creating layer relu6
I1202 02:14:26.140933 25152 net.cpp:67] Creating Layer relu6
I1202 02:14:26.140938 25152 net.cpp:394] relu6 <- fc6
I1202 02:14:26.140945 25152 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:14:26.140952 25152 net.cpp:96] Setting up relu6
I1202 02:14:26.140966 25152 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:14:26.140970 25152 layer_factory.hpp:78] Creating layer drop6
I1202 02:14:26.140979 25152 net.cpp:67] Creating Layer drop6
I1202 02:14:26.140981 25152 net.cpp:394] drop6 <- fc6
I1202 02:14:26.140985 25152 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:14:26.140990 25152 net.cpp:96] Setting up drop6
I1202 02:14:26.140993 25152 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:14:26.140997 25152 layer_factory.hpp:78] Creating layer fc7
I1202 02:14:26.141003 25152 net.cpp:67] Creating Layer fc7
I1202 02:14:26.141007 25152 net.cpp:394] fc7 <- fc6
I1202 02:14:26.141012 25152 net.cpp:356] fc7 -> fc7
I1202 02:14:26.141018 25152 net.cpp:96] Setting up fc7
I1202 02:14:26.575034 25152 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:14:26.575064 25152 layer_factory.hpp:78] Creating layer relu7
I1202 02:14:26.575073 25152 net.cpp:67] Creating Layer relu7
I1202 02:14:26.575078 25152 net.cpp:394] relu7 <- fc7
I1202 02:14:26.575084 25152 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:14:26.575090 25152 net.cpp:96] Setting up relu7
I1202 02:14:26.575105 25152 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:14:26.575109 25152 layer_factory.hpp:78] Creating layer drop7
I1202 02:14:26.575114 25152 net.cpp:67] Creating Layer drop7
I1202 02:14:26.575117 25152 net.cpp:394] drop7 <- fc7
I1202 02:14:26.575124 25152 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:14:26.575127 25152 net.cpp:96] Setting up drop7
I1202 02:14:26.575131 25152 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:14:26.575134 25152 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:14:26.575139 25152 net.cpp:67] Creating Layer fc8_2
I1202 02:14:26.575142 25152 net.cpp:394] fc8_2 <- fc7
I1202 02:14:26.575148 25152 net.cpp:356] fc8_2 -> fc8_2
I1202 02:14:26.575155 25152 net.cpp:96] Setting up fc8_2
I1202 02:14:26.575397 25152 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:14:26.575405 25152 layer_factory.hpp:78] Creating layer loss
I1202 02:14:26.575410 25152 net.cpp:67] Creating Layer loss
I1202 02:14:26.575414 25152 net.cpp:394] loss <- fc8_2
I1202 02:14:26.575419 25152 net.cpp:394] loss <- label
I1202 02:14:26.575428 25152 net.cpp:356] loss -> (automatic)
I1202 02:14:26.575433 25152 net.cpp:96] Setting up loss
I1202 02:14:26.575443 25152 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:14:26.575445 25152 net.cpp:109]     with loss weight 1
I1202 02:14:26.575484 25152 net.cpp:170] loss needs backward computation.
I1202 02:14:26.575487 25152 net.cpp:170] fc8_2 needs backward computation.
I1202 02:14:26.575490 25152 net.cpp:170] drop7 needs backward computation.
I1202 02:14:26.575492 25152 net.cpp:170] relu7 needs backward computation.
I1202 02:14:26.575495 25152 net.cpp:170] fc7 needs backward computation.
I1202 02:14:26.575497 25152 net.cpp:170] drop6 needs backward computation.
I1202 02:14:26.575500 25152 net.cpp:170] relu6 needs backward computation.
I1202 02:14:26.575503 25152 net.cpp:170] fc6 needs backward computation.
I1202 02:14:26.575515 25152 net.cpp:170] pool5 needs backward computation.
I1202 02:14:26.575518 25152 net.cpp:170] relu5_3 needs backward computation.
I1202 02:14:26.575520 25152 net.cpp:170] conv5_3 needs backward computation.
I1202 02:14:26.575528 25152 net.cpp:170] relu5_2 needs backward computation.
I1202 02:14:26.575531 25152 net.cpp:170] conv5_2 needs backward computation.
I1202 02:14:26.575534 25152 net.cpp:170] relu5_1 needs backward computation.
I1202 02:14:26.575537 25152 net.cpp:170] conv5_1 needs backward computation.
I1202 02:14:26.575541 25152 net.cpp:170] pool4 needs backward computation.
I1202 02:14:26.575543 25152 net.cpp:170] relu4_3 needs backward computation.
I1202 02:14:26.575546 25152 net.cpp:170] conv4_3 needs backward computation.
I1202 02:14:26.575548 25152 net.cpp:170] relu4_2 needs backward computation.
I1202 02:14:26.575551 25152 net.cpp:170] conv4_2 needs backward computation.
I1202 02:14:26.575554 25152 net.cpp:170] relu4_1 needs backward computation.
I1202 02:14:26.575557 25152 net.cpp:170] conv4_1 needs backward computation.
I1202 02:14:26.575561 25152 net.cpp:170] pool3 needs backward computation.
I1202 02:14:26.575563 25152 net.cpp:170] relu3_3 needs backward computation.
I1202 02:14:26.575567 25152 net.cpp:170] conv3_3 needs backward computation.
I1202 02:14:26.575570 25152 net.cpp:170] relu3_2 needs backward computation.
I1202 02:14:26.575573 25152 net.cpp:170] conv3_2 needs backward computation.
I1202 02:14:26.575577 25152 net.cpp:170] relu3_1 needs backward computation.
I1202 02:14:26.575579 25152 net.cpp:170] conv3_1 needs backward computation.
I1202 02:14:26.575582 25152 net.cpp:170] pool2 needs backward computation.
I1202 02:14:26.575585 25152 net.cpp:170] relu2_2 needs backward computation.
I1202 02:14:26.575588 25152 net.cpp:170] conv2_2 needs backward computation.
I1202 02:14:26.575592 25152 net.cpp:170] relu2_1 needs backward computation.
I1202 02:14:26.575593 25152 net.cpp:170] conv2_1 needs backward computation.
I1202 02:14:26.575597 25152 net.cpp:170] pool1 needs backward computation.
I1202 02:14:26.575599 25152 net.cpp:170] relu1_2 needs backward computation.
I1202 02:14:26.575603 25152 net.cpp:170] conv1_2 needs backward computation.
I1202 02:14:26.575605 25152 net.cpp:170] relu1_1 needs backward computation.
I1202 02:14:26.575608 25152 net.cpp:170] conv1_1 needs backward computation.
I1202 02:14:26.575610 25152 net.cpp:172] data does not need backward computation.
I1202 02:14:26.575629 25152 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:14:26.575636 25152 net.cpp:219] Network initialization done.
I1202 02:14:26.575639 25152 net.cpp:220] Memory required for data: 3686465924
I1202 02:14:26.576458 25152 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:14:26.576501 25152 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:14:26.576709 25152 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:14:26.576849 25152 layer_factory.hpp:78] Creating layer data
I1202 02:14:26.576858 25152 net.cpp:67] Creating Layer data
I1202 02:14:26.576864 25152 net.cpp:356] data -> data
I1202 02:14:26.576870 25152 net.cpp:356] data -> label
I1202 02:14:26.576876 25152 net.cpp:96] Setting up data
I1202 02:14:26.576879 25152 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:14:26.578398 25152 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:14:26.585412 25152 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:14:26.586055 25152 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:14:26.586065 25152 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:14:26.586068 25152 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:14:26.586081 25152 net.cpp:67] Creating Layer label_data_1_split
I1202 02:14:26.586084 25152 net.cpp:394] label_data_1_split <- label
I1202 02:14:26.586091 25152 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:14:26.586120 25152 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:14:26.586129 25152 net.cpp:96] Setting up label_data_1_split
I1202 02:14:26.586133 25152 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:14:26.586138 25152 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:14:26.586140 25152 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:14:26.586146 25152 net.cpp:67] Creating Layer conv1_1
I1202 02:14:26.586149 25152 net.cpp:394] conv1_1 <- data
I1202 02:14:26.586154 25152 net.cpp:356] conv1_1 -> conv1_1
I1202 02:14:26.586161 25152 net.cpp:96] Setting up conv1_1
I1202 02:14:26.586323 25152 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:14:26.586338 25152 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:14:26.586343 25152 net.cpp:67] Creating Layer relu1_1
I1202 02:14:26.586346 25152 net.cpp:394] relu1_1 <- conv1_1
I1202 02:14:26.586350 25152 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:14:26.586362 25152 net.cpp:96] Setting up relu1_1
I1202 02:14:26.586369 25152 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:14:26.586371 25152 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:14:26.586377 25152 net.cpp:67] Creating Layer conv1_2
I1202 02:14:26.586380 25152 net.cpp:394] conv1_2 <- conv1_1
I1202 02:14:26.586385 25152 net.cpp:356] conv1_2 -> conv1_2
I1202 02:14:26.586390 25152 net.cpp:96] Setting up conv1_2
I1202 02:14:26.587440 25152 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:14:26.587453 25152 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:14:26.587458 25152 net.cpp:67] Creating Layer relu1_2
I1202 02:14:26.587471 25152 net.cpp:394] relu1_2 <- conv1_2
I1202 02:14:26.587476 25152 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:14:26.587479 25152 net.cpp:96] Setting up relu1_2
I1202 02:14:26.587486 25152 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:14:26.587488 25152 layer_factory.hpp:78] Creating layer pool1
I1202 02:14:26.587493 25152 net.cpp:67] Creating Layer pool1
I1202 02:14:26.587496 25152 net.cpp:394] pool1 <- conv1_2
I1202 02:14:26.587501 25152 net.cpp:356] pool1 -> pool1
I1202 02:14:26.587505 25152 net.cpp:96] Setting up pool1
I1202 02:14:26.587512 25152 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:14:26.587517 25152 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:14:26.587520 25152 net.cpp:67] Creating Layer conv2_1
I1202 02:14:26.587523 25152 net.cpp:394] conv2_1 <- pool1
I1202 02:14:26.587528 25152 net.cpp:356] conv2_1 -> conv2_1
I1202 02:14:26.587539 25152 net.cpp:96] Setting up conv2_1
I1202 02:14:26.589648 25152 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:14:26.589661 25152 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:14:26.589668 25152 net.cpp:67] Creating Layer relu2_1
I1202 02:14:26.589670 25152 net.cpp:394] relu2_1 <- conv2_1
I1202 02:14:26.589675 25152 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:14:26.589680 25152 net.cpp:96] Setting up relu2_1
I1202 02:14:26.589685 25152 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:14:26.589689 25152 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:14:26.589694 25152 net.cpp:67] Creating Layer conv2_2
I1202 02:14:26.589697 25152 net.cpp:394] conv2_2 <- conv2_1
I1202 02:14:26.589701 25152 net.cpp:356] conv2_2 -> conv2_2
I1202 02:14:26.589707 25152 net.cpp:96] Setting up conv2_2
I1202 02:14:26.593586 25152 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:14:26.593597 25152 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:14:26.593603 25152 net.cpp:67] Creating Layer relu2_2
I1202 02:14:26.593606 25152 net.cpp:394] relu2_2 <- conv2_2
I1202 02:14:26.593611 25152 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:14:26.593616 25152 net.cpp:96] Setting up relu2_2
I1202 02:14:26.593621 25152 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:14:26.593624 25152 layer_factory.hpp:78] Creating layer pool2
I1202 02:14:26.593628 25152 net.cpp:67] Creating Layer pool2
I1202 02:14:26.593631 25152 net.cpp:394] pool2 <- conv2_2
I1202 02:14:26.593636 25152 net.cpp:356] pool2 -> pool2
I1202 02:14:26.593641 25152 net.cpp:96] Setting up pool2
I1202 02:14:26.593647 25152 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:14:26.593649 25152 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:14:26.593654 25152 net.cpp:67] Creating Layer conv3_1
I1202 02:14:26.593657 25152 net.cpp:394] conv3_1 <- pool2
I1202 02:14:26.593662 25152 net.cpp:356] conv3_1 -> conv3_1
I1202 02:14:26.593667 25152 net.cpp:96] Setting up conv3_1
I1202 02:14:26.601367 25152 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:14:26.601387 25152 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:14:26.601392 25152 net.cpp:67] Creating Layer relu3_1
I1202 02:14:26.601397 25152 net.cpp:394] relu3_1 <- conv3_1
I1202 02:14:26.601402 25152 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:14:26.601408 25152 net.cpp:96] Setting up relu3_1
I1202 02:14:26.601413 25152 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:14:26.601416 25152 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:14:26.601428 25152 net.cpp:67] Creating Layer conv3_2
I1202 02:14:26.601431 25152 net.cpp:394] conv3_2 <- conv3_1
I1202 02:14:26.601436 25152 net.cpp:356] conv3_2 -> conv3_2
I1202 02:14:26.601443 25152 net.cpp:96] Setting up conv3_2
I1202 02:14:26.617076 25152 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:14:26.617099 25152 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:14:26.617105 25152 net.cpp:67] Creating Layer relu3_2
I1202 02:14:26.617110 25152 net.cpp:394] relu3_2 <- conv3_2
I1202 02:14:26.617117 25152 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:14:26.617125 25152 net.cpp:96] Setting up relu3_2
I1202 02:14:26.617130 25152 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:14:26.617133 25152 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:14:26.617141 25152 net.cpp:67] Creating Layer conv3_3
I1202 02:14:26.617144 25152 net.cpp:394] conv3_3 <- conv3_2
I1202 02:14:26.617151 25152 net.cpp:356] conv3_3 -> conv3_3
I1202 02:14:26.617156 25152 net.cpp:96] Setting up conv3_3
I1202 02:14:26.632828 25152 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:14:26.632851 25152 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:14:26.632858 25152 net.cpp:67] Creating Layer relu3_3
I1202 02:14:26.632863 25152 net.cpp:394] relu3_3 <- conv3_3
I1202 02:14:26.632870 25152 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:14:26.632877 25152 net.cpp:96] Setting up relu3_3
I1202 02:14:26.632882 25152 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:14:26.632885 25152 layer_factory.hpp:78] Creating layer pool3
I1202 02:14:26.632891 25152 net.cpp:67] Creating Layer pool3
I1202 02:14:26.632894 25152 net.cpp:394] pool3 <- conv3_3
I1202 02:14:26.632900 25152 net.cpp:356] pool3 -> pool3
I1202 02:14:26.632906 25152 net.cpp:96] Setting up pool3
I1202 02:14:26.632913 25152 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:14:26.632916 25152 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:14:26.632922 25152 net.cpp:67] Creating Layer conv4_1
I1202 02:14:26.632925 25152 net.cpp:394] conv4_1 <- pool3
I1202 02:14:26.632931 25152 net.cpp:356] conv4_1 -> conv4_1
I1202 02:14:26.632937 25152 net.cpp:96] Setting up conv4_1
I1202 02:14:26.664000 25152 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:14:26.664021 25152 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:14:26.664028 25152 net.cpp:67] Creating Layer relu4_1
I1202 02:14:26.664032 25152 net.cpp:394] relu4_1 <- conv4_1
I1202 02:14:26.664041 25152 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:14:26.664047 25152 net.cpp:96] Setting up relu4_1
I1202 02:14:26.664052 25152 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:14:26.664057 25152 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:14:26.664062 25152 net.cpp:67] Creating Layer conv4_2
I1202 02:14:26.664065 25152 net.cpp:394] conv4_2 <- conv4_1
I1202 02:14:26.664072 25152 net.cpp:356] conv4_2 -> conv4_2
I1202 02:14:26.664077 25152 net.cpp:96] Setting up conv4_2
I1202 02:14:26.725509 25152 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:14:26.725540 25152 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:14:26.725548 25152 net.cpp:67] Creating Layer relu4_2
I1202 02:14:26.725553 25152 net.cpp:394] relu4_2 <- conv4_2
I1202 02:14:26.725560 25152 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:14:26.725567 25152 net.cpp:96] Setting up relu4_2
I1202 02:14:26.725572 25152 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:14:26.725576 25152 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:14:26.725582 25152 net.cpp:67] Creating Layer conv4_3
I1202 02:14:26.725585 25152 net.cpp:394] conv4_3 <- conv4_2
I1202 02:14:26.725589 25152 net.cpp:356] conv4_3 -> conv4_3
I1202 02:14:26.725599 25152 net.cpp:96] Setting up conv4_3
I1202 02:14:26.786818 25152 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:14:26.786842 25152 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:14:26.786850 25152 net.cpp:67] Creating Layer relu4_3
I1202 02:14:26.786854 25152 net.cpp:394] relu4_3 <- conv4_3
I1202 02:14:26.786862 25152 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:14:26.786877 25152 net.cpp:96] Setting up relu4_3
I1202 02:14:26.786883 25152 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:14:26.786887 25152 layer_factory.hpp:78] Creating layer pool4
I1202 02:14:26.786892 25152 net.cpp:67] Creating Layer pool4
I1202 02:14:26.786896 25152 net.cpp:394] pool4 <- conv4_3
I1202 02:14:26.786900 25152 net.cpp:356] pool4 -> pool4
I1202 02:14:26.786906 25152 net.cpp:96] Setting up pool4
I1202 02:14:26.786913 25152 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:14:26.786916 25152 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:14:26.786923 25152 net.cpp:67] Creating Layer conv5_1
I1202 02:14:26.786927 25152 net.cpp:394] conv5_1 <- pool4
I1202 02:14:26.786931 25152 net.cpp:356] conv5_1 -> conv5_1
I1202 02:14:26.786937 25152 net.cpp:96] Setting up conv5_1
I1202 02:14:26.850685 25152 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:14:26.850710 25152 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:14:26.850719 25152 net.cpp:67] Creating Layer relu5_1
I1202 02:14:26.850723 25152 net.cpp:394] relu5_1 <- conv5_1
I1202 02:14:26.850729 25152 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:14:26.850735 25152 net.cpp:96] Setting up relu5_1
I1202 02:14:26.850741 25152 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:14:26.850744 25152 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:14:26.850750 25152 net.cpp:67] Creating Layer conv5_2
I1202 02:14:26.850754 25152 net.cpp:394] conv5_2 <- conv5_1
I1202 02:14:26.850760 25152 net.cpp:356] conv5_2 -> conv5_2
I1202 02:14:26.850765 25152 net.cpp:96] Setting up conv5_2
I1202 02:14:26.911994 25152 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:14:26.912019 25152 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:14:26.912026 25152 net.cpp:67] Creating Layer relu5_2
I1202 02:14:26.912030 25152 net.cpp:394] relu5_2 <- conv5_2
I1202 02:14:26.912037 25152 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:14:26.912045 25152 net.cpp:96] Setting up relu5_2
I1202 02:14:26.912050 25152 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:14:26.912053 25152 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:14:26.912061 25152 net.cpp:67] Creating Layer conv5_3
I1202 02:14:26.912065 25152 net.cpp:394] conv5_3 <- conv5_2
I1202 02:14:26.912072 25152 net.cpp:356] conv5_3 -> conv5_3
I1202 02:14:26.912078 25152 net.cpp:96] Setting up conv5_3
I1202 02:14:26.973657 25152 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:14:26.973682 25152 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:14:26.973690 25152 net.cpp:67] Creating Layer relu5_3
I1202 02:14:26.973695 25152 net.cpp:394] relu5_3 <- conv5_3
I1202 02:14:26.973702 25152 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:14:26.973709 25152 net.cpp:96] Setting up relu5_3
I1202 02:14:26.973714 25152 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:14:26.973718 25152 layer_factory.hpp:78] Creating layer pool5
I1202 02:14:26.973728 25152 net.cpp:67] Creating Layer pool5
I1202 02:14:26.973732 25152 net.cpp:394] pool5 <- conv5_3
I1202 02:14:26.973737 25152 net.cpp:356] pool5 -> pool5
I1202 02:14:26.973743 25152 net.cpp:96] Setting up pool5
I1202 02:14:26.973752 25152 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:14:26.973754 25152 layer_factory.hpp:78] Creating layer fc6
I1202 02:14:26.973760 25152 net.cpp:67] Creating Layer fc6
I1202 02:14:26.973763 25152 net.cpp:394] fc6 <- pool5
I1202 02:14:26.973769 25152 net.cpp:356] fc6 -> fc6
I1202 02:14:26.973774 25152 net.cpp:96] Setting up fc6
I1202 02:14:29.634627 25152 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:14:29.634657 25152 layer_factory.hpp:78] Creating layer relu6
I1202 02:14:29.634665 25152 net.cpp:67] Creating Layer relu6
I1202 02:14:29.634670 25152 net.cpp:394] relu6 <- fc6
I1202 02:14:29.634678 25152 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:14:29.634685 25152 net.cpp:96] Setting up relu6
I1202 02:14:29.634699 25152 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:14:29.634703 25152 layer_factory.hpp:78] Creating layer drop6
I1202 02:14:29.634718 25152 net.cpp:67] Creating Layer drop6
I1202 02:14:29.634722 25152 net.cpp:394] drop6 <- fc6
I1202 02:14:29.634727 25152 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:14:29.634732 25152 net.cpp:96] Setting up drop6
I1202 02:14:29.634735 25152 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:14:29.634738 25152 layer_factory.hpp:78] Creating layer fc7
I1202 02:14:29.634744 25152 net.cpp:67] Creating Layer fc7
I1202 02:14:29.634747 25152 net.cpp:394] fc7 <- fc6
I1202 02:14:29.634753 25152 net.cpp:356] fc7 -> fc7
I1202 02:14:29.634759 25152 net.cpp:96] Setting up fc7
I1202 02:14:30.072073 25152 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:14:30.072103 25152 layer_factory.hpp:78] Creating layer relu7
I1202 02:14:30.072111 25152 net.cpp:67] Creating Layer relu7
I1202 02:14:30.072116 25152 net.cpp:394] relu7 <- fc7
I1202 02:14:30.072124 25152 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:14:30.072130 25152 net.cpp:96] Setting up relu7
I1202 02:14:30.072144 25152 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:14:30.072147 25152 layer_factory.hpp:78] Creating layer drop7
I1202 02:14:30.072152 25152 net.cpp:67] Creating Layer drop7
I1202 02:14:30.072155 25152 net.cpp:394] drop7 <- fc7
I1202 02:14:30.072160 25152 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:14:30.072165 25152 net.cpp:96] Setting up drop7
I1202 02:14:30.072167 25152 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:14:30.072170 25152 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:14:30.072180 25152 net.cpp:67] Creating Layer fc8_2
I1202 02:14:30.072182 25152 net.cpp:394] fc8_2 <- fc7
I1202 02:14:30.072187 25152 net.cpp:356] fc8_2 -> fc8_2
I1202 02:14:30.072195 25152 net.cpp:96] Setting up fc8_2
I1202 02:14:30.072427 25152 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:14:30.072434 25152 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:14:30.072439 25152 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:14:30.072443 25152 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:14:30.072448 25152 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:14:30.072453 25152 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:14:30.072458 25152 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:14:30.072461 25152 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:14:30.072464 25152 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:14:30.072468 25152 layer_factory.hpp:78] Creating layer loss
I1202 02:14:30.072474 25152 net.cpp:67] Creating Layer loss
I1202 02:14:30.072477 25152 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:14:30.072481 25152 net.cpp:394] loss <- label_data_1_split_0
I1202 02:14:30.072486 25152 net.cpp:356] loss -> (automatic)
I1202 02:14:30.072497 25152 net.cpp:96] Setting up loss
I1202 02:14:30.072504 25152 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:14:30.072506 25152 net.cpp:109]     with loss weight 1
I1202 02:14:30.072520 25152 layer_factory.hpp:78] Creating layer accuracy
I1202 02:14:30.072526 25152 net.cpp:67] Creating Layer accuracy
I1202 02:14:30.072530 25152 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:14:30.072533 25152 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:14:30.072543 25152 net.cpp:356] accuracy -> accuracy
I1202 02:14:30.072551 25152 net.cpp:96] Setting up accuracy
I1202 02:14:30.072559 25152 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:14:30.072562 25152 net.cpp:172] accuracy does not need backward computation.
I1202 02:14:30.072566 25152 net.cpp:170] loss needs backward computation.
I1202 02:14:30.072568 25152 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:14:30.072571 25152 net.cpp:170] fc8_2 needs backward computation.
I1202 02:14:30.072574 25152 net.cpp:170] drop7 needs backward computation.
I1202 02:14:30.072576 25152 net.cpp:170] relu7 needs backward computation.
I1202 02:14:30.072579 25152 net.cpp:170] fc7 needs backward computation.
I1202 02:14:30.072582 25152 net.cpp:170] drop6 needs backward computation.
I1202 02:14:30.072585 25152 net.cpp:170] relu6 needs backward computation.
I1202 02:14:30.072595 25152 net.cpp:170] fc6 needs backward computation.
I1202 02:14:30.072599 25152 net.cpp:170] pool5 needs backward computation.
I1202 02:14:30.072602 25152 net.cpp:170] relu5_3 needs backward computation.
I1202 02:14:30.072605 25152 net.cpp:170] conv5_3 needs backward computation.
I1202 02:14:30.072608 25152 net.cpp:170] relu5_2 needs backward computation.
I1202 02:14:30.072612 25152 net.cpp:170] conv5_2 needs backward computation.
I1202 02:14:30.072614 25152 net.cpp:170] relu5_1 needs backward computation.
I1202 02:14:30.072618 25152 net.cpp:170] conv5_1 needs backward computation.
I1202 02:14:30.072620 25152 net.cpp:170] pool4 needs backward computation.
I1202 02:14:30.072623 25152 net.cpp:170] relu4_3 needs backward computation.
I1202 02:14:30.072626 25152 net.cpp:170] conv4_3 needs backward computation.
I1202 02:14:30.072629 25152 net.cpp:170] relu4_2 needs backward computation.
I1202 02:14:30.072631 25152 net.cpp:170] conv4_2 needs backward computation.
I1202 02:14:30.072634 25152 net.cpp:170] relu4_1 needs backward computation.
I1202 02:14:30.072638 25152 net.cpp:170] conv4_1 needs backward computation.
I1202 02:14:30.072640 25152 net.cpp:170] pool3 needs backward computation.
I1202 02:14:30.072643 25152 net.cpp:170] relu3_3 needs backward computation.
I1202 02:14:30.072646 25152 net.cpp:170] conv3_3 needs backward computation.
I1202 02:14:30.072649 25152 net.cpp:170] relu3_2 needs backward computation.
I1202 02:14:30.072652 25152 net.cpp:170] conv3_2 needs backward computation.
I1202 02:14:30.072655 25152 net.cpp:170] relu3_1 needs backward computation.
I1202 02:14:30.072657 25152 net.cpp:170] conv3_1 needs backward computation.
I1202 02:14:30.072660 25152 net.cpp:170] pool2 needs backward computation.
I1202 02:14:30.072664 25152 net.cpp:170] relu2_2 needs backward computation.
I1202 02:14:30.072666 25152 net.cpp:170] conv2_2 needs backward computation.
I1202 02:14:30.072669 25152 net.cpp:170] relu2_1 needs backward computation.
I1202 02:14:30.072672 25152 net.cpp:170] conv2_1 needs backward computation.
I1202 02:14:30.072675 25152 net.cpp:170] pool1 needs backward computation.
I1202 02:14:30.072679 25152 net.cpp:170] relu1_2 needs backward computation.
I1202 02:14:30.072681 25152 net.cpp:170] conv1_2 needs backward computation.
I1202 02:14:30.072685 25152 net.cpp:170] relu1_1 needs backward computation.
I1202 02:14:30.072687 25152 net.cpp:170] conv1_1 needs backward computation.
I1202 02:14:30.072690 25152 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:14:30.072693 25152 net.cpp:172] data does not need backward computation.
I1202 02:14:30.072695 25152 net.cpp:208] This network produces output accuracy
I1202 02:14:30.072716 25152 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:14:30.072726 25152 net.cpp:219] Network initialization done.
I1202 02:14:30.072727 25152 net.cpp:220] Memory required for data: 921616692
I1202 02:14:30.072830 25152 solver.cpp:41] Solver scaffolding done.
I1202 02:14:30.072836 25152 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_8000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:14:33.406190 25152 solver.cpp:160] Solving small
I1202 02:14:33.406220 25152 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:14:33.406267 25152 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:15:58.139381 25152 solver.cpp:305] Test loss: 0.512751
I1202 02:15:58.139436 25152 solver.cpp:318] mean_score = test_score[0] { = 2626} / test_score[1] { = 3570 }
I1202 02:15:58.139444 25152 solver.cpp:319]            = 0.735574
I1202 02:15:58.139452 25152 solver.cpp:328]     Test net output #0: accuracy = 0.735574
I1202 02:15:58.139457 25152 solver.cpp:318] mean_score = test_score[2] { = 294} / test_score[3] { = 398 }
I1202 02:15:58.139472 25152 solver.cpp:319]            = 0.738693
I1202 02:15:58.139475 25152 solver.cpp:328]     Test net output #1: accuracy = 0.738693
I1202 02:15:58.139487 25152 solver.cpp:332]     Test net output #2: accuracy = 0.735887
I1202 02:15:58.139492 25152 solver.cpp:334]     Test net output #3: accuracy = 0.737134
I1202 02:15:58.825076 25152 solver.cpp:209] Iteration 0, loss = 0.459264
I1202 02:15:58.825106 25152 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:16:01.134498 25152 solver.cpp:209] Iteration 1, loss = 0.408567
I1202 02:16:01.134526 25152 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:16:03.110942 25152 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:16:07.970767 25152 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:16:12.030652 25152 solver.cpp:246] Iteration 2, loss = 0.61517
I1202 02:16:12.030695 25152 solver.cpp:251] Optimization Done.
I1202 02:16:12.030702 25152 caffe.cpp:121] Optimization Done.
I1202 02:16:12.174343 25774 caffe.cpp:99] Use GPU with device ID 0
I1202 02:16:12.360762 25774 caffe.cpp:107] Starting Optimization
I1202 02:16:12.360857 25774 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:16:12.360882 25774 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:16:12.361656 25774 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:16:12.361685 25774 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:16:12.361884 25774 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:16:12.362007 25774 layer_factory.hpp:78] Creating layer data
I1202 02:16:12.362031 25774 net.cpp:67] Creating Layer data
I1202 02:16:12.362038 25774 net.cpp:356] data -> data
I1202 02:16:12.362056 25774 net.cpp:356] data -> label
I1202 02:16:12.362064 25774 net.cpp:96] Setting up data
I1202 02:16:12.362071 25774 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:16:12.376340 25774 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:16:12.387303 25774 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:16:12.390171 25774 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:16:12.390195 25774 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:16:12.390200 25774 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:16:12.390215 25774 net.cpp:67] Creating Layer conv1_1
I1202 02:16:12.390220 25774 net.cpp:394] conv1_1 <- data
I1202 02:16:12.390243 25774 net.cpp:356] conv1_1 -> conv1_1
I1202 02:16:12.390254 25774 net.cpp:96] Setting up conv1_1
I1202 02:16:12.529121 25774 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:16:12.529155 25774 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:16:12.529166 25774 net.cpp:67] Creating Layer relu1_1
I1202 02:16:12.529171 25774 net.cpp:394] relu1_1 <- conv1_1
I1202 02:16:12.529178 25774 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:16:12.529186 25774 net.cpp:96] Setting up relu1_1
I1202 02:16:12.529194 25774 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:16:12.529198 25774 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:16:12.529204 25774 net.cpp:67] Creating Layer conv1_2
I1202 02:16:12.529207 25774 net.cpp:394] conv1_2 <- conv1_1
I1202 02:16:12.529212 25774 net.cpp:356] conv1_2 -> conv1_2
I1202 02:16:12.529219 25774 net.cpp:96] Setting up conv1_2
I1202 02:16:12.530292 25774 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:16:12.530304 25774 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:16:12.530309 25774 net.cpp:67] Creating Layer relu1_2
I1202 02:16:12.530313 25774 net.cpp:394] relu1_2 <- conv1_2
I1202 02:16:12.530318 25774 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:16:12.530323 25774 net.cpp:96] Setting up relu1_2
I1202 02:16:12.530328 25774 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:16:12.530330 25774 layer_factory.hpp:78] Creating layer pool1
I1202 02:16:12.530339 25774 net.cpp:67] Creating Layer pool1
I1202 02:16:12.530341 25774 net.cpp:394] pool1 <- conv1_2
I1202 02:16:12.530347 25774 net.cpp:356] pool1 -> pool1
I1202 02:16:12.530354 25774 net.cpp:96] Setting up pool1
I1202 02:16:12.530369 25774 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:16:12.530374 25774 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:16:12.530380 25774 net.cpp:67] Creating Layer conv2_1
I1202 02:16:12.530383 25774 net.cpp:394] conv2_1 <- pool1
I1202 02:16:12.530387 25774 net.cpp:356] conv2_1 -> conv2_1
I1202 02:16:12.530392 25774 net.cpp:96] Setting up conv2_1
I1202 02:16:12.532320 25774 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:16:12.532335 25774 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:16:12.532341 25774 net.cpp:67] Creating Layer relu2_1
I1202 02:16:12.532343 25774 net.cpp:394] relu2_1 <- conv2_1
I1202 02:16:12.532348 25774 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:16:12.532352 25774 net.cpp:96] Setting up relu2_1
I1202 02:16:12.532357 25774 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:16:12.532361 25774 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:16:12.532366 25774 net.cpp:67] Creating Layer conv2_2
I1202 02:16:12.532369 25774 net.cpp:394] conv2_2 <- conv2_1
I1202 02:16:12.532376 25774 net.cpp:356] conv2_2 -> conv2_2
I1202 02:16:12.532380 25774 net.cpp:96] Setting up conv2_2
I1202 02:16:12.536146 25774 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:16:12.536160 25774 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:16:12.536165 25774 net.cpp:67] Creating Layer relu2_2
I1202 02:16:12.536170 25774 net.cpp:394] relu2_2 <- conv2_2
I1202 02:16:12.536173 25774 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:16:12.536178 25774 net.cpp:96] Setting up relu2_2
I1202 02:16:12.536183 25774 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:16:12.536195 25774 layer_factory.hpp:78] Creating layer pool2
I1202 02:16:12.536200 25774 net.cpp:67] Creating Layer pool2
I1202 02:16:12.536202 25774 net.cpp:394] pool2 <- conv2_2
I1202 02:16:12.536208 25774 net.cpp:356] pool2 -> pool2
I1202 02:16:12.536213 25774 net.cpp:96] Setting up pool2
I1202 02:16:12.536219 25774 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:16:12.536223 25774 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:16:12.536229 25774 net.cpp:67] Creating Layer conv3_1
I1202 02:16:12.536232 25774 net.cpp:394] conv3_1 <- pool2
I1202 02:16:12.536237 25774 net.cpp:356] conv3_1 -> conv3_1
I1202 02:16:12.536242 25774 net.cpp:96] Setting up conv3_1
I1202 02:16:12.543653 25774 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:16:12.543666 25774 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:16:12.543673 25774 net.cpp:67] Creating Layer relu3_1
I1202 02:16:12.543676 25774 net.cpp:394] relu3_1 <- conv3_1
I1202 02:16:12.543680 25774 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:16:12.543685 25774 net.cpp:96] Setting up relu3_1
I1202 02:16:12.543690 25774 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:16:12.543694 25774 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:16:12.543699 25774 net.cpp:67] Creating Layer conv3_2
I1202 02:16:12.543701 25774 net.cpp:394] conv3_2 <- conv3_1
I1202 02:16:12.543706 25774 net.cpp:356] conv3_2 -> conv3_2
I1202 02:16:12.543712 25774 net.cpp:96] Setting up conv3_2
I1202 02:16:12.558742 25774 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:16:12.558765 25774 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:16:12.558774 25774 net.cpp:67] Creating Layer relu3_2
I1202 02:16:12.558779 25774 net.cpp:394] relu3_2 <- conv3_2
I1202 02:16:12.558785 25774 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:16:12.558791 25774 net.cpp:96] Setting up relu3_2
I1202 02:16:12.558797 25774 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:16:12.558800 25774 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:16:12.558807 25774 net.cpp:67] Creating Layer conv3_3
I1202 02:16:12.558810 25774 net.cpp:394] conv3_3 <- conv3_2
I1202 02:16:12.558815 25774 net.cpp:356] conv3_3 -> conv3_3
I1202 02:16:12.558821 25774 net.cpp:96] Setting up conv3_3
I1202 02:16:12.573472 25774 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:16:12.573493 25774 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:16:12.573503 25774 net.cpp:67] Creating Layer relu3_3
I1202 02:16:12.573506 25774 net.cpp:394] relu3_3 <- conv3_3
I1202 02:16:12.573513 25774 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:16:12.573518 25774 net.cpp:96] Setting up relu3_3
I1202 02:16:12.573523 25774 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:16:12.573526 25774 layer_factory.hpp:78] Creating layer pool3
I1202 02:16:12.573532 25774 net.cpp:67] Creating Layer pool3
I1202 02:16:12.573535 25774 net.cpp:394] pool3 <- conv3_3
I1202 02:16:12.573539 25774 net.cpp:356] pool3 -> pool3
I1202 02:16:12.573545 25774 net.cpp:96] Setting up pool3
I1202 02:16:12.573552 25774 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:16:12.573555 25774 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:16:12.573561 25774 net.cpp:67] Creating Layer conv4_1
I1202 02:16:12.573565 25774 net.cpp:394] conv4_1 <- pool3
I1202 02:16:12.573570 25774 net.cpp:356] conv4_1 -> conv4_1
I1202 02:16:12.573575 25774 net.cpp:96] Setting up conv4_1
I1202 02:16:12.602589 25774 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:16:12.602612 25774 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:16:12.602620 25774 net.cpp:67] Creating Layer relu4_1
I1202 02:16:12.602624 25774 net.cpp:394] relu4_1 <- conv4_1
I1202 02:16:12.602632 25774 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:16:12.602638 25774 net.cpp:96] Setting up relu4_1
I1202 02:16:12.602644 25774 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:16:12.602648 25774 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:16:12.602653 25774 net.cpp:67] Creating Layer conv4_2
I1202 02:16:12.602656 25774 net.cpp:394] conv4_2 <- conv4_1
I1202 02:16:12.602671 25774 net.cpp:356] conv4_2 -> conv4_2
I1202 02:16:12.602677 25774 net.cpp:96] Setting up conv4_2
I1202 02:16:12.660840 25774 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:16:12.660867 25774 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:16:12.660876 25774 net.cpp:67] Creating Layer relu4_2
I1202 02:16:12.660881 25774 net.cpp:394] relu4_2 <- conv4_2
I1202 02:16:12.660887 25774 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:16:12.660893 25774 net.cpp:96] Setting up relu4_2
I1202 02:16:12.660899 25774 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:16:12.660902 25774 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:16:12.660908 25774 net.cpp:67] Creating Layer conv4_3
I1202 02:16:12.660912 25774 net.cpp:394] conv4_3 <- conv4_2
I1202 02:16:12.660917 25774 net.cpp:356] conv4_3 -> conv4_3
I1202 02:16:12.660923 25774 net.cpp:96] Setting up conv4_3
I1202 02:16:12.718924 25774 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:16:12.718950 25774 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:16:12.718958 25774 net.cpp:67] Creating Layer relu4_3
I1202 02:16:12.718962 25774 net.cpp:394] relu4_3 <- conv4_3
I1202 02:16:12.718969 25774 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:16:12.718977 25774 net.cpp:96] Setting up relu4_3
I1202 02:16:12.718984 25774 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:16:12.718987 25774 layer_factory.hpp:78] Creating layer pool4
I1202 02:16:12.718993 25774 net.cpp:67] Creating Layer pool4
I1202 02:16:12.718997 25774 net.cpp:394] pool4 <- conv4_3
I1202 02:16:12.719002 25774 net.cpp:356] pool4 -> pool4
I1202 02:16:12.719007 25774 net.cpp:96] Setting up pool4
I1202 02:16:12.719014 25774 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:16:12.719018 25774 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:16:12.719024 25774 net.cpp:67] Creating Layer conv5_1
I1202 02:16:12.719027 25774 net.cpp:394] conv5_1 <- pool4
I1202 02:16:12.719032 25774 net.cpp:356] conv5_1 -> conv5_1
I1202 02:16:12.719039 25774 net.cpp:96] Setting up conv5_1
I1202 02:16:12.777361 25774 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:16:12.777387 25774 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:16:12.777395 25774 net.cpp:67] Creating Layer relu5_1
I1202 02:16:12.777400 25774 net.cpp:394] relu5_1 <- conv5_1
I1202 02:16:12.777405 25774 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:16:12.777412 25774 net.cpp:96] Setting up relu5_1
I1202 02:16:12.777418 25774 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:16:12.777421 25774 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:16:12.777434 25774 net.cpp:67] Creating Layer conv5_2
I1202 02:16:12.777438 25774 net.cpp:394] conv5_2 <- conv5_1
I1202 02:16:12.777443 25774 net.cpp:356] conv5_2 -> conv5_2
I1202 02:16:12.777449 25774 net.cpp:96] Setting up conv5_2
I1202 02:16:12.835487 25774 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:16:12.835513 25774 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:16:12.835522 25774 net.cpp:67] Creating Layer relu5_2
I1202 02:16:12.835526 25774 net.cpp:394] relu5_2 <- conv5_2
I1202 02:16:12.835533 25774 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:16:12.835539 25774 net.cpp:96] Setting up relu5_2
I1202 02:16:12.835546 25774 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:16:12.835548 25774 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:16:12.835556 25774 net.cpp:67] Creating Layer conv5_3
I1202 02:16:12.835557 25774 net.cpp:394] conv5_3 <- conv5_2
I1202 02:16:12.835562 25774 net.cpp:356] conv5_3 -> conv5_3
I1202 02:16:12.835568 25774 net.cpp:96] Setting up conv5_3
I1202 02:16:12.893724 25774 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:16:12.893749 25774 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:16:12.893757 25774 net.cpp:67] Creating Layer relu5_3
I1202 02:16:12.893760 25774 net.cpp:394] relu5_3 <- conv5_3
I1202 02:16:12.893766 25774 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:16:12.893774 25774 net.cpp:96] Setting up relu5_3
I1202 02:16:12.893779 25774 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:16:12.893791 25774 layer_factory.hpp:78] Creating layer pool5
I1202 02:16:12.893798 25774 net.cpp:67] Creating Layer pool5
I1202 02:16:12.893801 25774 net.cpp:394] pool5 <- conv5_3
I1202 02:16:12.893806 25774 net.cpp:356] pool5 -> pool5
I1202 02:16:12.893812 25774 net.cpp:96] Setting up pool5
I1202 02:16:12.893820 25774 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:16:12.893822 25774 layer_factory.hpp:78] Creating layer fc6
I1202 02:16:12.893836 25774 net.cpp:67] Creating Layer fc6
I1202 02:16:12.893839 25774 net.cpp:394] fc6 <- pool5
I1202 02:16:12.893846 25774 net.cpp:356] fc6 -> fc6
I1202 02:16:12.893851 25774 net.cpp:96] Setting up fc6
I1202 02:16:15.402824 25774 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:16:15.402855 25774 layer_factory.hpp:78] Creating layer relu6
I1202 02:16:15.402864 25774 net.cpp:67] Creating Layer relu6
I1202 02:16:15.402868 25774 net.cpp:394] relu6 <- fc6
I1202 02:16:15.402876 25774 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:16:15.402884 25774 net.cpp:96] Setting up relu6
I1202 02:16:15.402899 25774 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:16:15.402901 25774 layer_factory.hpp:78] Creating layer drop6
I1202 02:16:15.402907 25774 net.cpp:67] Creating Layer drop6
I1202 02:16:15.402910 25774 net.cpp:394] drop6 <- fc6
I1202 02:16:15.402915 25774 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:16:15.402920 25774 net.cpp:96] Setting up drop6
I1202 02:16:15.402923 25774 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:16:15.402926 25774 layer_factory.hpp:78] Creating layer fc7
I1202 02:16:15.402933 25774 net.cpp:67] Creating Layer fc7
I1202 02:16:15.402936 25774 net.cpp:394] fc7 <- fc6
I1202 02:16:15.402941 25774 net.cpp:356] fc7 -> fc7
I1202 02:16:15.402947 25774 net.cpp:96] Setting up fc7
I1202 02:16:15.814359 25774 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:16:15.814389 25774 layer_factory.hpp:78] Creating layer relu7
I1202 02:16:15.814399 25774 net.cpp:67] Creating Layer relu7
I1202 02:16:15.814402 25774 net.cpp:394] relu7 <- fc7
I1202 02:16:15.814409 25774 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:16:15.814415 25774 net.cpp:96] Setting up relu7
I1202 02:16:15.814429 25774 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:16:15.814434 25774 layer_factory.hpp:78] Creating layer drop7
I1202 02:16:15.814438 25774 net.cpp:67] Creating Layer drop7
I1202 02:16:15.814441 25774 net.cpp:394] drop7 <- fc7
I1202 02:16:15.814448 25774 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:16:15.814453 25774 net.cpp:96] Setting up drop7
I1202 02:16:15.814457 25774 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:16:15.814460 25774 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:16:15.814465 25774 net.cpp:67] Creating Layer fc8_2
I1202 02:16:15.814468 25774 net.cpp:394] fc8_2 <- fc7
I1202 02:16:15.814473 25774 net.cpp:356] fc8_2 -> fc8_2
I1202 02:16:15.814479 25774 net.cpp:96] Setting up fc8_2
I1202 02:16:15.814700 25774 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:16:15.814708 25774 layer_factory.hpp:78] Creating layer loss
I1202 02:16:15.814717 25774 net.cpp:67] Creating Layer loss
I1202 02:16:15.814719 25774 net.cpp:394] loss <- fc8_2
I1202 02:16:15.814723 25774 net.cpp:394] loss <- label
I1202 02:16:15.814733 25774 net.cpp:356] loss -> (automatic)
I1202 02:16:15.814736 25774 net.cpp:96] Setting up loss
I1202 02:16:15.814745 25774 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:16:15.814749 25774 net.cpp:109]     with loss weight 1
I1202 02:16:15.814784 25774 net.cpp:170] loss needs backward computation.
I1202 02:16:15.814787 25774 net.cpp:170] fc8_2 needs backward computation.
I1202 02:16:15.814790 25774 net.cpp:170] drop7 needs backward computation.
I1202 02:16:15.814792 25774 net.cpp:170] relu7 needs backward computation.
I1202 02:16:15.814795 25774 net.cpp:170] fc7 needs backward computation.
I1202 02:16:15.814797 25774 net.cpp:170] drop6 needs backward computation.
I1202 02:16:15.814800 25774 net.cpp:170] relu6 needs backward computation.
I1202 02:16:15.814803 25774 net.cpp:170] fc6 needs backward computation.
I1202 02:16:15.814815 25774 net.cpp:170] pool5 needs backward computation.
I1202 02:16:15.814817 25774 net.cpp:170] relu5_3 needs backward computation.
I1202 02:16:15.814826 25774 net.cpp:170] conv5_3 needs backward computation.
I1202 02:16:15.814828 25774 net.cpp:170] relu5_2 needs backward computation.
I1202 02:16:15.814831 25774 net.cpp:170] conv5_2 needs backward computation.
I1202 02:16:15.814834 25774 net.cpp:170] relu5_1 needs backward computation.
I1202 02:16:15.814836 25774 net.cpp:170] conv5_1 needs backward computation.
I1202 02:16:15.814841 25774 net.cpp:170] pool4 needs backward computation.
I1202 02:16:15.814843 25774 net.cpp:170] relu4_3 needs backward computation.
I1202 02:16:15.814846 25774 net.cpp:170] conv4_3 needs backward computation.
I1202 02:16:15.814849 25774 net.cpp:170] relu4_2 needs backward computation.
I1202 02:16:15.814853 25774 net.cpp:170] conv4_2 needs backward computation.
I1202 02:16:15.814857 25774 net.cpp:170] relu4_1 needs backward computation.
I1202 02:16:15.814859 25774 net.cpp:170] conv4_1 needs backward computation.
I1202 02:16:15.814862 25774 net.cpp:170] pool3 needs backward computation.
I1202 02:16:15.814865 25774 net.cpp:170] relu3_3 needs backward computation.
I1202 02:16:15.814868 25774 net.cpp:170] conv3_3 needs backward computation.
I1202 02:16:15.814872 25774 net.cpp:170] relu3_2 needs backward computation.
I1202 02:16:15.814874 25774 net.cpp:170] conv3_2 needs backward computation.
I1202 02:16:15.814877 25774 net.cpp:170] relu3_1 needs backward computation.
I1202 02:16:15.814879 25774 net.cpp:170] conv3_1 needs backward computation.
I1202 02:16:15.814882 25774 net.cpp:170] pool2 needs backward computation.
I1202 02:16:15.814885 25774 net.cpp:170] relu2_2 needs backward computation.
I1202 02:16:15.814888 25774 net.cpp:170] conv2_2 needs backward computation.
I1202 02:16:15.814890 25774 net.cpp:170] relu2_1 needs backward computation.
I1202 02:16:15.814893 25774 net.cpp:170] conv2_1 needs backward computation.
I1202 02:16:15.814896 25774 net.cpp:170] pool1 needs backward computation.
I1202 02:16:15.814899 25774 net.cpp:170] relu1_2 needs backward computation.
I1202 02:16:15.814901 25774 net.cpp:170] conv1_2 needs backward computation.
I1202 02:16:15.814904 25774 net.cpp:170] relu1_1 needs backward computation.
I1202 02:16:15.814906 25774 net.cpp:170] conv1_1 needs backward computation.
I1202 02:16:15.814909 25774 net.cpp:172] data does not need backward computation.
I1202 02:16:15.814926 25774 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:16:15.814934 25774 net.cpp:219] Network initialization done.
I1202 02:16:15.814936 25774 net.cpp:220] Memory required for data: 3686465924
I1202 02:16:15.815795 25774 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:16:15.815840 25774 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:16:15.816046 25774 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:16:15.816190 25774 layer_factory.hpp:78] Creating layer data
I1202 02:16:15.816200 25774 net.cpp:67] Creating Layer data
I1202 02:16:15.816205 25774 net.cpp:356] data -> data
I1202 02:16:15.816212 25774 net.cpp:356] data -> label
I1202 02:16:15.816218 25774 net.cpp:96] Setting up data
I1202 02:16:15.816221 25774 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:16:15.817798 25774 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:16:15.824842 25774 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:16:15.825752 25774 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:16:15.825762 25774 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:16:15.825765 25774 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:16:15.825778 25774 net.cpp:67] Creating Layer label_data_1_split
I1202 02:16:15.825783 25774 net.cpp:394] label_data_1_split <- label
I1202 02:16:15.825789 25774 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:16:15.825798 25774 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:16:15.825803 25774 net.cpp:96] Setting up label_data_1_split
I1202 02:16:15.825808 25774 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:16:15.825810 25774 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:16:15.825814 25774 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:16:15.825819 25774 net.cpp:67] Creating Layer conv1_1
I1202 02:16:15.825824 25774 net.cpp:394] conv1_1 <- data
I1202 02:16:15.825827 25774 net.cpp:356] conv1_1 -> conv1_1
I1202 02:16:15.825834 25774 net.cpp:96] Setting up conv1_1
I1202 02:16:15.825989 25774 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:16:15.826004 25774 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:16:15.826009 25774 net.cpp:67] Creating Layer relu1_1
I1202 02:16:15.826011 25774 net.cpp:394] relu1_1 <- conv1_1
I1202 02:16:15.826016 25774 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:16:15.826028 25774 net.cpp:96] Setting up relu1_1
I1202 02:16:15.826035 25774 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:16:15.826037 25774 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:16:15.826043 25774 net.cpp:67] Creating Layer conv1_2
I1202 02:16:15.826046 25774 net.cpp:394] conv1_2 <- conv1_1
I1202 02:16:15.826050 25774 net.cpp:356] conv1_2 -> conv1_2
I1202 02:16:15.826056 25774 net.cpp:96] Setting up conv1_2
I1202 02:16:15.827059 25774 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:16:15.827070 25774 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:16:15.827075 25774 net.cpp:67] Creating Layer relu1_2
I1202 02:16:15.827078 25774 net.cpp:394] relu1_2 <- conv1_2
I1202 02:16:15.827083 25774 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:16:15.827087 25774 net.cpp:96] Setting up relu1_2
I1202 02:16:15.827092 25774 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:16:15.827095 25774 layer_factory.hpp:78] Creating layer pool1
I1202 02:16:15.827100 25774 net.cpp:67] Creating Layer pool1
I1202 02:16:15.827103 25774 net.cpp:394] pool1 <- conv1_2
I1202 02:16:15.827107 25774 net.cpp:356] pool1 -> pool1
I1202 02:16:15.827112 25774 net.cpp:96] Setting up pool1
I1202 02:16:15.827119 25774 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:16:15.827122 25774 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:16:15.827127 25774 net.cpp:67] Creating Layer conv2_1
I1202 02:16:15.827131 25774 net.cpp:394] conv2_1 <- pool1
I1202 02:16:15.827134 25774 net.cpp:356] conv2_1 -> conv2_1
I1202 02:16:15.827139 25774 net.cpp:96] Setting up conv2_1
I1202 02:16:15.829154 25774 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:16:15.829167 25774 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:16:15.829174 25774 net.cpp:67] Creating Layer relu2_1
I1202 02:16:15.829176 25774 net.cpp:394] relu2_1 <- conv2_1
I1202 02:16:15.829180 25774 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:16:15.829186 25774 net.cpp:96] Setting up relu2_1
I1202 02:16:15.829191 25774 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:16:15.829195 25774 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:16:15.829200 25774 net.cpp:67] Creating Layer conv2_2
I1202 02:16:15.829202 25774 net.cpp:394] conv2_2 <- conv2_1
I1202 02:16:15.829206 25774 net.cpp:356] conv2_2 -> conv2_2
I1202 02:16:15.829212 25774 net.cpp:96] Setting up conv2_2
I1202 02:16:15.832990 25774 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:16:15.833003 25774 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:16:15.833008 25774 net.cpp:67] Creating Layer relu2_2
I1202 02:16:15.833011 25774 net.cpp:394] relu2_2 <- conv2_2
I1202 02:16:15.833016 25774 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:16:15.833020 25774 net.cpp:96] Setting up relu2_2
I1202 02:16:15.833025 25774 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:16:15.833029 25774 layer_factory.hpp:78] Creating layer pool2
I1202 02:16:15.833034 25774 net.cpp:67] Creating Layer pool2
I1202 02:16:15.833036 25774 net.cpp:394] pool2 <- conv2_2
I1202 02:16:15.833040 25774 net.cpp:356] pool2 -> pool2
I1202 02:16:15.833045 25774 net.cpp:96] Setting up pool2
I1202 02:16:15.833050 25774 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:16:15.833053 25774 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:16:15.833058 25774 net.cpp:67] Creating Layer conv3_1
I1202 02:16:15.833061 25774 net.cpp:394] conv3_1 <- pool2
I1202 02:16:15.833066 25774 net.cpp:356] conv3_1 -> conv3_1
I1202 02:16:15.833071 25774 net.cpp:96] Setting up conv3_1
I1202 02:16:15.840315 25774 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:16:15.840332 25774 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:16:15.840337 25774 net.cpp:67] Creating Layer relu3_1
I1202 02:16:15.840340 25774 net.cpp:394] relu3_1 <- conv3_1
I1202 02:16:15.840345 25774 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:16:15.840350 25774 net.cpp:96] Setting up relu3_1
I1202 02:16:15.840355 25774 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:16:15.840359 25774 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:16:15.840373 25774 net.cpp:67] Creating Layer conv3_2
I1202 02:16:15.840375 25774 net.cpp:394] conv3_2 <- conv3_1
I1202 02:16:15.840380 25774 net.cpp:356] conv3_2 -> conv3_2
I1202 02:16:15.840385 25774 net.cpp:96] Setting up conv3_2
I1202 02:16:15.854995 25774 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:16:15.855013 25774 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:16:15.855021 25774 net.cpp:67] Creating Layer relu3_2
I1202 02:16:15.855026 25774 net.cpp:394] relu3_2 <- conv3_2
I1202 02:16:15.855031 25774 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:16:15.855036 25774 net.cpp:96] Setting up relu3_2
I1202 02:16:15.855042 25774 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:16:15.855046 25774 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:16:15.855053 25774 net.cpp:67] Creating Layer conv3_3
I1202 02:16:15.855057 25774 net.cpp:394] conv3_3 <- conv3_2
I1202 02:16:15.855062 25774 net.cpp:356] conv3_3 -> conv3_3
I1202 02:16:15.855067 25774 net.cpp:96] Setting up conv3_3
I1202 02:16:15.870054 25774 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:16:15.870077 25774 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:16:15.870086 25774 net.cpp:67] Creating Layer relu3_3
I1202 02:16:15.870092 25774 net.cpp:394] relu3_3 <- conv3_3
I1202 02:16:15.870098 25774 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:16:15.870105 25774 net.cpp:96] Setting up relu3_3
I1202 02:16:15.870111 25774 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:16:15.870115 25774 layer_factory.hpp:78] Creating layer pool3
I1202 02:16:15.870120 25774 net.cpp:67] Creating Layer pool3
I1202 02:16:15.870122 25774 net.cpp:394] pool3 <- conv3_3
I1202 02:16:15.870128 25774 net.cpp:356] pool3 -> pool3
I1202 02:16:15.870134 25774 net.cpp:96] Setting up pool3
I1202 02:16:15.870141 25774 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:16:15.870146 25774 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:16:15.870151 25774 net.cpp:67] Creating Layer conv4_1
I1202 02:16:15.870153 25774 net.cpp:394] conv4_1 <- pool3
I1202 02:16:15.870159 25774 net.cpp:356] conv4_1 -> conv4_1
I1202 02:16:15.870165 25774 net.cpp:96] Setting up conv4_1
I1202 02:16:15.899564 25774 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:16:15.899587 25774 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:16:15.899596 25774 net.cpp:67] Creating Layer relu4_1
I1202 02:16:15.899600 25774 net.cpp:394] relu4_1 <- conv4_1
I1202 02:16:15.899608 25774 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:16:15.899616 25774 net.cpp:96] Setting up relu4_1
I1202 02:16:15.899621 25774 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:16:15.899623 25774 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:16:15.899631 25774 net.cpp:67] Creating Layer conv4_2
I1202 02:16:15.899633 25774 net.cpp:394] conv4_2 <- conv4_1
I1202 02:16:15.899638 25774 net.cpp:356] conv4_2 -> conv4_2
I1202 02:16:15.899644 25774 net.cpp:96] Setting up conv4_2
I1202 02:16:15.957626 25774 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:16:15.957659 25774 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:16:15.957666 25774 net.cpp:67] Creating Layer relu4_2
I1202 02:16:15.957671 25774 net.cpp:394] relu4_2 <- conv4_2
I1202 02:16:15.957679 25774 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:16:15.957685 25774 net.cpp:96] Setting up relu4_2
I1202 02:16:15.957690 25774 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:16:15.957694 25774 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:16:15.957700 25774 net.cpp:67] Creating Layer conv4_3
I1202 02:16:15.957702 25774 net.cpp:394] conv4_3 <- conv4_2
I1202 02:16:15.957710 25774 net.cpp:356] conv4_3 -> conv4_3
I1202 02:16:15.957716 25774 net.cpp:96] Setting up conv4_3
I1202 02:16:16.015831 25774 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:16:16.015856 25774 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:16:16.015863 25774 net.cpp:67] Creating Layer relu4_3
I1202 02:16:16.015867 25774 net.cpp:394] relu4_3 <- conv4_3
I1202 02:16:16.015876 25774 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:16:16.015890 25774 net.cpp:96] Setting up relu4_3
I1202 02:16:16.015897 25774 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:16:16.015899 25774 layer_factory.hpp:78] Creating layer pool4
I1202 02:16:16.015905 25774 net.cpp:67] Creating Layer pool4
I1202 02:16:16.015908 25774 net.cpp:394] pool4 <- conv4_3
I1202 02:16:16.015913 25774 net.cpp:356] pool4 -> pool4
I1202 02:16:16.015918 25774 net.cpp:96] Setting up pool4
I1202 02:16:16.015925 25774 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:16:16.015928 25774 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:16:16.015935 25774 net.cpp:67] Creating Layer conv5_1
I1202 02:16:16.015938 25774 net.cpp:394] conv5_1 <- pool4
I1202 02:16:16.015944 25774 net.cpp:356] conv5_1 -> conv5_1
I1202 02:16:16.015949 25774 net.cpp:96] Setting up conv5_1
I1202 02:16:16.074262 25774 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:16:16.074288 25774 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:16:16.074297 25774 net.cpp:67] Creating Layer relu5_1
I1202 02:16:16.074302 25774 net.cpp:394] relu5_1 <- conv5_1
I1202 02:16:16.074308 25774 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:16:16.074316 25774 net.cpp:96] Setting up relu5_1
I1202 02:16:16.074321 25774 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:16:16.074324 25774 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:16:16.074331 25774 net.cpp:67] Creating Layer conv5_2
I1202 02:16:16.074333 25774 net.cpp:394] conv5_2 <- conv5_1
I1202 02:16:16.074340 25774 net.cpp:356] conv5_2 -> conv5_2
I1202 02:16:16.074350 25774 net.cpp:96] Setting up conv5_2
I1202 02:16:16.132488 25774 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:16:16.132520 25774 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:16:16.132531 25774 net.cpp:67] Creating Layer relu5_2
I1202 02:16:16.132539 25774 net.cpp:394] relu5_2 <- conv5_2
I1202 02:16:16.132550 25774 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:16:16.132562 25774 net.cpp:96] Setting up relu5_2
I1202 02:16:16.132573 25774 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:16:16.132580 25774 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:16:16.132589 25774 net.cpp:67] Creating Layer conv5_3
I1202 02:16:16.132597 25774 net.cpp:394] conv5_3 <- conv5_2
I1202 02:16:16.132608 25774 net.cpp:356] conv5_3 -> conv5_3
I1202 02:16:16.132621 25774 net.cpp:96] Setting up conv5_3
I1202 02:16:16.190698 25774 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:16:16.190726 25774 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:16:16.190733 25774 net.cpp:67] Creating Layer relu5_3
I1202 02:16:16.190738 25774 net.cpp:394] relu5_3 <- conv5_3
I1202 02:16:16.190745 25774 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:16:16.190752 25774 net.cpp:96] Setting up relu5_3
I1202 02:16:16.190758 25774 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:16:16.190762 25774 layer_factory.hpp:78] Creating layer pool5
I1202 02:16:16.190773 25774 net.cpp:67] Creating Layer pool5
I1202 02:16:16.190778 25774 net.cpp:394] pool5 <- conv5_3
I1202 02:16:16.190783 25774 net.cpp:356] pool5 -> pool5
I1202 02:16:16.190789 25774 net.cpp:96] Setting up pool5
I1202 02:16:16.190798 25774 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:16:16.190803 25774 layer_factory.hpp:78] Creating layer fc6
I1202 02:16:16.190807 25774 net.cpp:67] Creating Layer fc6
I1202 02:16:16.190810 25774 net.cpp:394] fc6 <- pool5
I1202 02:16:16.190816 25774 net.cpp:356] fc6 -> fc6
I1202 02:16:16.190821 25774 net.cpp:96] Setting up fc6
I1202 02:16:18.700793 25774 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:16:18.700821 25774 layer_factory.hpp:78] Creating layer relu6
I1202 02:16:18.700829 25774 net.cpp:67] Creating Layer relu6
I1202 02:16:18.700834 25774 net.cpp:394] relu6 <- fc6
I1202 02:16:18.700842 25774 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:16:18.700850 25774 net.cpp:96] Setting up relu6
I1202 02:16:18.700863 25774 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:16:18.700867 25774 layer_factory.hpp:78] Creating layer drop6
I1202 02:16:18.700882 25774 net.cpp:67] Creating Layer drop6
I1202 02:16:18.700886 25774 net.cpp:394] drop6 <- fc6
I1202 02:16:18.700889 25774 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:16:18.700894 25774 net.cpp:96] Setting up drop6
I1202 02:16:18.700898 25774 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:16:18.700901 25774 layer_factory.hpp:78] Creating layer fc7
I1202 02:16:18.700908 25774 net.cpp:67] Creating Layer fc7
I1202 02:16:18.700911 25774 net.cpp:394] fc7 <- fc6
I1202 02:16:18.700917 25774 net.cpp:356] fc7 -> fc7
I1202 02:16:18.700922 25774 net.cpp:96] Setting up fc7
I1202 02:16:19.111423 25774 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:16:19.111454 25774 layer_factory.hpp:78] Creating layer relu7
I1202 02:16:19.111464 25774 net.cpp:67] Creating Layer relu7
I1202 02:16:19.111470 25774 net.cpp:394] relu7 <- fc7
I1202 02:16:19.111477 25774 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:16:19.111484 25774 net.cpp:96] Setting up relu7
I1202 02:16:19.111498 25774 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:16:19.111502 25774 layer_factory.hpp:78] Creating layer drop7
I1202 02:16:19.111507 25774 net.cpp:67] Creating Layer drop7
I1202 02:16:19.111510 25774 net.cpp:394] drop7 <- fc7
I1202 02:16:19.111516 25774 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:16:19.111521 25774 net.cpp:96] Setting up drop7
I1202 02:16:19.111524 25774 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:16:19.111527 25774 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:16:19.111533 25774 net.cpp:67] Creating Layer fc8_2
I1202 02:16:19.111536 25774 net.cpp:394] fc8_2 <- fc7
I1202 02:16:19.111544 25774 net.cpp:356] fc8_2 -> fc8_2
I1202 02:16:19.111557 25774 net.cpp:96] Setting up fc8_2
I1202 02:16:19.111776 25774 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:16:19.111784 25774 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:16:19.111789 25774 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:16:19.111793 25774 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:16:19.111798 25774 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:16:19.111803 25774 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:16:19.111809 25774 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:16:19.111814 25774 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:16:19.111816 25774 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:16:19.111819 25774 layer_factory.hpp:78] Creating layer loss
I1202 02:16:19.111824 25774 net.cpp:67] Creating Layer loss
I1202 02:16:19.111827 25774 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:16:19.111832 25774 net.cpp:394] loss <- label_data_1_split_0
I1202 02:16:19.111836 25774 net.cpp:356] loss -> (automatic)
I1202 02:16:19.111848 25774 net.cpp:96] Setting up loss
I1202 02:16:19.111855 25774 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:16:19.111860 25774 net.cpp:109]     with loss weight 1
I1202 02:16:19.111874 25774 layer_factory.hpp:78] Creating layer accuracy
I1202 02:16:19.111879 25774 net.cpp:67] Creating Layer accuracy
I1202 02:16:19.111882 25774 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:16:19.111886 25774 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:16:19.111897 25774 net.cpp:356] accuracy -> accuracy
I1202 02:16:19.111903 25774 net.cpp:96] Setting up accuracy
I1202 02:16:19.111912 25774 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:16:19.111917 25774 net.cpp:172] accuracy does not need backward computation.
I1202 02:16:19.111919 25774 net.cpp:170] loss needs backward computation.
I1202 02:16:19.111922 25774 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:16:19.111925 25774 net.cpp:170] fc8_2 needs backward computation.
I1202 02:16:19.111928 25774 net.cpp:170] drop7 needs backward computation.
I1202 02:16:19.111930 25774 net.cpp:170] relu7 needs backward computation.
I1202 02:16:19.111933 25774 net.cpp:170] fc7 needs backward computation.
I1202 02:16:19.111937 25774 net.cpp:170] drop6 needs backward computation.
I1202 02:16:19.111939 25774 net.cpp:170] relu6 needs backward computation.
I1202 02:16:19.111949 25774 net.cpp:170] fc6 needs backward computation.
I1202 02:16:19.111953 25774 net.cpp:170] pool5 needs backward computation.
I1202 02:16:19.111955 25774 net.cpp:170] relu5_3 needs backward computation.
I1202 02:16:19.111958 25774 net.cpp:170] conv5_3 needs backward computation.
I1202 02:16:19.111961 25774 net.cpp:170] relu5_2 needs backward computation.
I1202 02:16:19.111963 25774 net.cpp:170] conv5_2 needs backward computation.
I1202 02:16:19.111966 25774 net.cpp:170] relu5_1 needs backward computation.
I1202 02:16:19.111969 25774 net.cpp:170] conv5_1 needs backward computation.
I1202 02:16:19.111973 25774 net.cpp:170] pool4 needs backward computation.
I1202 02:16:19.111975 25774 net.cpp:170] relu4_3 needs backward computation.
I1202 02:16:19.111979 25774 net.cpp:170] conv4_3 needs backward computation.
I1202 02:16:19.111981 25774 net.cpp:170] relu4_2 needs backward computation.
I1202 02:16:19.111984 25774 net.cpp:170] conv4_2 needs backward computation.
I1202 02:16:19.111986 25774 net.cpp:170] relu4_1 needs backward computation.
I1202 02:16:19.111989 25774 net.cpp:170] conv4_1 needs backward computation.
I1202 02:16:19.111992 25774 net.cpp:170] pool3 needs backward computation.
I1202 02:16:19.111995 25774 net.cpp:170] relu3_3 needs backward computation.
I1202 02:16:19.111997 25774 net.cpp:170] conv3_3 needs backward computation.
I1202 02:16:19.112000 25774 net.cpp:170] relu3_2 needs backward computation.
I1202 02:16:19.112004 25774 net.cpp:170] conv3_2 needs backward computation.
I1202 02:16:19.112005 25774 net.cpp:170] relu3_1 needs backward computation.
I1202 02:16:19.112009 25774 net.cpp:170] conv3_1 needs backward computation.
I1202 02:16:19.112011 25774 net.cpp:170] pool2 needs backward computation.
I1202 02:16:19.112015 25774 net.cpp:170] relu2_2 needs backward computation.
I1202 02:16:19.112017 25774 net.cpp:170] conv2_2 needs backward computation.
I1202 02:16:19.112020 25774 net.cpp:170] relu2_1 needs backward computation.
I1202 02:16:19.112022 25774 net.cpp:170] conv2_1 needs backward computation.
I1202 02:16:19.112025 25774 net.cpp:170] pool1 needs backward computation.
I1202 02:16:19.112028 25774 net.cpp:170] relu1_2 needs backward computation.
I1202 02:16:19.112030 25774 net.cpp:170] conv1_2 needs backward computation.
I1202 02:16:19.112033 25774 net.cpp:170] relu1_1 needs backward computation.
I1202 02:16:19.112035 25774 net.cpp:170] conv1_1 needs backward computation.
I1202 02:16:19.112038 25774 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:16:19.112041 25774 net.cpp:172] data does not need backward computation.
I1202 02:16:19.112045 25774 net.cpp:208] This network produces output accuracy
I1202 02:16:19.112064 25774 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:16:19.112072 25774 net.cpp:219] Network initialization done.
I1202 02:16:19.112077 25774 net.cpp:220] Memory required for data: 921616692
I1202 02:16:19.112175 25774 solver.cpp:41] Solver scaffolding done.
I1202 02:16:19.112181 25774 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_10000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:16:22.444571 25774 solver.cpp:160] Solving small
I1202 02:16:22.444596 25774 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:16:22.444641 25774 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:17:47.148737 25774 solver.cpp:305] Test loss: 0.472344
I1202 02:17:47.148821 25774 solver.cpp:318] mean_score = test_score[0] { = 2763} / test_score[1] { = 3570 }
I1202 02:17:47.148831 25774 solver.cpp:319]            = 0.77395
I1202 02:17:47.148839 25774 solver.cpp:328]     Test net output #0: accuracy = 0.77395
I1202 02:17:47.148844 25774 solver.cpp:318] mean_score = test_score[2] { = 279} / test_score[3] { = 398 }
I1202 02:17:47.148849 25774 solver.cpp:319]            = 0.701005
I1202 02:17:47.148854 25774 solver.cpp:328]     Test net output #1: accuracy = 0.701005
I1202 02:17:47.148864 25774 solver.cpp:332]     Test net output #2: accuracy = 0.766633
I1202 02:17:47.148869 25774 solver.cpp:334]     Test net output #3: accuracy = 0.737477
I1202 02:17:47.845310 25774 solver.cpp:209] Iteration 0, loss = 0.314636
I1202 02:17:47.845340 25774 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:17:50.193922 25774 solver.cpp:209] Iteration 1, loss = 0.373816
I1202 02:17:50.193950 25774 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:17:52.200037 25774 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:17:56.034865 25774 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:18:00.101006 25774 solver.cpp:246] Iteration 2, loss = 0.459917
I1202 02:18:00.101040 25774 solver.cpp:251] Optimization Done.
I1202 02:18:00.101044 25774 caffe.cpp:121] Optimization Done.
I1202 02:18:00.244557 26346 caffe.cpp:99] Use GPU with device ID 0
I1202 02:18:00.425855 26346 caffe.cpp:107] Starting Optimization
I1202 02:18:00.425962 26346 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:18:00.425992 26346 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:18:00.426775 26346 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:18:00.426818 26346 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:18:00.427019 26346 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:18:00.427193 26346 layer_factory.hpp:78] Creating layer data
I1202 02:18:00.427217 26346 net.cpp:67] Creating Layer data
I1202 02:18:00.427232 26346 net.cpp:356] data -> data
I1202 02:18:00.427274 26346 net.cpp:356] data -> label
I1202 02:18:00.427289 26346 net.cpp:96] Setting up data
I1202 02:18:00.427300 26346 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:18:00.442436 26346 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:18:00.452882 26346 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:18:00.455693 26346 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:18:00.455721 26346 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:18:00.455728 26346 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:18:00.455754 26346 net.cpp:67] Creating Layer conv1_1
I1202 02:18:00.455765 26346 net.cpp:394] conv1_1 <- data
I1202 02:18:00.455782 26346 net.cpp:356] conv1_1 -> conv1_1
I1202 02:18:00.455795 26346 net.cpp:96] Setting up conv1_1
I1202 02:18:00.598131 26346 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:18:00.598165 26346 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:18:00.598176 26346 net.cpp:67] Creating Layer relu1_1
I1202 02:18:00.598181 26346 net.cpp:394] relu1_1 <- conv1_1
I1202 02:18:00.598187 26346 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:18:00.598194 26346 net.cpp:96] Setting up relu1_1
I1202 02:18:00.598204 26346 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:18:00.598208 26346 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:18:00.598217 26346 net.cpp:67] Creating Layer conv1_2
I1202 02:18:00.598220 26346 net.cpp:394] conv1_2 <- conv1_1
I1202 02:18:00.598225 26346 net.cpp:356] conv1_2 -> conv1_2
I1202 02:18:00.598232 26346 net.cpp:96] Setting up conv1_2
I1202 02:18:00.599403 26346 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:18:00.599417 26346 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:18:00.599423 26346 net.cpp:67] Creating Layer relu1_2
I1202 02:18:00.599426 26346 net.cpp:394] relu1_2 <- conv1_2
I1202 02:18:00.599431 26346 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:18:00.599436 26346 net.cpp:96] Setting up relu1_2
I1202 02:18:00.599442 26346 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:18:00.599444 26346 layer_factory.hpp:78] Creating layer pool1
I1202 02:18:00.599453 26346 net.cpp:67] Creating Layer pool1
I1202 02:18:00.599457 26346 net.cpp:394] pool1 <- conv1_2
I1202 02:18:00.599477 26346 net.cpp:356] pool1 -> pool1
I1202 02:18:00.599483 26346 net.cpp:96] Setting up pool1
I1202 02:18:00.599501 26346 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:18:00.599508 26346 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:18:00.599514 26346 net.cpp:67] Creating Layer conv2_1
I1202 02:18:00.599517 26346 net.cpp:394] conv2_1 <- pool1
I1202 02:18:00.599529 26346 net.cpp:356] conv2_1 -> conv2_1
I1202 02:18:00.599535 26346 net.cpp:96] Setting up conv2_1
I1202 02:18:00.601447 26346 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:18:00.601462 26346 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:18:00.601467 26346 net.cpp:67] Creating Layer relu2_1
I1202 02:18:00.601470 26346 net.cpp:394] relu2_1 <- conv2_1
I1202 02:18:00.601475 26346 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:18:00.601480 26346 net.cpp:96] Setting up relu2_1
I1202 02:18:00.601485 26346 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:18:00.601488 26346 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:18:00.601495 26346 net.cpp:67] Creating Layer conv2_2
I1202 02:18:00.601498 26346 net.cpp:394] conv2_2 <- conv2_1
I1202 02:18:00.601503 26346 net.cpp:356] conv2_2 -> conv2_2
I1202 02:18:00.601510 26346 net.cpp:96] Setting up conv2_2
I1202 02:18:00.605268 26346 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:18:00.605279 26346 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:18:00.605284 26346 net.cpp:67] Creating Layer relu2_2
I1202 02:18:00.605288 26346 net.cpp:394] relu2_2 <- conv2_2
I1202 02:18:00.605291 26346 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:18:00.605296 26346 net.cpp:96] Setting up relu2_2
I1202 02:18:00.605301 26346 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:18:00.605312 26346 layer_factory.hpp:78] Creating layer pool2
I1202 02:18:00.605317 26346 net.cpp:67] Creating Layer pool2
I1202 02:18:00.605319 26346 net.cpp:394] pool2 <- conv2_2
I1202 02:18:00.605326 26346 net.cpp:356] pool2 -> pool2
I1202 02:18:00.605330 26346 net.cpp:96] Setting up pool2
I1202 02:18:00.605336 26346 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:18:00.605340 26346 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:18:00.605346 26346 net.cpp:67] Creating Layer conv3_1
I1202 02:18:00.605350 26346 net.cpp:394] conv3_1 <- pool2
I1202 02:18:00.605353 26346 net.cpp:356] conv3_1 -> conv3_1
I1202 02:18:00.605360 26346 net.cpp:96] Setting up conv3_1
I1202 02:18:00.612761 26346 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:18:00.612776 26346 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:18:00.612782 26346 net.cpp:67] Creating Layer relu3_1
I1202 02:18:00.612784 26346 net.cpp:394] relu3_1 <- conv3_1
I1202 02:18:00.612789 26346 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:18:00.612794 26346 net.cpp:96] Setting up relu3_1
I1202 02:18:00.612799 26346 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:18:00.612802 26346 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:18:00.612807 26346 net.cpp:67] Creating Layer conv3_2
I1202 02:18:00.612810 26346 net.cpp:394] conv3_2 <- conv3_1
I1202 02:18:00.612817 26346 net.cpp:356] conv3_2 -> conv3_2
I1202 02:18:00.612821 26346 net.cpp:96] Setting up conv3_2
I1202 02:18:00.627862 26346 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:18:00.627885 26346 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:18:00.627897 26346 net.cpp:67] Creating Layer relu3_2
I1202 02:18:00.627902 26346 net.cpp:394] relu3_2 <- conv3_2
I1202 02:18:00.627907 26346 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:18:00.627914 26346 net.cpp:96] Setting up relu3_2
I1202 02:18:00.627920 26346 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:18:00.627923 26346 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:18:00.627931 26346 net.cpp:67] Creating Layer conv3_3
I1202 02:18:00.627934 26346 net.cpp:394] conv3_3 <- conv3_2
I1202 02:18:00.627939 26346 net.cpp:356] conv3_3 -> conv3_3
I1202 02:18:00.627944 26346 net.cpp:96] Setting up conv3_3
I1202 02:18:00.642796 26346 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:18:00.642812 26346 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:18:00.642822 26346 net.cpp:67] Creating Layer relu3_3
I1202 02:18:00.642824 26346 net.cpp:394] relu3_3 <- conv3_3
I1202 02:18:00.642829 26346 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:18:00.642835 26346 net.cpp:96] Setting up relu3_3
I1202 02:18:00.642842 26346 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:18:00.642844 26346 layer_factory.hpp:78] Creating layer pool3
I1202 02:18:00.642851 26346 net.cpp:67] Creating Layer pool3
I1202 02:18:00.642854 26346 net.cpp:394] pool3 <- conv3_3
I1202 02:18:00.642858 26346 net.cpp:356] pool3 -> pool3
I1202 02:18:00.642863 26346 net.cpp:96] Setting up pool3
I1202 02:18:00.642870 26346 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:18:00.642874 26346 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:18:00.642880 26346 net.cpp:67] Creating Layer conv4_1
I1202 02:18:00.642884 26346 net.cpp:394] conv4_1 <- pool3
I1202 02:18:00.642889 26346 net.cpp:356] conv4_1 -> conv4_1
I1202 02:18:00.642894 26346 net.cpp:96] Setting up conv4_1
I1202 02:18:00.671917 26346 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:18:00.671941 26346 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:18:00.671948 26346 net.cpp:67] Creating Layer relu4_1
I1202 02:18:00.671953 26346 net.cpp:394] relu4_1 <- conv4_1
I1202 02:18:00.671960 26346 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:18:00.671967 26346 net.cpp:96] Setting up relu4_1
I1202 02:18:00.671972 26346 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:18:00.671975 26346 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:18:00.671983 26346 net.cpp:67] Creating Layer conv4_2
I1202 02:18:00.671986 26346 net.cpp:394] conv4_2 <- conv4_1
I1202 02:18:00.672003 26346 net.cpp:356] conv4_2 -> conv4_2
I1202 02:18:00.672010 26346 net.cpp:96] Setting up conv4_2
I1202 02:18:00.730166 26346 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:18:00.730195 26346 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:18:00.730204 26346 net.cpp:67] Creating Layer relu4_2
I1202 02:18:00.730209 26346 net.cpp:394] relu4_2 <- conv4_2
I1202 02:18:00.730216 26346 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:18:00.730222 26346 net.cpp:96] Setting up relu4_2
I1202 02:18:00.730228 26346 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:18:00.730232 26346 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:18:00.730240 26346 net.cpp:67] Creating Layer conv4_3
I1202 02:18:00.730243 26346 net.cpp:394] conv4_3 <- conv4_2
I1202 02:18:00.730248 26346 net.cpp:356] conv4_3 -> conv4_3
I1202 02:18:00.730254 26346 net.cpp:96] Setting up conv4_3
I1202 02:18:00.788179 26346 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:18:00.788203 26346 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:18:00.788211 26346 net.cpp:67] Creating Layer relu4_3
I1202 02:18:00.788215 26346 net.cpp:394] relu4_3 <- conv4_3
I1202 02:18:00.788224 26346 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:18:00.788231 26346 net.cpp:96] Setting up relu4_3
I1202 02:18:00.788238 26346 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:18:00.788240 26346 layer_factory.hpp:78] Creating layer pool4
I1202 02:18:00.788245 26346 net.cpp:67] Creating Layer pool4
I1202 02:18:00.788249 26346 net.cpp:394] pool4 <- conv4_3
I1202 02:18:00.788254 26346 net.cpp:356] pool4 -> pool4
I1202 02:18:00.788259 26346 net.cpp:96] Setting up pool4
I1202 02:18:00.788267 26346 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:18:00.788270 26346 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:18:00.788277 26346 net.cpp:67] Creating Layer conv5_1
I1202 02:18:00.788280 26346 net.cpp:394] conv5_1 <- pool4
I1202 02:18:00.788287 26346 net.cpp:356] conv5_1 -> conv5_1
I1202 02:18:00.788296 26346 net.cpp:96] Setting up conv5_1
I1202 02:18:00.846904 26346 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:18:00.846930 26346 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:18:00.846940 26346 net.cpp:67] Creating Layer relu5_1
I1202 02:18:00.846943 26346 net.cpp:394] relu5_1 <- conv5_1
I1202 02:18:00.846956 26346 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:18:00.846964 26346 net.cpp:96] Setting up relu5_1
I1202 02:18:00.846971 26346 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:18:00.846973 26346 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:18:00.846979 26346 net.cpp:67] Creating Layer conv5_2
I1202 02:18:00.846982 26346 net.cpp:394] conv5_2 <- conv5_1
I1202 02:18:00.846989 26346 net.cpp:356] conv5_2 -> conv5_2
I1202 02:18:00.846995 26346 net.cpp:96] Setting up conv5_2
I1202 02:18:00.904822 26346 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:18:00.904850 26346 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:18:00.904858 26346 net.cpp:67] Creating Layer relu5_2
I1202 02:18:00.904862 26346 net.cpp:394] relu5_2 <- conv5_2
I1202 02:18:00.904870 26346 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:18:00.904878 26346 net.cpp:96] Setting up relu5_2
I1202 02:18:00.904885 26346 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:18:00.904887 26346 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:18:00.904893 26346 net.cpp:67] Creating Layer conv5_3
I1202 02:18:00.904896 26346 net.cpp:394] conv5_3 <- conv5_2
I1202 02:18:00.904901 26346 net.cpp:356] conv5_3 -> conv5_3
I1202 02:18:00.904907 26346 net.cpp:96] Setting up conv5_3
I1202 02:18:00.963001 26346 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:18:00.963027 26346 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:18:00.963033 26346 net.cpp:67] Creating Layer relu5_3
I1202 02:18:00.963037 26346 net.cpp:394] relu5_3 <- conv5_3
I1202 02:18:00.963044 26346 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:18:00.963052 26346 net.cpp:96] Setting up relu5_3
I1202 02:18:00.963057 26346 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:18:00.963071 26346 layer_factory.hpp:78] Creating layer pool5
I1202 02:18:00.963078 26346 net.cpp:67] Creating Layer pool5
I1202 02:18:00.963080 26346 net.cpp:394] pool5 <- conv5_3
I1202 02:18:00.963086 26346 net.cpp:356] pool5 -> pool5
I1202 02:18:00.963093 26346 net.cpp:96] Setting up pool5
I1202 02:18:00.963100 26346 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:18:00.963104 26346 layer_factory.hpp:78] Creating layer fc6
I1202 02:18:00.963116 26346 net.cpp:67] Creating Layer fc6
I1202 02:18:00.963121 26346 net.cpp:394] fc6 <- pool5
I1202 02:18:00.963129 26346 net.cpp:356] fc6 -> fc6
I1202 02:18:00.963135 26346 net.cpp:96] Setting up fc6
I1202 02:18:03.470836 26346 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:18:03.470867 26346 layer_factory.hpp:78] Creating layer relu6
I1202 02:18:03.470877 26346 net.cpp:67] Creating Layer relu6
I1202 02:18:03.470882 26346 net.cpp:394] relu6 <- fc6
I1202 02:18:03.470890 26346 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:18:03.470896 26346 net.cpp:96] Setting up relu6
I1202 02:18:03.470911 26346 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:18:03.470913 26346 layer_factory.hpp:78] Creating layer drop6
I1202 02:18:03.470921 26346 net.cpp:67] Creating Layer drop6
I1202 02:18:03.470924 26346 net.cpp:394] drop6 <- fc6
I1202 02:18:03.470928 26346 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:18:03.470933 26346 net.cpp:96] Setting up drop6
I1202 02:18:03.470937 26346 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:18:03.470940 26346 layer_factory.hpp:78] Creating layer fc7
I1202 02:18:03.470947 26346 net.cpp:67] Creating Layer fc7
I1202 02:18:03.470950 26346 net.cpp:394] fc7 <- fc6
I1202 02:18:03.470955 26346 net.cpp:356] fc7 -> fc7
I1202 02:18:03.470962 26346 net.cpp:96] Setting up fc7
I1202 02:18:03.882143 26346 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:18:03.882174 26346 layer_factory.hpp:78] Creating layer relu7
I1202 02:18:03.882182 26346 net.cpp:67] Creating Layer relu7
I1202 02:18:03.882186 26346 net.cpp:394] relu7 <- fc7
I1202 02:18:03.882194 26346 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:18:03.882200 26346 net.cpp:96] Setting up relu7
I1202 02:18:03.882215 26346 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:18:03.882218 26346 layer_factory.hpp:78] Creating layer drop7
I1202 02:18:03.882223 26346 net.cpp:67] Creating Layer drop7
I1202 02:18:03.882226 26346 net.cpp:394] drop7 <- fc7
I1202 02:18:03.882232 26346 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:18:03.882237 26346 net.cpp:96] Setting up drop7
I1202 02:18:03.882241 26346 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:18:03.882244 26346 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:18:03.882249 26346 net.cpp:67] Creating Layer fc8_2
I1202 02:18:03.882252 26346 net.cpp:394] fc8_2 <- fc7
I1202 02:18:03.882258 26346 net.cpp:356] fc8_2 -> fc8_2
I1202 02:18:03.882264 26346 net.cpp:96] Setting up fc8_2
I1202 02:18:03.882486 26346 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:18:03.882495 26346 layer_factory.hpp:78] Creating layer loss
I1202 02:18:03.882503 26346 net.cpp:67] Creating Layer loss
I1202 02:18:03.882505 26346 net.cpp:394] loss <- fc8_2
I1202 02:18:03.882509 26346 net.cpp:394] loss <- label
I1202 02:18:03.882519 26346 net.cpp:356] loss -> (automatic)
I1202 02:18:03.882524 26346 net.cpp:96] Setting up loss
I1202 02:18:03.882534 26346 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:18:03.882537 26346 net.cpp:109]     with loss weight 1
I1202 02:18:03.882572 26346 net.cpp:170] loss needs backward computation.
I1202 02:18:03.882576 26346 net.cpp:170] fc8_2 needs backward computation.
I1202 02:18:03.882580 26346 net.cpp:170] drop7 needs backward computation.
I1202 02:18:03.882583 26346 net.cpp:170] relu7 needs backward computation.
I1202 02:18:03.882586 26346 net.cpp:170] fc7 needs backward computation.
I1202 02:18:03.882589 26346 net.cpp:170] drop6 needs backward computation.
I1202 02:18:03.882592 26346 net.cpp:170] relu6 needs backward computation.
I1202 02:18:03.882594 26346 net.cpp:170] fc6 needs backward computation.
I1202 02:18:03.882612 26346 net.cpp:170] pool5 needs backward computation.
I1202 02:18:03.882616 26346 net.cpp:170] relu5_3 needs backward computation.
I1202 02:18:03.882618 26346 net.cpp:170] conv5_3 needs backward computation.
I1202 02:18:03.882622 26346 net.cpp:170] relu5_2 needs backward computation.
I1202 02:18:03.882624 26346 net.cpp:170] conv5_2 needs backward computation.
I1202 02:18:03.882627 26346 net.cpp:170] relu5_1 needs backward computation.
I1202 02:18:03.882630 26346 net.cpp:170] conv5_1 needs backward computation.
I1202 02:18:03.882633 26346 net.cpp:170] pool4 needs backward computation.
I1202 02:18:03.882637 26346 net.cpp:170] relu4_3 needs backward computation.
I1202 02:18:03.882639 26346 net.cpp:170] conv4_3 needs backward computation.
I1202 02:18:03.882642 26346 net.cpp:170] relu4_2 needs backward computation.
I1202 02:18:03.882644 26346 net.cpp:170] conv4_2 needs backward computation.
I1202 02:18:03.882647 26346 net.cpp:170] relu4_1 needs backward computation.
I1202 02:18:03.882650 26346 net.cpp:170] conv4_1 needs backward computation.
I1202 02:18:03.882653 26346 net.cpp:170] pool3 needs backward computation.
I1202 02:18:03.882657 26346 net.cpp:170] relu3_3 needs backward computation.
I1202 02:18:03.882659 26346 net.cpp:170] conv3_3 needs backward computation.
I1202 02:18:03.882663 26346 net.cpp:170] relu3_2 needs backward computation.
I1202 02:18:03.882665 26346 net.cpp:170] conv3_2 needs backward computation.
I1202 02:18:03.882668 26346 net.cpp:170] relu3_1 needs backward computation.
I1202 02:18:03.882670 26346 net.cpp:170] conv3_1 needs backward computation.
I1202 02:18:03.882673 26346 net.cpp:170] pool2 needs backward computation.
I1202 02:18:03.882676 26346 net.cpp:170] relu2_2 needs backward computation.
I1202 02:18:03.882679 26346 net.cpp:170] conv2_2 needs backward computation.
I1202 02:18:03.882683 26346 net.cpp:170] relu2_1 needs backward computation.
I1202 02:18:03.882685 26346 net.cpp:170] conv2_1 needs backward computation.
I1202 02:18:03.882688 26346 net.cpp:170] pool1 needs backward computation.
I1202 02:18:03.882690 26346 net.cpp:170] relu1_2 needs backward computation.
I1202 02:18:03.882694 26346 net.cpp:170] conv1_2 needs backward computation.
I1202 02:18:03.882696 26346 net.cpp:170] relu1_1 needs backward computation.
I1202 02:18:03.882699 26346 net.cpp:170] conv1_1 needs backward computation.
I1202 02:18:03.882702 26346 net.cpp:172] data does not need backward computation.
I1202 02:18:03.882720 26346 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:18:03.882727 26346 net.cpp:219] Network initialization done.
I1202 02:18:03.882731 26346 net.cpp:220] Memory required for data: 3686465924
I1202 02:18:03.883591 26346 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:18:03.883633 26346 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:18:03.883841 26346 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:18:03.883991 26346 layer_factory.hpp:78] Creating layer data
I1202 02:18:03.884001 26346 net.cpp:67] Creating Layer data
I1202 02:18:03.884006 26346 net.cpp:356] data -> data
I1202 02:18:03.884012 26346 net.cpp:356] data -> label
I1202 02:18:03.884018 26346 net.cpp:96] Setting up data
I1202 02:18:03.884022 26346 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:18:03.885617 26346 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:18:03.892626 26346 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:18:03.893532 26346 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:18:03.893542 26346 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:18:03.893545 26346 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:18:03.893558 26346 net.cpp:67] Creating Layer label_data_1_split
I1202 02:18:03.893563 26346 net.cpp:394] label_data_1_split <- label
I1202 02:18:03.893568 26346 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:18:03.893578 26346 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:18:03.893591 26346 net.cpp:96] Setting up label_data_1_split
I1202 02:18:03.893595 26346 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:18:03.893599 26346 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:18:03.893602 26346 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:18:03.893609 26346 net.cpp:67] Creating Layer conv1_1
I1202 02:18:03.893612 26346 net.cpp:394] conv1_1 <- data
I1202 02:18:03.893616 26346 net.cpp:356] conv1_1 -> conv1_1
I1202 02:18:03.893623 26346 net.cpp:96] Setting up conv1_1
I1202 02:18:03.893784 26346 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:18:03.893797 26346 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:18:03.893802 26346 net.cpp:67] Creating Layer relu1_1
I1202 02:18:03.893806 26346 net.cpp:394] relu1_1 <- conv1_1
I1202 02:18:03.893810 26346 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:18:03.893823 26346 net.cpp:96] Setting up relu1_1
I1202 02:18:03.893828 26346 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:18:03.893832 26346 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:18:03.893837 26346 net.cpp:67] Creating Layer conv1_2
I1202 02:18:03.893841 26346 net.cpp:394] conv1_2 <- conv1_1
I1202 02:18:03.893846 26346 net.cpp:356] conv1_2 -> conv1_2
I1202 02:18:03.893851 26346 net.cpp:96] Setting up conv1_2
I1202 02:18:03.894850 26346 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:18:03.894863 26346 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:18:03.894868 26346 net.cpp:67] Creating Layer relu1_2
I1202 02:18:03.894871 26346 net.cpp:394] relu1_2 <- conv1_2
I1202 02:18:03.894876 26346 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:18:03.894881 26346 net.cpp:96] Setting up relu1_2
I1202 02:18:03.894886 26346 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:18:03.894889 26346 layer_factory.hpp:78] Creating layer pool1
I1202 02:18:03.894894 26346 net.cpp:67] Creating Layer pool1
I1202 02:18:03.894897 26346 net.cpp:394] pool1 <- conv1_2
I1202 02:18:03.894901 26346 net.cpp:356] pool1 -> pool1
I1202 02:18:03.894906 26346 net.cpp:96] Setting up pool1
I1202 02:18:03.894913 26346 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:18:03.894917 26346 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:18:03.894922 26346 net.cpp:67] Creating Layer conv2_1
I1202 02:18:03.894925 26346 net.cpp:394] conv2_1 <- pool1
I1202 02:18:03.894929 26346 net.cpp:356] conv2_1 -> conv2_1
I1202 02:18:03.894934 26346 net.cpp:96] Setting up conv2_1
I1202 02:18:03.896947 26346 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:18:03.896962 26346 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:18:03.896968 26346 net.cpp:67] Creating Layer relu2_1
I1202 02:18:03.896971 26346 net.cpp:394] relu2_1 <- conv2_1
I1202 02:18:03.896976 26346 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:18:03.896981 26346 net.cpp:96] Setting up relu2_1
I1202 02:18:03.896986 26346 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:18:03.896991 26346 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:18:03.896996 26346 net.cpp:67] Creating Layer conv2_2
I1202 02:18:03.896997 26346 net.cpp:394] conv2_2 <- conv2_1
I1202 02:18:03.897002 26346 net.cpp:356] conv2_2 -> conv2_2
I1202 02:18:03.897008 26346 net.cpp:96] Setting up conv2_2
I1202 02:18:03.900667 26346 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:18:03.900678 26346 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:18:03.900683 26346 net.cpp:67] Creating Layer relu2_2
I1202 02:18:03.900686 26346 net.cpp:394] relu2_2 <- conv2_2
I1202 02:18:03.900691 26346 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:18:03.900696 26346 net.cpp:96] Setting up relu2_2
I1202 02:18:03.900701 26346 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:18:03.900706 26346 layer_factory.hpp:78] Creating layer pool2
I1202 02:18:03.900709 26346 net.cpp:67] Creating Layer pool2
I1202 02:18:03.900712 26346 net.cpp:394] pool2 <- conv2_2
I1202 02:18:03.900717 26346 net.cpp:356] pool2 -> pool2
I1202 02:18:03.900722 26346 net.cpp:96] Setting up pool2
I1202 02:18:03.900727 26346 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:18:03.900730 26346 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:18:03.900735 26346 net.cpp:67] Creating Layer conv3_1
I1202 02:18:03.900738 26346 net.cpp:394] conv3_1 <- pool2
I1202 02:18:03.900743 26346 net.cpp:356] conv3_1 -> conv3_1
I1202 02:18:03.900748 26346 net.cpp:96] Setting up conv3_1
I1202 02:18:03.908102 26346 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:18:03.908118 26346 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:18:03.908123 26346 net.cpp:67] Creating Layer relu3_1
I1202 02:18:03.908126 26346 net.cpp:394] relu3_1 <- conv3_1
I1202 02:18:03.908130 26346 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:18:03.908136 26346 net.cpp:96] Setting up relu3_1
I1202 02:18:03.908141 26346 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:18:03.908144 26346 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:18:03.908156 26346 net.cpp:67] Creating Layer conv3_2
I1202 02:18:03.908159 26346 net.cpp:394] conv3_2 <- conv3_1
I1202 02:18:03.908164 26346 net.cpp:356] conv3_2 -> conv3_2
I1202 02:18:03.908169 26346 net.cpp:96] Setting up conv3_2
I1202 02:18:03.922787 26346 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:18:03.922809 26346 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:18:03.922817 26346 net.cpp:67] Creating Layer relu3_2
I1202 02:18:03.922822 26346 net.cpp:394] relu3_2 <- conv3_2
I1202 02:18:03.922828 26346 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:18:03.922835 26346 net.cpp:96] Setting up relu3_2
I1202 02:18:03.922840 26346 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:18:03.922844 26346 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:18:03.922853 26346 net.cpp:67] Creating Layer conv3_3
I1202 02:18:03.922857 26346 net.cpp:394] conv3_3 <- conv3_2
I1202 02:18:03.922862 26346 net.cpp:356] conv3_3 -> conv3_3
I1202 02:18:03.922868 26346 net.cpp:96] Setting up conv3_3
I1202 02:18:03.937753 26346 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:18:03.937772 26346 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:18:03.937782 26346 net.cpp:67] Creating Layer relu3_3
I1202 02:18:03.937785 26346 net.cpp:394] relu3_3 <- conv3_3
I1202 02:18:03.937793 26346 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:18:03.937798 26346 net.cpp:96] Setting up relu3_3
I1202 02:18:03.937803 26346 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:18:03.937806 26346 layer_factory.hpp:78] Creating layer pool3
I1202 02:18:03.937813 26346 net.cpp:67] Creating Layer pool3
I1202 02:18:03.937816 26346 net.cpp:394] pool3 <- conv3_3
I1202 02:18:03.937821 26346 net.cpp:356] pool3 -> pool3
I1202 02:18:03.937826 26346 net.cpp:96] Setting up pool3
I1202 02:18:03.937834 26346 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:18:03.937836 26346 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:18:03.937841 26346 net.cpp:67] Creating Layer conv4_1
I1202 02:18:03.937844 26346 net.cpp:394] conv4_1 <- pool3
I1202 02:18:03.937850 26346 net.cpp:356] conv4_1 -> conv4_1
I1202 02:18:03.937856 26346 net.cpp:96] Setting up conv4_1
I1202 02:18:03.967226 26346 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:18:03.967249 26346 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:18:03.967259 26346 net.cpp:67] Creating Layer relu4_1
I1202 02:18:03.967264 26346 net.cpp:394] relu4_1 <- conv4_1
I1202 02:18:03.967272 26346 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:18:03.967278 26346 net.cpp:96] Setting up relu4_1
I1202 02:18:03.967284 26346 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:18:03.967288 26346 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:18:03.967295 26346 net.cpp:67] Creating Layer conv4_2
I1202 02:18:03.967298 26346 net.cpp:394] conv4_2 <- conv4_1
I1202 02:18:03.967303 26346 net.cpp:356] conv4_2 -> conv4_2
I1202 02:18:03.967309 26346 net.cpp:96] Setting up conv4_2
I1202 02:18:04.025353 26346 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:18:04.025382 26346 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:18:04.025393 26346 net.cpp:67] Creating Layer relu4_2
I1202 02:18:04.025398 26346 net.cpp:394] relu4_2 <- conv4_2
I1202 02:18:04.025403 26346 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:18:04.025409 26346 net.cpp:96] Setting up relu4_2
I1202 02:18:04.025415 26346 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:18:04.025418 26346 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:18:04.025424 26346 net.cpp:67] Creating Layer conv4_3
I1202 02:18:04.025427 26346 net.cpp:394] conv4_3 <- conv4_2
I1202 02:18:04.025434 26346 net.cpp:356] conv4_3 -> conv4_3
I1202 02:18:04.025441 26346 net.cpp:96] Setting up conv4_3
I1202 02:18:04.083453 26346 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:18:04.083484 26346 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:18:04.083494 26346 net.cpp:67] Creating Layer relu4_3
I1202 02:18:04.083499 26346 net.cpp:394] relu4_3 <- conv4_3
I1202 02:18:04.083506 26346 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:18:04.083524 26346 net.cpp:96] Setting up relu4_3
I1202 02:18:04.083530 26346 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:18:04.083534 26346 layer_factory.hpp:78] Creating layer pool4
I1202 02:18:04.083539 26346 net.cpp:67] Creating Layer pool4
I1202 02:18:04.083542 26346 net.cpp:394] pool4 <- conv4_3
I1202 02:18:04.083549 26346 net.cpp:356] pool4 -> pool4
I1202 02:18:04.083555 26346 net.cpp:96] Setting up pool4
I1202 02:18:04.083564 26346 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:18:04.083566 26346 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:18:04.083573 26346 net.cpp:67] Creating Layer conv5_1
I1202 02:18:04.083576 26346 net.cpp:394] conv5_1 <- pool4
I1202 02:18:04.083580 26346 net.cpp:356] conv5_1 -> conv5_1
I1202 02:18:04.083586 26346 net.cpp:96] Setting up conv5_1
I1202 02:18:04.141625 26346 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:18:04.141652 26346 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:18:04.141660 26346 net.cpp:67] Creating Layer relu5_1
I1202 02:18:04.141664 26346 net.cpp:394] relu5_1 <- conv5_1
I1202 02:18:04.141671 26346 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:18:04.141677 26346 net.cpp:96] Setting up relu5_1
I1202 02:18:04.141683 26346 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:18:04.141686 26346 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:18:04.141692 26346 net.cpp:67] Creating Layer conv5_2
I1202 02:18:04.141695 26346 net.cpp:394] conv5_2 <- conv5_1
I1202 02:18:04.141701 26346 net.cpp:356] conv5_2 -> conv5_2
I1202 02:18:04.141707 26346 net.cpp:96] Setting up conv5_2
I1202 02:18:04.199515 26346 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:18:04.199542 26346 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:18:04.199549 26346 net.cpp:67] Creating Layer relu5_2
I1202 02:18:04.199553 26346 net.cpp:394] relu5_2 <- conv5_2
I1202 02:18:04.199563 26346 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:18:04.199569 26346 net.cpp:96] Setting up relu5_2
I1202 02:18:04.199575 26346 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:18:04.199579 26346 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:18:04.199584 26346 net.cpp:67] Creating Layer conv5_3
I1202 02:18:04.199587 26346 net.cpp:394] conv5_3 <- conv5_2
I1202 02:18:04.199594 26346 net.cpp:356] conv5_3 -> conv5_3
I1202 02:18:04.199599 26346 net.cpp:96] Setting up conv5_3
I1202 02:18:04.257875 26346 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:18:04.257902 26346 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:18:04.257910 26346 net.cpp:67] Creating Layer relu5_3
I1202 02:18:04.257913 26346 net.cpp:394] relu5_3 <- conv5_3
I1202 02:18:04.257923 26346 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:18:04.257930 26346 net.cpp:96] Setting up relu5_3
I1202 02:18:04.257936 26346 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:18:04.257940 26346 layer_factory.hpp:78] Creating layer pool5
I1202 02:18:04.257951 26346 net.cpp:67] Creating Layer pool5
I1202 02:18:04.257953 26346 net.cpp:394] pool5 <- conv5_3
I1202 02:18:04.257958 26346 net.cpp:356] pool5 -> pool5
I1202 02:18:04.257963 26346 net.cpp:96] Setting up pool5
I1202 02:18:04.257971 26346 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:18:04.257974 26346 layer_factory.hpp:78] Creating layer fc6
I1202 02:18:04.257979 26346 net.cpp:67] Creating Layer fc6
I1202 02:18:04.257982 26346 net.cpp:394] fc6 <- pool5
I1202 02:18:04.257989 26346 net.cpp:356] fc6 -> fc6
I1202 02:18:04.257995 26346 net.cpp:96] Setting up fc6
I1202 02:18:06.765360 26346 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:18:06.765390 26346 layer_factory.hpp:78] Creating layer relu6
I1202 02:18:06.765400 26346 net.cpp:67] Creating Layer relu6
I1202 02:18:06.765404 26346 net.cpp:394] relu6 <- fc6
I1202 02:18:06.765413 26346 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:18:06.765419 26346 net.cpp:96] Setting up relu6
I1202 02:18:06.765434 26346 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:18:06.765437 26346 layer_factory.hpp:78] Creating layer drop6
I1202 02:18:06.765454 26346 net.cpp:67] Creating Layer drop6
I1202 02:18:06.765457 26346 net.cpp:394] drop6 <- fc6
I1202 02:18:06.765461 26346 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:18:06.765466 26346 net.cpp:96] Setting up drop6
I1202 02:18:06.765470 26346 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:18:06.765472 26346 layer_factory.hpp:78] Creating layer fc7
I1202 02:18:06.765482 26346 net.cpp:67] Creating Layer fc7
I1202 02:18:06.765486 26346 net.cpp:394] fc7 <- fc6
I1202 02:18:06.765491 26346 net.cpp:356] fc7 -> fc7
I1202 02:18:06.765496 26346 net.cpp:96] Setting up fc7
I1202 02:18:07.175694 26346 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:18:07.175725 26346 layer_factory.hpp:78] Creating layer relu7
I1202 02:18:07.175734 26346 net.cpp:67] Creating Layer relu7
I1202 02:18:07.175739 26346 net.cpp:394] relu7 <- fc7
I1202 02:18:07.175745 26346 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:18:07.175753 26346 net.cpp:96] Setting up relu7
I1202 02:18:07.175768 26346 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:18:07.175771 26346 layer_factory.hpp:78] Creating layer drop7
I1202 02:18:07.175777 26346 net.cpp:67] Creating Layer drop7
I1202 02:18:07.175781 26346 net.cpp:394] drop7 <- fc7
I1202 02:18:07.175786 26346 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:18:07.175791 26346 net.cpp:96] Setting up drop7
I1202 02:18:07.175796 26346 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:18:07.175798 26346 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:18:07.175803 26346 net.cpp:67] Creating Layer fc8_2
I1202 02:18:07.175806 26346 net.cpp:394] fc8_2 <- fc7
I1202 02:18:07.175812 26346 net.cpp:356] fc8_2 -> fc8_2
I1202 02:18:07.175818 26346 net.cpp:96] Setting up fc8_2
I1202 02:18:07.176038 26346 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:18:07.176048 26346 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:18:07.176053 26346 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:18:07.176055 26346 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:18:07.176061 26346 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:18:07.176067 26346 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:18:07.176072 26346 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:18:07.176076 26346 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:18:07.176079 26346 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:18:07.176082 26346 layer_factory.hpp:78] Creating layer loss
I1202 02:18:07.176089 26346 net.cpp:67] Creating Layer loss
I1202 02:18:07.176091 26346 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:18:07.176095 26346 net.cpp:394] loss <- label_data_1_split_0
I1202 02:18:07.176100 26346 net.cpp:356] loss -> (automatic)
I1202 02:18:07.176105 26346 net.cpp:96] Setting up loss
I1202 02:18:07.176115 26346 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:18:07.176118 26346 net.cpp:109]     with loss weight 1
I1202 02:18:07.176131 26346 layer_factory.hpp:78] Creating layer accuracy
I1202 02:18:07.176136 26346 net.cpp:67] Creating Layer accuracy
I1202 02:18:07.176138 26346 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:18:07.176146 26346 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:18:07.176151 26346 net.cpp:356] accuracy -> accuracy
I1202 02:18:07.176156 26346 net.cpp:96] Setting up accuracy
I1202 02:18:07.176169 26346 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:18:07.176172 26346 net.cpp:172] accuracy does not need backward computation.
I1202 02:18:07.176175 26346 net.cpp:170] loss needs backward computation.
I1202 02:18:07.176178 26346 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:18:07.176182 26346 net.cpp:170] fc8_2 needs backward computation.
I1202 02:18:07.176183 26346 net.cpp:170] drop7 needs backward computation.
I1202 02:18:07.176187 26346 net.cpp:170] relu7 needs backward computation.
I1202 02:18:07.176189 26346 net.cpp:170] fc7 needs backward computation.
I1202 02:18:07.176192 26346 net.cpp:170] drop6 needs backward computation.
I1202 02:18:07.176194 26346 net.cpp:170] relu6 needs backward computation.
I1202 02:18:07.176205 26346 net.cpp:170] fc6 needs backward computation.
I1202 02:18:07.176208 26346 net.cpp:170] pool5 needs backward computation.
I1202 02:18:07.176213 26346 net.cpp:170] relu5_3 needs backward computation.
I1202 02:18:07.176215 26346 net.cpp:170] conv5_3 needs backward computation.
I1202 02:18:07.176218 26346 net.cpp:170] relu5_2 needs backward computation.
I1202 02:18:07.176220 26346 net.cpp:170] conv5_2 needs backward computation.
I1202 02:18:07.176223 26346 net.cpp:170] relu5_1 needs backward computation.
I1202 02:18:07.176226 26346 net.cpp:170] conv5_1 needs backward computation.
I1202 02:18:07.176229 26346 net.cpp:170] pool4 needs backward computation.
I1202 02:18:07.176233 26346 net.cpp:170] relu4_3 needs backward computation.
I1202 02:18:07.176235 26346 net.cpp:170] conv4_3 needs backward computation.
I1202 02:18:07.176239 26346 net.cpp:170] relu4_2 needs backward computation.
I1202 02:18:07.176241 26346 net.cpp:170] conv4_2 needs backward computation.
I1202 02:18:07.176244 26346 net.cpp:170] relu4_1 needs backward computation.
I1202 02:18:07.176246 26346 net.cpp:170] conv4_1 needs backward computation.
I1202 02:18:07.176249 26346 net.cpp:170] pool3 needs backward computation.
I1202 02:18:07.176252 26346 net.cpp:170] relu3_3 needs backward computation.
I1202 02:18:07.176255 26346 net.cpp:170] conv3_3 needs backward computation.
I1202 02:18:07.176257 26346 net.cpp:170] relu3_2 needs backward computation.
I1202 02:18:07.176260 26346 net.cpp:170] conv3_2 needs backward computation.
I1202 02:18:07.176264 26346 net.cpp:170] relu3_1 needs backward computation.
I1202 02:18:07.176266 26346 net.cpp:170] conv3_1 needs backward computation.
I1202 02:18:07.176269 26346 net.cpp:170] pool2 needs backward computation.
I1202 02:18:07.176271 26346 net.cpp:170] relu2_2 needs backward computation.
I1202 02:18:07.176275 26346 net.cpp:170] conv2_2 needs backward computation.
I1202 02:18:07.176277 26346 net.cpp:170] relu2_1 needs backward computation.
I1202 02:18:07.176281 26346 net.cpp:170] conv2_1 needs backward computation.
I1202 02:18:07.176285 26346 net.cpp:170] pool1 needs backward computation.
I1202 02:18:07.176287 26346 net.cpp:170] relu1_2 needs backward computation.
I1202 02:18:07.176290 26346 net.cpp:170] conv1_2 needs backward computation.
I1202 02:18:07.176293 26346 net.cpp:170] relu1_1 needs backward computation.
I1202 02:18:07.176296 26346 net.cpp:170] conv1_1 needs backward computation.
I1202 02:18:07.176300 26346 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:18:07.176302 26346 net.cpp:172] data does not need backward computation.
I1202 02:18:07.176304 26346 net.cpp:208] This network produces output accuracy
I1202 02:18:07.176324 26346 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:18:07.176331 26346 net.cpp:219] Network initialization done.
I1202 02:18:07.176334 26346 net.cpp:220] Memory required for data: 921616692
I1202 02:18:07.176480 26346 solver.cpp:41] Solver scaffolding done.
I1202 02:18:07.176487 26346 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_12000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:18:10.517386 26346 solver.cpp:160] Solving small
I1202 02:18:10.517415 26346 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:18:10.517462 26346 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:19:35.172008 26346 solver.cpp:305] Test loss: 0.506203
I1202 02:19:35.172070 26346 solver.cpp:318] mean_score = test_score[0] { = 2713} / test_score[1] { = 3570 }
I1202 02:19:35.172080 26346 solver.cpp:319]            = 0.759944
I1202 02:19:35.172090 26346 solver.cpp:328]     Test net output #0: accuracy = 0.759944
I1202 02:19:35.172094 26346 solver.cpp:318] mean_score = test_score[2] { = 276} / test_score[3] { = 398 }
I1202 02:19:35.172099 26346 solver.cpp:319]            = 0.693467
I1202 02:19:35.172103 26346 solver.cpp:328]     Test net output #1: accuracy = 0.693467
I1202 02:19:35.172113 26346 solver.cpp:332]     Test net output #2: accuracy = 0.753276
I1202 02:19:35.172118 26346 solver.cpp:334]     Test net output #3: accuracy = 0.726706
I1202 02:19:35.866358 26346 solver.cpp:209] Iteration 0, loss = 0.411682
I1202 02:19:35.866390 26346 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:19:38.209494 26346 solver.cpp:209] Iteration 1, loss = 0.399367
I1202 02:19:38.209524 26346 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:19:40.211194 26346 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:19:44.049949 26346 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:19:48.077879 26346 solver.cpp:246] Iteration 2, loss = 0.321354
I1202 02:19:48.077913 26346 solver.cpp:251] Optimization Done.
I1202 02:19:48.077916 26346 caffe.cpp:121] Optimization Done.
I1202 02:19:48.215745 26907 caffe.cpp:99] Use GPU with device ID 0
I1202 02:19:48.400393 26907 caffe.cpp:107] Starting Optimization
I1202 02:19:48.400488 26907 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:19:48.400511 26907 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:19:48.401321 26907 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:19:48.401350 26907 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:19:48.401538 26907 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:19:48.401664 26907 layer_factory.hpp:78] Creating layer data
I1202 02:19:48.401684 26907 net.cpp:67] Creating Layer data
I1202 02:19:48.401691 26907 net.cpp:356] data -> data
I1202 02:19:48.401710 26907 net.cpp:356] data -> label
I1202 02:19:48.401718 26907 net.cpp:96] Setting up data
I1202 02:19:48.401725 26907 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:19:48.415974 26907 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:19:48.426651 26907 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:19:48.429292 26907 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:19:48.429316 26907 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:19:48.429322 26907 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:19:48.429338 26907 net.cpp:67] Creating Layer conv1_1
I1202 02:19:48.429342 26907 net.cpp:394] conv1_1 <- data
I1202 02:19:48.429355 26907 net.cpp:356] conv1_1 -> conv1_1
I1202 02:19:48.429365 26907 net.cpp:96] Setting up conv1_1
I1202 02:19:48.570186 26907 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:19:48.570219 26907 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:19:48.570230 26907 net.cpp:67] Creating Layer relu1_1
I1202 02:19:48.570233 26907 net.cpp:394] relu1_1 <- conv1_1
I1202 02:19:48.570240 26907 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:19:48.570247 26907 net.cpp:96] Setting up relu1_1
I1202 02:19:48.570257 26907 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:19:48.570261 26907 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:19:48.570267 26907 net.cpp:67] Creating Layer conv1_2
I1202 02:19:48.570271 26907 net.cpp:394] conv1_2 <- conv1_1
I1202 02:19:48.570276 26907 net.cpp:356] conv1_2 -> conv1_2
I1202 02:19:48.570283 26907 net.cpp:96] Setting up conv1_2
I1202 02:19:48.571359 26907 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:19:48.571374 26907 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:19:48.571380 26907 net.cpp:67] Creating Layer relu1_2
I1202 02:19:48.571383 26907 net.cpp:394] relu1_2 <- conv1_2
I1202 02:19:48.571388 26907 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:19:48.571393 26907 net.cpp:96] Setting up relu1_2
I1202 02:19:48.571398 26907 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:19:48.571401 26907 layer_factory.hpp:78] Creating layer pool1
I1202 02:19:48.571408 26907 net.cpp:67] Creating Layer pool1
I1202 02:19:48.571411 26907 net.cpp:394] pool1 <- conv1_2
I1202 02:19:48.571418 26907 net.cpp:356] pool1 -> pool1
I1202 02:19:48.571424 26907 net.cpp:96] Setting up pool1
I1202 02:19:48.571440 26907 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:19:48.571444 26907 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:19:48.571450 26907 net.cpp:67] Creating Layer conv2_1
I1202 02:19:48.571454 26907 net.cpp:394] conv2_1 <- pool1
I1202 02:19:48.571463 26907 net.cpp:356] conv2_1 -> conv2_1
I1202 02:19:48.571470 26907 net.cpp:96] Setting up conv2_1
I1202 02:19:48.573397 26907 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:19:48.573411 26907 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:19:48.573416 26907 net.cpp:67] Creating Layer relu2_1
I1202 02:19:48.573420 26907 net.cpp:394] relu2_1 <- conv2_1
I1202 02:19:48.573425 26907 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:19:48.573428 26907 net.cpp:96] Setting up relu2_1
I1202 02:19:48.573433 26907 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:19:48.573437 26907 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:19:48.573442 26907 net.cpp:67] Creating Layer conv2_2
I1202 02:19:48.573446 26907 net.cpp:394] conv2_2 <- conv2_1
I1202 02:19:48.573451 26907 net.cpp:356] conv2_2 -> conv2_2
I1202 02:19:48.573457 26907 net.cpp:96] Setting up conv2_2
I1202 02:19:48.577241 26907 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:19:48.577256 26907 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:19:48.577262 26907 net.cpp:67] Creating Layer relu2_2
I1202 02:19:48.577265 26907 net.cpp:394] relu2_2 <- conv2_2
I1202 02:19:48.577270 26907 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:19:48.577275 26907 net.cpp:96] Setting up relu2_2
I1202 02:19:48.577280 26907 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:19:48.577291 26907 layer_factory.hpp:78] Creating layer pool2
I1202 02:19:48.577296 26907 net.cpp:67] Creating Layer pool2
I1202 02:19:48.577299 26907 net.cpp:394] pool2 <- conv2_2
I1202 02:19:48.577306 26907 net.cpp:356] pool2 -> pool2
I1202 02:19:48.577311 26907 net.cpp:96] Setting up pool2
I1202 02:19:48.577316 26907 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:19:48.577321 26907 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:19:48.577327 26907 net.cpp:67] Creating Layer conv3_1
I1202 02:19:48.577329 26907 net.cpp:394] conv3_1 <- pool2
I1202 02:19:48.577334 26907 net.cpp:356] conv3_1 -> conv3_1
I1202 02:19:48.577339 26907 net.cpp:96] Setting up conv3_1
I1202 02:19:48.584744 26907 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:19:48.584758 26907 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:19:48.584765 26907 net.cpp:67] Creating Layer relu3_1
I1202 02:19:48.584769 26907 net.cpp:394] relu3_1 <- conv3_1
I1202 02:19:48.584774 26907 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:19:48.584777 26907 net.cpp:96] Setting up relu3_1
I1202 02:19:48.584782 26907 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:19:48.584785 26907 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:19:48.584790 26907 net.cpp:67] Creating Layer conv3_2
I1202 02:19:48.584794 26907 net.cpp:394] conv3_2 <- conv3_1
I1202 02:19:48.584800 26907 net.cpp:356] conv3_2 -> conv3_2
I1202 02:19:48.584805 26907 net.cpp:96] Setting up conv3_2
I1202 02:19:48.599516 26907 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:19:48.599547 26907 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:19:48.599558 26907 net.cpp:67] Creating Layer relu3_2
I1202 02:19:48.599563 26907 net.cpp:394] relu3_2 <- conv3_2
I1202 02:19:48.599570 26907 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:19:48.599577 26907 net.cpp:96] Setting up relu3_2
I1202 02:19:48.599583 26907 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:19:48.599586 26907 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:19:48.599592 26907 net.cpp:67] Creating Layer conv3_3
I1202 02:19:48.599596 26907 net.cpp:394] conv3_3 <- conv3_2
I1202 02:19:48.599601 26907 net.cpp:356] conv3_3 -> conv3_3
I1202 02:19:48.599607 26907 net.cpp:96] Setting up conv3_3
I1202 02:19:48.614364 26907 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:19:48.614382 26907 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:19:48.614392 26907 net.cpp:67] Creating Layer relu3_3
I1202 02:19:48.614395 26907 net.cpp:394] relu3_3 <- conv3_3
I1202 02:19:48.614400 26907 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:19:48.614406 26907 net.cpp:96] Setting up relu3_3
I1202 02:19:48.614411 26907 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:19:48.614414 26907 layer_factory.hpp:78] Creating layer pool3
I1202 02:19:48.614419 26907 net.cpp:67] Creating Layer pool3
I1202 02:19:48.614424 26907 net.cpp:394] pool3 <- conv3_3
I1202 02:19:48.614428 26907 net.cpp:356] pool3 -> pool3
I1202 02:19:48.614434 26907 net.cpp:96] Setting up pool3
I1202 02:19:48.614441 26907 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:19:48.614445 26907 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:19:48.614450 26907 net.cpp:67] Creating Layer conv4_1
I1202 02:19:48.614454 26907 net.cpp:394] conv4_1 <- pool3
I1202 02:19:48.614459 26907 net.cpp:356] conv4_1 -> conv4_1
I1202 02:19:48.614464 26907 net.cpp:96] Setting up conv4_1
I1202 02:19:48.643650 26907 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:19:48.643673 26907 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:19:48.643681 26907 net.cpp:67] Creating Layer relu4_1
I1202 02:19:48.643685 26907 net.cpp:394] relu4_1 <- conv4_1
I1202 02:19:48.643692 26907 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:19:48.643698 26907 net.cpp:96] Setting up relu4_1
I1202 02:19:48.643704 26907 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:19:48.643707 26907 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:19:48.643714 26907 net.cpp:67] Creating Layer conv4_2
I1202 02:19:48.643718 26907 net.cpp:394] conv4_2 <- conv4_1
I1202 02:19:48.643730 26907 net.cpp:356] conv4_2 -> conv4_2
I1202 02:19:48.643736 26907 net.cpp:96] Setting up conv4_2
I1202 02:19:48.701781 26907 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:19:48.701809 26907 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:19:48.701819 26907 net.cpp:67] Creating Layer relu4_2
I1202 02:19:48.701824 26907 net.cpp:394] relu4_2 <- conv4_2
I1202 02:19:48.701830 26907 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:19:48.701838 26907 net.cpp:96] Setting up relu4_2
I1202 02:19:48.701843 26907 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:19:48.701846 26907 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:19:48.701853 26907 net.cpp:67] Creating Layer conv4_3
I1202 02:19:48.701856 26907 net.cpp:394] conv4_3 <- conv4_2
I1202 02:19:48.701861 26907 net.cpp:356] conv4_3 -> conv4_3
I1202 02:19:48.701867 26907 net.cpp:96] Setting up conv4_3
I1202 02:19:48.759699 26907 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:19:48.759722 26907 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:19:48.759732 26907 net.cpp:67] Creating Layer relu4_3
I1202 02:19:48.759735 26907 net.cpp:394] relu4_3 <- conv4_3
I1202 02:19:48.759743 26907 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:19:48.759750 26907 net.cpp:96] Setting up relu4_3
I1202 02:19:48.759757 26907 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:19:48.759759 26907 layer_factory.hpp:78] Creating layer pool4
I1202 02:19:48.759765 26907 net.cpp:67] Creating Layer pool4
I1202 02:19:48.759768 26907 net.cpp:394] pool4 <- conv4_3
I1202 02:19:48.759773 26907 net.cpp:356] pool4 -> pool4
I1202 02:19:48.759778 26907 net.cpp:96] Setting up pool4
I1202 02:19:48.759785 26907 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:19:48.759789 26907 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:19:48.759796 26907 net.cpp:67] Creating Layer conv5_1
I1202 02:19:48.759799 26907 net.cpp:394] conv5_1 <- pool4
I1202 02:19:48.759804 26907 net.cpp:356] conv5_1 -> conv5_1
I1202 02:19:48.759814 26907 net.cpp:96] Setting up conv5_1
I1202 02:19:48.817987 26907 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:19:48.818013 26907 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:19:48.818022 26907 net.cpp:67] Creating Layer relu5_1
I1202 02:19:48.818025 26907 net.cpp:394] relu5_1 <- conv5_1
I1202 02:19:48.818032 26907 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:19:48.818038 26907 net.cpp:96] Setting up relu5_1
I1202 02:19:48.818044 26907 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:19:48.818048 26907 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:19:48.818061 26907 net.cpp:67] Creating Layer conv5_2
I1202 02:19:48.818065 26907 net.cpp:394] conv5_2 <- conv5_1
I1202 02:19:48.818071 26907 net.cpp:356] conv5_2 -> conv5_2
I1202 02:19:48.818078 26907 net.cpp:96] Setting up conv5_2
I1202 02:19:48.875808 26907 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:19:48.875834 26907 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:19:48.875844 26907 net.cpp:67] Creating Layer relu5_2
I1202 02:19:48.875849 26907 net.cpp:394] relu5_2 <- conv5_2
I1202 02:19:48.875854 26907 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:19:48.875861 26907 net.cpp:96] Setting up relu5_2
I1202 02:19:48.875866 26907 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:19:48.875869 26907 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:19:48.875876 26907 net.cpp:67] Creating Layer conv5_3
I1202 02:19:48.875880 26907 net.cpp:394] conv5_3 <- conv5_2
I1202 02:19:48.875885 26907 net.cpp:356] conv5_3 -> conv5_3
I1202 02:19:48.875890 26907 net.cpp:96] Setting up conv5_3
I1202 02:19:48.933857 26907 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:19:48.933882 26907 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:19:48.933889 26907 net.cpp:67] Creating Layer relu5_3
I1202 02:19:48.933894 26907 net.cpp:394] relu5_3 <- conv5_3
I1202 02:19:48.933900 26907 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:19:48.933907 26907 net.cpp:96] Setting up relu5_3
I1202 02:19:48.933912 26907 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:19:48.933925 26907 layer_factory.hpp:78] Creating layer pool5
I1202 02:19:48.933933 26907 net.cpp:67] Creating Layer pool5
I1202 02:19:48.933936 26907 net.cpp:394] pool5 <- conv5_3
I1202 02:19:48.933941 26907 net.cpp:356] pool5 -> pool5
I1202 02:19:48.933948 26907 net.cpp:96] Setting up pool5
I1202 02:19:48.933954 26907 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:19:48.933959 26907 layer_factory.hpp:78] Creating layer fc6
I1202 02:19:48.933974 26907 net.cpp:67] Creating Layer fc6
I1202 02:19:48.933976 26907 net.cpp:394] fc6 <- pool5
I1202 02:19:48.933982 26907 net.cpp:356] fc6 -> fc6
I1202 02:19:48.933989 26907 net.cpp:96] Setting up fc6
I1202 02:19:51.433682 26907 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:19:51.433712 26907 layer_factory.hpp:78] Creating layer relu6
I1202 02:19:51.433719 26907 net.cpp:67] Creating Layer relu6
I1202 02:19:51.433724 26907 net.cpp:394] relu6 <- fc6
I1202 02:19:51.433732 26907 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:19:51.433739 26907 net.cpp:96] Setting up relu6
I1202 02:19:51.433753 26907 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:19:51.433758 26907 layer_factory.hpp:78] Creating layer drop6
I1202 02:19:51.433764 26907 net.cpp:67] Creating Layer drop6
I1202 02:19:51.433768 26907 net.cpp:394] drop6 <- fc6
I1202 02:19:51.433771 26907 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:19:51.433776 26907 net.cpp:96] Setting up drop6
I1202 02:19:51.433779 26907 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:19:51.433783 26907 layer_factory.hpp:78] Creating layer fc7
I1202 02:19:51.433791 26907 net.cpp:67] Creating Layer fc7
I1202 02:19:51.433794 26907 net.cpp:394] fc7 <- fc6
I1202 02:19:51.433799 26907 net.cpp:356] fc7 -> fc7
I1202 02:19:51.433805 26907 net.cpp:96] Setting up fc7
I1202 02:19:51.843942 26907 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:19:51.843973 26907 layer_factory.hpp:78] Creating layer relu7
I1202 02:19:51.843981 26907 net.cpp:67] Creating Layer relu7
I1202 02:19:51.843986 26907 net.cpp:394] relu7 <- fc7
I1202 02:19:51.843993 26907 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:19:51.843999 26907 net.cpp:96] Setting up relu7
I1202 02:19:51.844014 26907 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:19:51.844017 26907 layer_factory.hpp:78] Creating layer drop7
I1202 02:19:51.844023 26907 net.cpp:67] Creating Layer drop7
I1202 02:19:51.844025 26907 net.cpp:394] drop7 <- fc7
I1202 02:19:51.844032 26907 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:19:51.844035 26907 net.cpp:96] Setting up drop7
I1202 02:19:51.844039 26907 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:19:51.844043 26907 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:19:51.844048 26907 net.cpp:67] Creating Layer fc8_2
I1202 02:19:51.844050 26907 net.cpp:394] fc8_2 <- fc7
I1202 02:19:51.844056 26907 net.cpp:356] fc8_2 -> fc8_2
I1202 02:19:51.844063 26907 net.cpp:96] Setting up fc8_2
I1202 02:19:51.844283 26907 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:19:51.844291 26907 layer_factory.hpp:78] Creating layer loss
I1202 02:19:51.844297 26907 net.cpp:67] Creating Layer loss
I1202 02:19:51.844301 26907 net.cpp:394] loss <- fc8_2
I1202 02:19:51.844305 26907 net.cpp:394] loss <- label
I1202 02:19:51.844313 26907 net.cpp:356] loss -> (automatic)
I1202 02:19:51.844317 26907 net.cpp:96] Setting up loss
I1202 02:19:51.844326 26907 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:19:51.844329 26907 net.cpp:109]     with loss weight 1
I1202 02:19:51.844365 26907 net.cpp:170] loss needs backward computation.
I1202 02:19:51.844368 26907 net.cpp:170] fc8_2 needs backward computation.
I1202 02:19:51.844372 26907 net.cpp:170] drop7 needs backward computation.
I1202 02:19:51.844373 26907 net.cpp:170] relu7 needs backward computation.
I1202 02:19:51.844377 26907 net.cpp:170] fc7 needs backward computation.
I1202 02:19:51.844378 26907 net.cpp:170] drop6 needs backward computation.
I1202 02:19:51.844382 26907 net.cpp:170] relu6 needs backward computation.
I1202 02:19:51.844384 26907 net.cpp:170] fc6 needs backward computation.
I1202 02:19:51.844398 26907 net.cpp:170] pool5 needs backward computation.
I1202 02:19:51.844400 26907 net.cpp:170] relu5_3 needs backward computation.
I1202 02:19:51.844408 26907 net.cpp:170] conv5_3 needs backward computation.
I1202 02:19:51.844411 26907 net.cpp:170] relu5_2 needs backward computation.
I1202 02:19:51.844413 26907 net.cpp:170] conv5_2 needs backward computation.
I1202 02:19:51.844416 26907 net.cpp:170] relu5_1 needs backward computation.
I1202 02:19:51.844419 26907 net.cpp:170] conv5_1 needs backward computation.
I1202 02:19:51.844422 26907 net.cpp:170] pool4 needs backward computation.
I1202 02:19:51.844425 26907 net.cpp:170] relu4_3 needs backward computation.
I1202 02:19:51.844429 26907 net.cpp:170] conv4_3 needs backward computation.
I1202 02:19:51.844431 26907 net.cpp:170] relu4_2 needs backward computation.
I1202 02:19:51.844435 26907 net.cpp:170] conv4_2 needs backward computation.
I1202 02:19:51.844439 26907 net.cpp:170] relu4_1 needs backward computation.
I1202 02:19:51.844441 26907 net.cpp:170] conv4_1 needs backward computation.
I1202 02:19:51.844444 26907 net.cpp:170] pool3 needs backward computation.
I1202 02:19:51.844447 26907 net.cpp:170] relu3_3 needs backward computation.
I1202 02:19:51.844450 26907 net.cpp:170] conv3_3 needs backward computation.
I1202 02:19:51.844454 26907 net.cpp:170] relu3_2 needs backward computation.
I1202 02:19:51.844455 26907 net.cpp:170] conv3_2 needs backward computation.
I1202 02:19:51.844458 26907 net.cpp:170] relu3_1 needs backward computation.
I1202 02:19:51.844461 26907 net.cpp:170] conv3_1 needs backward computation.
I1202 02:19:51.844465 26907 net.cpp:170] pool2 needs backward computation.
I1202 02:19:51.844467 26907 net.cpp:170] relu2_2 needs backward computation.
I1202 02:19:51.844470 26907 net.cpp:170] conv2_2 needs backward computation.
I1202 02:19:51.844472 26907 net.cpp:170] relu2_1 needs backward computation.
I1202 02:19:51.844475 26907 net.cpp:170] conv2_1 needs backward computation.
I1202 02:19:51.844478 26907 net.cpp:170] pool1 needs backward computation.
I1202 02:19:51.844480 26907 net.cpp:170] relu1_2 needs backward computation.
I1202 02:19:51.844483 26907 net.cpp:170] conv1_2 needs backward computation.
I1202 02:19:51.844486 26907 net.cpp:170] relu1_1 needs backward computation.
I1202 02:19:51.844488 26907 net.cpp:170] conv1_1 needs backward computation.
I1202 02:19:51.844491 26907 net.cpp:172] data does not need backward computation.
I1202 02:19:51.844509 26907 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:19:51.844516 26907 net.cpp:219] Network initialization done.
I1202 02:19:51.844518 26907 net.cpp:220] Memory required for data: 3686465924
I1202 02:19:51.845368 26907 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:19:51.845412 26907 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:19:51.845634 26907 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:19:51.845777 26907 layer_factory.hpp:78] Creating layer data
I1202 02:19:51.845787 26907 net.cpp:67] Creating Layer data
I1202 02:19:51.845790 26907 net.cpp:356] data -> data
I1202 02:19:51.845798 26907 net.cpp:356] data -> label
I1202 02:19:51.845804 26907 net.cpp:96] Setting up data
I1202 02:19:51.845808 26907 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:19:51.847323 26907 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:19:51.854420 26907 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:19:51.855293 26907 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:19:51.855304 26907 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:19:51.855307 26907 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:19:51.855321 26907 net.cpp:67] Creating Layer label_data_1_split
I1202 02:19:51.855325 26907 net.cpp:394] label_data_1_split <- label
I1202 02:19:51.855331 26907 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:19:51.855340 26907 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:19:51.855346 26907 net.cpp:96] Setting up label_data_1_split
I1202 02:19:51.855350 26907 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:19:51.855353 26907 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:19:51.855356 26907 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:19:51.855362 26907 net.cpp:67] Creating Layer conv1_1
I1202 02:19:51.855365 26907 net.cpp:394] conv1_1 <- data
I1202 02:19:51.855370 26907 net.cpp:356] conv1_1 -> conv1_1
I1202 02:19:51.855376 26907 net.cpp:96] Setting up conv1_1
I1202 02:19:51.855542 26907 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:19:51.855556 26907 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:19:51.855561 26907 net.cpp:67] Creating Layer relu1_1
I1202 02:19:51.855566 26907 net.cpp:394] relu1_1 <- conv1_1
I1202 02:19:51.855569 26907 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:19:51.855581 26907 net.cpp:96] Setting up relu1_1
I1202 02:19:51.855587 26907 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:19:51.855590 26907 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:19:51.855595 26907 net.cpp:67] Creating Layer conv1_2
I1202 02:19:51.855598 26907 net.cpp:394] conv1_2 <- conv1_1
I1202 02:19:51.855603 26907 net.cpp:356] conv1_2 -> conv1_2
I1202 02:19:51.855608 26907 net.cpp:96] Setting up conv1_2
I1202 02:19:51.856607 26907 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:19:51.856621 26907 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:19:51.856626 26907 net.cpp:67] Creating Layer relu1_2
I1202 02:19:51.856628 26907 net.cpp:394] relu1_2 <- conv1_2
I1202 02:19:51.856632 26907 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:19:51.856637 26907 net.cpp:96] Setting up relu1_2
I1202 02:19:51.856642 26907 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:19:51.856645 26907 layer_factory.hpp:78] Creating layer pool1
I1202 02:19:51.856650 26907 net.cpp:67] Creating Layer pool1
I1202 02:19:51.856653 26907 net.cpp:394] pool1 <- conv1_2
I1202 02:19:51.856657 26907 net.cpp:356] pool1 -> pool1
I1202 02:19:51.856662 26907 net.cpp:96] Setting up pool1
I1202 02:19:51.856669 26907 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:19:51.856673 26907 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:19:51.856678 26907 net.cpp:67] Creating Layer conv2_1
I1202 02:19:51.856680 26907 net.cpp:394] conv2_1 <- pool1
I1202 02:19:51.856685 26907 net.cpp:356] conv2_1 -> conv2_1
I1202 02:19:51.856690 26907 net.cpp:96] Setting up conv2_1
I1202 02:19:51.858692 26907 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:19:51.858705 26907 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:19:51.858711 26907 net.cpp:67] Creating Layer relu2_1
I1202 02:19:51.858716 26907 net.cpp:394] relu2_1 <- conv2_1
I1202 02:19:51.858719 26907 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:19:51.858724 26907 net.cpp:96] Setting up relu2_1
I1202 02:19:51.858729 26907 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:19:51.858732 26907 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:19:51.858737 26907 net.cpp:67] Creating Layer conv2_2
I1202 02:19:51.858741 26907 net.cpp:394] conv2_2 <- conv2_1
I1202 02:19:51.858744 26907 net.cpp:356] conv2_2 -> conv2_2
I1202 02:19:51.858750 26907 net.cpp:96] Setting up conv2_2
I1202 02:19:51.862396 26907 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:19:51.862407 26907 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:19:51.862411 26907 net.cpp:67] Creating Layer relu2_2
I1202 02:19:51.862416 26907 net.cpp:394] relu2_2 <- conv2_2
I1202 02:19:51.862419 26907 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:19:51.862424 26907 net.cpp:96] Setting up relu2_2
I1202 02:19:51.862428 26907 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:19:51.862432 26907 layer_factory.hpp:78] Creating layer pool2
I1202 02:19:51.862437 26907 net.cpp:67] Creating Layer pool2
I1202 02:19:51.862439 26907 net.cpp:394] pool2 <- conv2_2
I1202 02:19:51.862443 26907 net.cpp:356] pool2 -> pool2
I1202 02:19:51.862448 26907 net.cpp:96] Setting up pool2
I1202 02:19:51.862454 26907 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:19:51.862457 26907 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:19:51.862462 26907 net.cpp:67] Creating Layer conv3_1
I1202 02:19:51.862465 26907 net.cpp:394] conv3_1 <- pool2
I1202 02:19:51.862469 26907 net.cpp:356] conv3_1 -> conv3_1
I1202 02:19:51.862474 26907 net.cpp:96] Setting up conv3_1
I1202 02:19:51.869714 26907 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:19:51.869729 26907 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:19:51.869734 26907 net.cpp:67] Creating Layer relu3_1
I1202 02:19:51.869736 26907 net.cpp:394] relu3_1 <- conv3_1
I1202 02:19:51.869741 26907 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:19:51.869746 26907 net.cpp:96] Setting up relu3_1
I1202 02:19:51.869751 26907 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:19:51.869755 26907 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:19:51.869766 26907 net.cpp:67] Creating Layer conv3_2
I1202 02:19:51.869770 26907 net.cpp:394] conv3_2 <- conv3_1
I1202 02:19:51.869774 26907 net.cpp:356] conv3_2 -> conv3_2
I1202 02:19:51.869779 26907 net.cpp:96] Setting up conv3_2
I1202 02:19:51.884404 26907 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:19:51.884425 26907 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:19:51.884434 26907 net.cpp:67] Creating Layer relu3_2
I1202 02:19:51.884439 26907 net.cpp:394] relu3_2 <- conv3_2
I1202 02:19:51.884445 26907 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:19:51.884451 26907 net.cpp:96] Setting up relu3_2
I1202 02:19:51.884457 26907 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:19:51.884460 26907 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:19:51.884469 26907 net.cpp:67] Creating Layer conv3_3
I1202 02:19:51.884471 26907 net.cpp:394] conv3_3 <- conv3_2
I1202 02:19:51.884479 26907 net.cpp:356] conv3_3 -> conv3_3
I1202 02:19:51.884485 26907 net.cpp:96] Setting up conv3_3
I1202 02:19:51.899000 26907 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:19:51.899019 26907 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:19:51.899025 26907 net.cpp:67] Creating Layer relu3_3
I1202 02:19:51.899029 26907 net.cpp:394] relu3_3 <- conv3_3
I1202 02:19:51.899034 26907 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:19:51.899040 26907 net.cpp:96] Setting up relu3_3
I1202 02:19:51.899045 26907 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:19:51.899049 26907 layer_factory.hpp:78] Creating layer pool3
I1202 02:19:51.899055 26907 net.cpp:67] Creating Layer pool3
I1202 02:19:51.899057 26907 net.cpp:394] pool3 <- conv3_3
I1202 02:19:51.899062 26907 net.cpp:356] pool3 -> pool3
I1202 02:19:51.899068 26907 net.cpp:96] Setting up pool3
I1202 02:19:51.899075 26907 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:19:51.899078 26907 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:19:51.899085 26907 net.cpp:67] Creating Layer conv4_1
I1202 02:19:51.899086 26907 net.cpp:394] conv4_1 <- pool3
I1202 02:19:51.899092 26907 net.cpp:356] conv4_1 -> conv4_1
I1202 02:19:51.899098 26907 net.cpp:96] Setting up conv4_1
I1202 02:19:51.928383 26907 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:19:51.928406 26907 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:19:51.928416 26907 net.cpp:67] Creating Layer relu4_1
I1202 02:19:51.928421 26907 net.cpp:394] relu4_1 <- conv4_1
I1202 02:19:51.928426 26907 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:19:51.928433 26907 net.cpp:96] Setting up relu4_1
I1202 02:19:51.928438 26907 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:19:51.928442 26907 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:19:51.928449 26907 net.cpp:67] Creating Layer conv4_2
I1202 02:19:51.928452 26907 net.cpp:394] conv4_2 <- conv4_1
I1202 02:19:51.928457 26907 net.cpp:356] conv4_2 -> conv4_2
I1202 02:19:51.928463 26907 net.cpp:96] Setting up conv4_2
I1202 02:19:51.986135 26907 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:19:51.986163 26907 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:19:51.986171 26907 net.cpp:67] Creating Layer relu4_2
I1202 02:19:51.986176 26907 net.cpp:394] relu4_2 <- conv4_2
I1202 02:19:51.986183 26907 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:19:51.986189 26907 net.cpp:96] Setting up relu4_2
I1202 02:19:51.986196 26907 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:19:51.986199 26907 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:19:51.986206 26907 net.cpp:67] Creating Layer conv4_3
I1202 02:19:51.986208 26907 net.cpp:394] conv4_3 <- conv4_2
I1202 02:19:51.986215 26907 net.cpp:356] conv4_3 -> conv4_3
I1202 02:19:51.986223 26907 net.cpp:96] Setting up conv4_3
I1202 02:19:52.044137 26907 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:19:52.044162 26907 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:19:52.044169 26907 net.cpp:67] Creating Layer relu4_3
I1202 02:19:52.044175 26907 net.cpp:394] relu4_3 <- conv4_3
I1202 02:19:52.044183 26907 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:19:52.044198 26907 net.cpp:96] Setting up relu4_3
I1202 02:19:52.044203 26907 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:19:52.044208 26907 layer_factory.hpp:78] Creating layer pool4
I1202 02:19:52.044214 26907 net.cpp:67] Creating Layer pool4
I1202 02:19:52.044216 26907 net.cpp:394] pool4 <- conv4_3
I1202 02:19:52.044220 26907 net.cpp:356] pool4 -> pool4
I1202 02:19:52.044226 26907 net.cpp:96] Setting up pool4
I1202 02:19:52.044234 26907 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:19:52.044237 26907 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:19:52.044245 26907 net.cpp:67] Creating Layer conv5_1
I1202 02:19:52.044248 26907 net.cpp:394] conv5_1 <- pool4
I1202 02:19:52.044252 26907 net.cpp:356] conv5_1 -> conv5_1
I1202 02:19:52.044258 26907 net.cpp:96] Setting up conv5_1
I1202 02:19:52.101894 26907 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:19:52.101919 26907 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:19:52.101927 26907 net.cpp:67] Creating Layer relu5_1
I1202 02:19:52.101932 26907 net.cpp:394] relu5_1 <- conv5_1
I1202 02:19:52.101939 26907 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:19:52.101945 26907 net.cpp:96] Setting up relu5_1
I1202 02:19:52.101951 26907 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:19:52.101954 26907 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:19:52.101959 26907 net.cpp:67] Creating Layer conv5_2
I1202 02:19:52.101963 26907 net.cpp:394] conv5_2 <- conv5_1
I1202 02:19:52.101969 26907 net.cpp:356] conv5_2 -> conv5_2
I1202 02:19:52.101976 26907 net.cpp:96] Setting up conv5_2
I1202 02:19:52.159852 26907 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:19:52.159876 26907 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:19:52.159884 26907 net.cpp:67] Creating Layer relu5_2
I1202 02:19:52.159888 26907 net.cpp:394] relu5_2 <- conv5_2
I1202 02:19:52.159896 26907 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:19:52.159903 26907 net.cpp:96] Setting up relu5_2
I1202 02:19:52.159909 26907 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:19:52.159911 26907 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:19:52.159917 26907 net.cpp:67] Creating Layer conv5_3
I1202 02:19:52.159920 26907 net.cpp:394] conv5_3 <- conv5_2
I1202 02:19:52.159926 26907 net.cpp:356] conv5_3 -> conv5_3
I1202 02:19:52.159932 26907 net.cpp:96] Setting up conv5_3
I1202 02:19:52.217717 26907 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:19:52.217743 26907 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:19:52.217752 26907 net.cpp:67] Creating Layer relu5_3
I1202 02:19:52.217756 26907 net.cpp:394] relu5_3 <- conv5_3
I1202 02:19:52.217764 26907 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:19:52.217772 26907 net.cpp:96] Setting up relu5_3
I1202 02:19:52.217777 26907 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:19:52.217780 26907 layer_factory.hpp:78] Creating layer pool5
I1202 02:19:52.217793 26907 net.cpp:67] Creating Layer pool5
I1202 02:19:52.217797 26907 net.cpp:394] pool5 <- conv5_3
I1202 02:19:52.217802 26907 net.cpp:356] pool5 -> pool5
I1202 02:19:52.217808 26907 net.cpp:96] Setting up pool5
I1202 02:19:52.217814 26907 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:19:52.217818 26907 layer_factory.hpp:78] Creating layer fc6
I1202 02:19:52.217824 26907 net.cpp:67] Creating Layer fc6
I1202 02:19:52.217826 26907 net.cpp:394] fc6 <- pool5
I1202 02:19:52.217833 26907 net.cpp:356] fc6 -> fc6
I1202 02:19:52.217839 26907 net.cpp:96] Setting up fc6
I1202 02:19:54.715195 26907 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:19:54.715224 26907 layer_factory.hpp:78] Creating layer relu6
I1202 02:19:54.715232 26907 net.cpp:67] Creating Layer relu6
I1202 02:19:54.715236 26907 net.cpp:394] relu6 <- fc6
I1202 02:19:54.715245 26907 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:19:54.715252 26907 net.cpp:96] Setting up relu6
I1202 02:19:54.715265 26907 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:19:54.715270 26907 layer_factory.hpp:78] Creating layer drop6
I1202 02:19:54.715286 26907 net.cpp:67] Creating Layer drop6
I1202 02:19:54.715289 26907 net.cpp:394] drop6 <- fc6
I1202 02:19:54.715294 26907 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:19:54.715298 26907 net.cpp:96] Setting up drop6
I1202 02:19:54.715302 26907 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:19:54.715306 26907 layer_factory.hpp:78] Creating layer fc7
I1202 02:19:54.715312 26907 net.cpp:67] Creating Layer fc7
I1202 02:19:54.715314 26907 net.cpp:394] fc7 <- fc6
I1202 02:19:54.715319 26907 net.cpp:356] fc7 -> fc7
I1202 02:19:54.715327 26907 net.cpp:96] Setting up fc7
I1202 02:19:55.124063 26907 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:19:55.124092 26907 layer_factory.hpp:78] Creating layer relu7
I1202 02:19:55.124101 26907 net.cpp:67] Creating Layer relu7
I1202 02:19:55.124106 26907 net.cpp:394] relu7 <- fc7
I1202 02:19:55.124114 26907 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:19:55.124119 26907 net.cpp:96] Setting up relu7
I1202 02:19:55.124135 26907 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:19:55.124137 26907 layer_factory.hpp:78] Creating layer drop7
I1202 02:19:55.124142 26907 net.cpp:67] Creating Layer drop7
I1202 02:19:55.124145 26907 net.cpp:394] drop7 <- fc7
I1202 02:19:55.124151 26907 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:19:55.124155 26907 net.cpp:96] Setting up drop7
I1202 02:19:55.124160 26907 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:19:55.124162 26907 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:19:55.124168 26907 net.cpp:67] Creating Layer fc8_2
I1202 02:19:55.124171 26907 net.cpp:394] fc8_2 <- fc7
I1202 02:19:55.124176 26907 net.cpp:356] fc8_2 -> fc8_2
I1202 02:19:55.124183 26907 net.cpp:96] Setting up fc8_2
I1202 02:19:55.124403 26907 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:19:55.124411 26907 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:19:55.124416 26907 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:19:55.124419 26907 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:19:55.124423 26907 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:19:55.124430 26907 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:19:55.124436 26907 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:19:55.124444 26907 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:19:55.124446 26907 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:19:55.124449 26907 layer_factory.hpp:78] Creating layer loss
I1202 02:19:55.124456 26907 net.cpp:67] Creating Layer loss
I1202 02:19:55.124464 26907 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:19:55.124472 26907 net.cpp:394] loss <- label_data_1_split_0
I1202 02:19:55.124478 26907 net.cpp:356] loss -> (automatic)
I1202 02:19:55.124482 26907 net.cpp:96] Setting up loss
I1202 02:19:55.124488 26907 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:19:55.124495 26907 net.cpp:109]     with loss weight 1
I1202 02:19:55.124508 26907 layer_factory.hpp:78] Creating layer accuracy
I1202 02:19:55.124513 26907 net.cpp:67] Creating Layer accuracy
I1202 02:19:55.124521 26907 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:19:55.124524 26907 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:19:55.124531 26907 net.cpp:356] accuracy -> accuracy
I1202 02:19:55.124537 26907 net.cpp:96] Setting up accuracy
I1202 02:19:55.124547 26907 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:19:55.124552 26907 net.cpp:172] accuracy does not need backward computation.
I1202 02:19:55.124553 26907 net.cpp:170] loss needs backward computation.
I1202 02:19:55.124557 26907 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:19:55.124559 26907 net.cpp:170] fc8_2 needs backward computation.
I1202 02:19:55.124562 26907 net.cpp:170] drop7 needs backward computation.
I1202 02:19:55.124564 26907 net.cpp:170] relu7 needs backward computation.
I1202 02:19:55.124567 26907 net.cpp:170] fc7 needs backward computation.
I1202 02:19:55.124570 26907 net.cpp:170] drop6 needs backward computation.
I1202 02:19:55.124572 26907 net.cpp:170] relu6 needs backward computation.
I1202 02:19:55.124583 26907 net.cpp:170] fc6 needs backward computation.
I1202 02:19:55.124586 26907 net.cpp:170] pool5 needs backward computation.
I1202 02:19:55.124589 26907 net.cpp:170] relu5_3 needs backward computation.
I1202 02:19:55.124593 26907 net.cpp:170] conv5_3 needs backward computation.
I1202 02:19:55.124595 26907 net.cpp:170] relu5_2 needs backward computation.
I1202 02:19:55.124598 26907 net.cpp:170] conv5_2 needs backward computation.
I1202 02:19:55.124601 26907 net.cpp:170] relu5_1 needs backward computation.
I1202 02:19:55.124603 26907 net.cpp:170] conv5_1 needs backward computation.
I1202 02:19:55.124606 26907 net.cpp:170] pool4 needs backward computation.
I1202 02:19:55.124609 26907 net.cpp:170] relu4_3 needs backward computation.
I1202 02:19:55.124613 26907 net.cpp:170] conv4_3 needs backward computation.
I1202 02:19:55.124615 26907 net.cpp:170] relu4_2 needs backward computation.
I1202 02:19:55.124618 26907 net.cpp:170] conv4_2 needs backward computation.
I1202 02:19:55.124620 26907 net.cpp:170] relu4_1 needs backward computation.
I1202 02:19:55.124624 26907 net.cpp:170] conv4_1 needs backward computation.
I1202 02:19:55.124625 26907 net.cpp:170] pool3 needs backward computation.
I1202 02:19:55.124629 26907 net.cpp:170] relu3_3 needs backward computation.
I1202 02:19:55.124631 26907 net.cpp:170] conv3_3 needs backward computation.
I1202 02:19:55.124634 26907 net.cpp:170] relu3_2 needs backward computation.
I1202 02:19:55.124636 26907 net.cpp:170] conv3_2 needs backward computation.
I1202 02:19:55.124639 26907 net.cpp:170] relu3_1 needs backward computation.
I1202 02:19:55.124642 26907 net.cpp:170] conv3_1 needs backward computation.
I1202 02:19:55.124645 26907 net.cpp:170] pool2 needs backward computation.
I1202 02:19:55.124647 26907 net.cpp:170] relu2_2 needs backward computation.
I1202 02:19:55.124650 26907 net.cpp:170] conv2_2 needs backward computation.
I1202 02:19:55.124654 26907 net.cpp:170] relu2_1 needs backward computation.
I1202 02:19:55.124655 26907 net.cpp:170] conv2_1 needs backward computation.
I1202 02:19:55.124658 26907 net.cpp:170] pool1 needs backward computation.
I1202 02:19:55.124661 26907 net.cpp:170] relu1_2 needs backward computation.
I1202 02:19:55.124665 26907 net.cpp:170] conv1_2 needs backward computation.
I1202 02:19:55.124666 26907 net.cpp:170] relu1_1 needs backward computation.
I1202 02:19:55.124670 26907 net.cpp:170] conv1_1 needs backward computation.
I1202 02:19:55.124672 26907 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:19:55.124675 26907 net.cpp:172] data does not need backward computation.
I1202 02:19:55.124677 26907 net.cpp:208] This network produces output accuracy
I1202 02:19:55.124701 26907 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:19:55.124709 26907 net.cpp:219] Network initialization done.
I1202 02:19:55.124712 26907 net.cpp:220] Memory required for data: 921616692
I1202 02:19:55.124811 26907 solver.cpp:41] Solver scaffolding done.
I1202 02:19:55.124817 26907 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_14000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:19:59.203905 26907 solver.cpp:160] Solving small
I1202 02:19:59.203932 26907 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:19:59.203977 26907 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:21:23.949995 26907 solver.cpp:305] Test loss: 0.441505
I1202 02:21:23.950078 26907 solver.cpp:318] mean_score = test_score[0] { = 2935} / test_score[1] { = 3570 }
I1202 02:21:23.950088 26907 solver.cpp:319]            = 0.822129
I1202 02:21:23.950095 26907 solver.cpp:328]     Test net output #0: accuracy = 0.822129
I1202 02:21:23.950100 26907 solver.cpp:318] mean_score = test_score[2] { = 256} / test_score[3] { = 398 }
I1202 02:21:23.950105 26907 solver.cpp:319]            = 0.643216
I1202 02:21:23.950109 26907 solver.cpp:328]     Test net output #1: accuracy = 0.643216
I1202 02:21:23.950119 26907 solver.cpp:332]     Test net output #2: accuracy = 0.804183
I1202 02:21:23.950124 26907 solver.cpp:334]     Test net output #3: accuracy = 0.732672
I1202 02:21:24.647892 26907 solver.cpp:209] Iteration 0, loss = 0.180339
I1202 02:21:24.647922 26907 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:21:26.998522 26907 solver.cpp:209] Iteration 1, loss = 0.177711
I1202 02:21:26.998550 26907 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:21:29.012560 26907 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:21:32.840286 26907 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:21:36.946494 26907 solver.cpp:246] Iteration 2, loss = 0.411995
I1202 02:21:36.946527 26907 solver.cpp:251] Optimization Done.
I1202 02:21:36.946530 26907 caffe.cpp:121] Optimization Done.
I1202 02:21:37.084990 27461 caffe.cpp:99] Use GPU with device ID 0
I1202 02:21:37.269964 27461 caffe.cpp:107] Starting Optimization
I1202 02:21:37.270062 27461 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:21:37.270086 27461 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:21:37.270867 27461 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:21:37.270911 27461 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:21:37.271126 27461 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:21:37.271250 27461 layer_factory.hpp:78] Creating layer data
I1202 02:21:37.271271 27461 net.cpp:67] Creating Layer data
I1202 02:21:37.271278 27461 net.cpp:356] data -> data
I1202 02:21:37.271297 27461 net.cpp:356] data -> label
I1202 02:21:37.271304 27461 net.cpp:96] Setting up data
I1202 02:21:37.271311 27461 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:21:37.285542 27461 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:21:37.295380 27461 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:21:37.298252 27461 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:21:37.298279 27461 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:21:37.298284 27461 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:21:37.298300 27461 net.cpp:67] Creating Layer conv1_1
I1202 02:21:37.298303 27461 net.cpp:394] conv1_1 <- data
I1202 02:21:37.298316 27461 net.cpp:356] conv1_1 -> conv1_1
I1202 02:21:37.298327 27461 net.cpp:96] Setting up conv1_1
I1202 02:21:37.440027 27461 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:21:37.440062 27461 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:21:37.440073 27461 net.cpp:67] Creating Layer relu1_1
I1202 02:21:37.440078 27461 net.cpp:394] relu1_1 <- conv1_1
I1202 02:21:37.440084 27461 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:21:37.440093 27461 net.cpp:96] Setting up relu1_1
I1202 02:21:37.440101 27461 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:21:37.440104 27461 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:21:37.440111 27461 net.cpp:67] Creating Layer conv1_2
I1202 02:21:37.440114 27461 net.cpp:394] conv1_2 <- conv1_1
I1202 02:21:37.440119 27461 net.cpp:356] conv1_2 -> conv1_2
I1202 02:21:37.440125 27461 net.cpp:96] Setting up conv1_2
I1202 02:21:37.441184 27461 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:21:37.441197 27461 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:21:37.441205 27461 net.cpp:67] Creating Layer relu1_2
I1202 02:21:37.441208 27461 net.cpp:394] relu1_2 <- conv1_2
I1202 02:21:37.441213 27461 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:21:37.441217 27461 net.cpp:96] Setting up relu1_2
I1202 02:21:37.441222 27461 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:21:37.441226 27461 layer_factory.hpp:78] Creating layer pool1
I1202 02:21:37.441233 27461 net.cpp:67] Creating Layer pool1
I1202 02:21:37.441236 27461 net.cpp:394] pool1 <- conv1_2
I1202 02:21:37.441241 27461 net.cpp:356] pool1 -> pool1
I1202 02:21:37.441247 27461 net.cpp:96] Setting up pool1
I1202 02:21:37.441262 27461 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:21:37.441267 27461 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:21:37.441272 27461 net.cpp:67] Creating Layer conv2_1
I1202 02:21:37.441274 27461 net.cpp:394] conv2_1 <- pool1
I1202 02:21:37.441280 27461 net.cpp:356] conv2_1 -> conv2_1
I1202 02:21:37.441285 27461 net.cpp:96] Setting up conv2_1
I1202 02:21:37.443218 27461 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:21:37.443231 27461 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:21:37.443236 27461 net.cpp:67] Creating Layer relu2_1
I1202 02:21:37.443239 27461 net.cpp:394] relu2_1 <- conv2_1
I1202 02:21:37.443244 27461 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:21:37.443248 27461 net.cpp:96] Setting up relu2_1
I1202 02:21:37.443253 27461 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:21:37.443256 27461 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:21:37.443264 27461 net.cpp:67] Creating Layer conv2_2
I1202 02:21:37.443267 27461 net.cpp:394] conv2_2 <- conv2_1
I1202 02:21:37.443274 27461 net.cpp:356] conv2_2 -> conv2_2
I1202 02:21:37.443279 27461 net.cpp:96] Setting up conv2_2
I1202 02:21:37.447087 27461 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:21:37.447101 27461 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:21:37.447106 27461 net.cpp:67] Creating Layer relu2_2
I1202 02:21:37.447109 27461 net.cpp:394] relu2_2 <- conv2_2
I1202 02:21:37.447115 27461 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:21:37.447120 27461 net.cpp:96] Setting up relu2_2
I1202 02:21:37.447135 27461 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:21:37.447147 27461 layer_factory.hpp:78] Creating layer pool2
I1202 02:21:37.447154 27461 net.cpp:67] Creating Layer pool2
I1202 02:21:37.447156 27461 net.cpp:394] pool2 <- conv2_2
I1202 02:21:37.447160 27461 net.cpp:356] pool2 -> pool2
I1202 02:21:37.447167 27461 net.cpp:96] Setting up pool2
I1202 02:21:37.447175 27461 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:21:37.447177 27461 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:21:37.447182 27461 net.cpp:67] Creating Layer conv3_1
I1202 02:21:37.447185 27461 net.cpp:394] conv3_1 <- pool2
I1202 02:21:37.447190 27461 net.cpp:356] conv3_1 -> conv3_1
I1202 02:21:37.447197 27461 net.cpp:96] Setting up conv3_1
I1202 02:21:37.454639 27461 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:21:37.454654 27461 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:21:37.454659 27461 net.cpp:67] Creating Layer relu3_1
I1202 02:21:37.454663 27461 net.cpp:394] relu3_1 <- conv3_1
I1202 02:21:37.454668 27461 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:21:37.454673 27461 net.cpp:96] Setting up relu3_1
I1202 02:21:37.454677 27461 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:21:37.454680 27461 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:21:37.454691 27461 net.cpp:67] Creating Layer conv3_2
I1202 02:21:37.454694 27461 net.cpp:394] conv3_2 <- conv3_1
I1202 02:21:37.454699 27461 net.cpp:356] conv3_2 -> conv3_2
I1202 02:21:37.454704 27461 net.cpp:96] Setting up conv3_2
I1202 02:21:37.469683 27461 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:21:37.469702 27461 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:21:37.469708 27461 net.cpp:67] Creating Layer relu3_2
I1202 02:21:37.469712 27461 net.cpp:394] relu3_2 <- conv3_2
I1202 02:21:37.469719 27461 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:21:37.469727 27461 net.cpp:96] Setting up relu3_2
I1202 02:21:37.469732 27461 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:21:37.469734 27461 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:21:37.469739 27461 net.cpp:67] Creating Layer conv3_3
I1202 02:21:37.469743 27461 net.cpp:394] conv3_3 <- conv3_2
I1202 02:21:37.469746 27461 net.cpp:356] conv3_3 -> conv3_3
I1202 02:21:37.469753 27461 net.cpp:96] Setting up conv3_3
I1202 02:21:37.484654 27461 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:21:37.484675 27461 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:21:37.484685 27461 net.cpp:67] Creating Layer relu3_3
I1202 02:21:37.484690 27461 net.cpp:394] relu3_3 <- conv3_3
I1202 02:21:37.484696 27461 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:21:37.484702 27461 net.cpp:96] Setting up relu3_3
I1202 02:21:37.484709 27461 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:21:37.484712 27461 layer_factory.hpp:78] Creating layer pool3
I1202 02:21:37.484717 27461 net.cpp:67] Creating Layer pool3
I1202 02:21:37.484720 27461 net.cpp:394] pool3 <- conv3_3
I1202 02:21:37.484724 27461 net.cpp:356] pool3 -> pool3
I1202 02:21:37.484730 27461 net.cpp:96] Setting up pool3
I1202 02:21:37.484736 27461 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:21:37.484740 27461 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:21:37.484746 27461 net.cpp:67] Creating Layer conv4_1
I1202 02:21:37.484750 27461 net.cpp:394] conv4_1 <- pool3
I1202 02:21:37.484756 27461 net.cpp:356] conv4_1 -> conv4_1
I1202 02:21:37.484761 27461 net.cpp:96] Setting up conv4_1
I1202 02:21:37.514138 27461 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:21:37.514163 27461 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:21:37.514171 27461 net.cpp:67] Creating Layer relu4_1
I1202 02:21:37.514175 27461 net.cpp:394] relu4_1 <- conv4_1
I1202 02:21:37.514183 27461 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:21:37.514189 27461 net.cpp:96] Setting up relu4_1
I1202 02:21:37.514195 27461 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:21:37.514199 27461 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:21:37.514205 27461 net.cpp:67] Creating Layer conv4_2
I1202 02:21:37.514209 27461 net.cpp:394] conv4_2 <- conv4_1
I1202 02:21:37.514224 27461 net.cpp:356] conv4_2 -> conv4_2
I1202 02:21:37.514230 27461 net.cpp:96] Setting up conv4_2
I1202 02:21:37.573137 27461 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:21:37.573165 27461 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:21:37.573174 27461 net.cpp:67] Creating Layer relu4_2
I1202 02:21:37.573179 27461 net.cpp:394] relu4_2 <- conv4_2
I1202 02:21:37.573186 27461 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:21:37.573192 27461 net.cpp:96] Setting up relu4_2
I1202 02:21:37.573199 27461 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:21:37.573201 27461 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:21:37.573207 27461 net.cpp:67] Creating Layer conv4_3
I1202 02:21:37.573210 27461 net.cpp:394] conv4_3 <- conv4_2
I1202 02:21:37.573216 27461 net.cpp:356] conv4_3 -> conv4_3
I1202 02:21:37.573222 27461 net.cpp:96] Setting up conv4_3
I1202 02:21:37.630929 27461 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:21:37.630956 27461 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:21:37.630964 27461 net.cpp:67] Creating Layer relu4_3
I1202 02:21:37.630969 27461 net.cpp:394] relu4_3 <- conv4_3
I1202 02:21:37.630975 27461 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:21:37.630982 27461 net.cpp:96] Setting up relu4_3
I1202 02:21:37.630987 27461 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:21:37.630991 27461 layer_factory.hpp:78] Creating layer pool4
I1202 02:21:37.630996 27461 net.cpp:67] Creating Layer pool4
I1202 02:21:37.631000 27461 net.cpp:394] pool4 <- conv4_3
I1202 02:21:37.631006 27461 net.cpp:356] pool4 -> pool4
I1202 02:21:37.631011 27461 net.cpp:96] Setting up pool4
I1202 02:21:37.631018 27461 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:21:37.631022 27461 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:21:37.631031 27461 net.cpp:67] Creating Layer conv5_1
I1202 02:21:37.631034 27461 net.cpp:394] conv5_1 <- pool4
I1202 02:21:37.631038 27461 net.cpp:356] conv5_1 -> conv5_1
I1202 02:21:37.631047 27461 net.cpp:96] Setting up conv5_1
I1202 02:21:37.689107 27461 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:21:37.689133 27461 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:21:37.689148 27461 net.cpp:67] Creating Layer relu5_1
I1202 02:21:37.689153 27461 net.cpp:394] relu5_1 <- conv5_1
I1202 02:21:37.689159 27461 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:21:37.689167 27461 net.cpp:96] Setting up relu5_1
I1202 02:21:37.689172 27461 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:21:37.689175 27461 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:21:37.689182 27461 net.cpp:67] Creating Layer conv5_2
I1202 02:21:37.689185 27461 net.cpp:394] conv5_2 <- conv5_1
I1202 02:21:37.689189 27461 net.cpp:356] conv5_2 -> conv5_2
I1202 02:21:37.689195 27461 net.cpp:96] Setting up conv5_2
I1202 02:21:37.746826 27461 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:21:37.746850 27461 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:21:37.746860 27461 net.cpp:67] Creating Layer relu5_2
I1202 02:21:37.746865 27461 net.cpp:394] relu5_2 <- conv5_2
I1202 02:21:37.746871 27461 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:21:37.746877 27461 net.cpp:96] Setting up relu5_2
I1202 02:21:37.746883 27461 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:21:37.746886 27461 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:21:37.746892 27461 net.cpp:67] Creating Layer conv5_3
I1202 02:21:37.746896 27461 net.cpp:394] conv5_3 <- conv5_2
I1202 02:21:37.746902 27461 net.cpp:356] conv5_3 -> conv5_3
I1202 02:21:37.746908 27461 net.cpp:96] Setting up conv5_3
I1202 02:21:37.804913 27461 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:21:37.804939 27461 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:21:37.804947 27461 net.cpp:67] Creating Layer relu5_3
I1202 02:21:37.804952 27461 net.cpp:394] relu5_3 <- conv5_3
I1202 02:21:37.804960 27461 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:21:37.804966 27461 net.cpp:96] Setting up relu5_3
I1202 02:21:37.804972 27461 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:21:37.804985 27461 layer_factory.hpp:78] Creating layer pool5
I1202 02:21:37.804991 27461 net.cpp:67] Creating Layer pool5
I1202 02:21:37.804996 27461 net.cpp:394] pool5 <- conv5_3
I1202 02:21:37.804999 27461 net.cpp:356] pool5 -> pool5
I1202 02:21:37.805006 27461 net.cpp:96] Setting up pool5
I1202 02:21:37.805012 27461 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:21:37.805016 27461 layer_factory.hpp:78] Creating layer fc6
I1202 02:21:37.805029 27461 net.cpp:67] Creating Layer fc6
I1202 02:21:37.805032 27461 net.cpp:394] fc6 <- pool5
I1202 02:21:37.805037 27461 net.cpp:356] fc6 -> fc6
I1202 02:21:37.805042 27461 net.cpp:96] Setting up fc6
I1202 02:21:40.302660 27461 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:21:40.302690 27461 layer_factory.hpp:78] Creating layer relu6
I1202 02:21:40.302698 27461 net.cpp:67] Creating Layer relu6
I1202 02:21:40.302703 27461 net.cpp:394] relu6 <- fc6
I1202 02:21:40.302711 27461 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:21:40.302717 27461 net.cpp:96] Setting up relu6
I1202 02:21:40.302731 27461 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:21:40.302734 27461 layer_factory.hpp:78] Creating layer drop6
I1202 02:21:40.302742 27461 net.cpp:67] Creating Layer drop6
I1202 02:21:40.302744 27461 net.cpp:394] drop6 <- fc6
I1202 02:21:40.302750 27461 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:21:40.302755 27461 net.cpp:96] Setting up drop6
I1202 02:21:40.302759 27461 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:21:40.302762 27461 layer_factory.hpp:78] Creating layer fc7
I1202 02:21:40.302767 27461 net.cpp:67] Creating Layer fc7
I1202 02:21:40.302769 27461 net.cpp:394] fc7 <- fc6
I1202 02:21:40.302774 27461 net.cpp:356] fc7 -> fc7
I1202 02:21:40.302780 27461 net.cpp:96] Setting up fc7
I1202 02:21:40.711230 27461 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:21:40.711259 27461 layer_factory.hpp:78] Creating layer relu7
I1202 02:21:40.711267 27461 net.cpp:67] Creating Layer relu7
I1202 02:21:40.711272 27461 net.cpp:394] relu7 <- fc7
I1202 02:21:40.711282 27461 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:21:40.711287 27461 net.cpp:96] Setting up relu7
I1202 02:21:40.711302 27461 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:21:40.711304 27461 layer_factory.hpp:78] Creating layer drop7
I1202 02:21:40.711310 27461 net.cpp:67] Creating Layer drop7
I1202 02:21:40.711313 27461 net.cpp:394] drop7 <- fc7
I1202 02:21:40.711318 27461 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:21:40.711321 27461 net.cpp:96] Setting up drop7
I1202 02:21:40.711325 27461 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:21:40.711328 27461 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:21:40.711334 27461 net.cpp:67] Creating Layer fc8_2
I1202 02:21:40.711338 27461 net.cpp:394] fc8_2 <- fc7
I1202 02:21:40.711341 27461 net.cpp:356] fc8_2 -> fc8_2
I1202 02:21:40.711347 27461 net.cpp:96] Setting up fc8_2
I1202 02:21:40.711573 27461 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:21:40.711582 27461 layer_factory.hpp:78] Creating layer loss
I1202 02:21:40.711590 27461 net.cpp:67] Creating Layer loss
I1202 02:21:40.711592 27461 net.cpp:394] loss <- fc8_2
I1202 02:21:40.711596 27461 net.cpp:394] loss <- label
I1202 02:21:40.711606 27461 net.cpp:356] loss -> (automatic)
I1202 02:21:40.711611 27461 net.cpp:96] Setting up loss
I1202 02:21:40.711621 27461 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:21:40.711623 27461 net.cpp:109]     with loss weight 1
I1202 02:21:40.711658 27461 net.cpp:170] loss needs backward computation.
I1202 02:21:40.711662 27461 net.cpp:170] fc8_2 needs backward computation.
I1202 02:21:40.711664 27461 net.cpp:170] drop7 needs backward computation.
I1202 02:21:40.711666 27461 net.cpp:170] relu7 needs backward computation.
I1202 02:21:40.711669 27461 net.cpp:170] fc7 needs backward computation.
I1202 02:21:40.711671 27461 net.cpp:170] drop6 needs backward computation.
I1202 02:21:40.711674 27461 net.cpp:170] relu6 needs backward computation.
I1202 02:21:40.711678 27461 net.cpp:170] fc6 needs backward computation.
I1202 02:21:40.711688 27461 net.cpp:170] pool5 needs backward computation.
I1202 02:21:40.711691 27461 net.cpp:170] relu5_3 needs backward computation.
I1202 02:21:40.711694 27461 net.cpp:170] conv5_3 needs backward computation.
I1202 02:21:40.711701 27461 net.cpp:170] relu5_2 needs backward computation.
I1202 02:21:40.711704 27461 net.cpp:170] conv5_2 needs backward computation.
I1202 02:21:40.711707 27461 net.cpp:170] relu5_1 needs backward computation.
I1202 02:21:40.711709 27461 net.cpp:170] conv5_1 needs backward computation.
I1202 02:21:40.711712 27461 net.cpp:170] pool4 needs backward computation.
I1202 02:21:40.711715 27461 net.cpp:170] relu4_3 needs backward computation.
I1202 02:21:40.711719 27461 net.cpp:170] conv4_3 needs backward computation.
I1202 02:21:40.711721 27461 net.cpp:170] relu4_2 needs backward computation.
I1202 02:21:40.711724 27461 net.cpp:170] conv4_2 needs backward computation.
I1202 02:21:40.711727 27461 net.cpp:170] relu4_1 needs backward computation.
I1202 02:21:40.711730 27461 net.cpp:170] conv4_1 needs backward computation.
I1202 02:21:40.711732 27461 net.cpp:170] pool3 needs backward computation.
I1202 02:21:40.711735 27461 net.cpp:170] relu3_3 needs backward computation.
I1202 02:21:40.711738 27461 net.cpp:170] conv3_3 needs backward computation.
I1202 02:21:40.711740 27461 net.cpp:170] relu3_2 needs backward computation.
I1202 02:21:40.711743 27461 net.cpp:170] conv3_2 needs backward computation.
I1202 02:21:40.711746 27461 net.cpp:170] relu3_1 needs backward computation.
I1202 02:21:40.711748 27461 net.cpp:170] conv3_1 needs backward computation.
I1202 02:21:40.711751 27461 net.cpp:170] pool2 needs backward computation.
I1202 02:21:40.711755 27461 net.cpp:170] relu2_2 needs backward computation.
I1202 02:21:40.711757 27461 net.cpp:170] conv2_2 needs backward computation.
I1202 02:21:40.711760 27461 net.cpp:170] relu2_1 needs backward computation.
I1202 02:21:40.711762 27461 net.cpp:170] conv2_1 needs backward computation.
I1202 02:21:40.711766 27461 net.cpp:170] pool1 needs backward computation.
I1202 02:21:40.711768 27461 net.cpp:170] relu1_2 needs backward computation.
I1202 02:21:40.711771 27461 net.cpp:170] conv1_2 needs backward computation.
I1202 02:21:40.711773 27461 net.cpp:170] relu1_1 needs backward computation.
I1202 02:21:40.711776 27461 net.cpp:170] conv1_1 needs backward computation.
I1202 02:21:40.711778 27461 net.cpp:172] data does not need backward computation.
I1202 02:21:40.711797 27461 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:21:40.711805 27461 net.cpp:219] Network initialization done.
I1202 02:21:40.711807 27461 net.cpp:220] Memory required for data: 3686465924
I1202 02:21:40.712633 27461 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:21:40.712676 27461 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:21:40.712882 27461 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:21:40.713023 27461 layer_factory.hpp:78] Creating layer data
I1202 02:21:40.713033 27461 net.cpp:67] Creating Layer data
I1202 02:21:40.713037 27461 net.cpp:356] data -> data
I1202 02:21:40.713044 27461 net.cpp:356] data -> label
I1202 02:21:40.713050 27461 net.cpp:96] Setting up data
I1202 02:21:40.713054 27461 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:21:40.714588 27461 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:21:40.721724 27461 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:21:40.722589 27461 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:21:40.722599 27461 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:21:40.722602 27461 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:21:40.722615 27461 net.cpp:67] Creating Layer label_data_1_split
I1202 02:21:40.722620 27461 net.cpp:394] label_data_1_split <- label
I1202 02:21:40.722626 27461 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:21:40.722635 27461 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:21:40.722640 27461 net.cpp:96] Setting up label_data_1_split
I1202 02:21:40.722645 27461 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:21:40.722648 27461 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:21:40.722651 27461 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:21:40.722657 27461 net.cpp:67] Creating Layer conv1_1
I1202 02:21:40.722661 27461 net.cpp:394] conv1_1 <- data
I1202 02:21:40.722666 27461 net.cpp:356] conv1_1 -> conv1_1
I1202 02:21:40.722671 27461 net.cpp:96] Setting up conv1_1
I1202 02:21:40.722836 27461 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:21:40.722851 27461 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:21:40.722856 27461 net.cpp:67] Creating Layer relu1_1
I1202 02:21:40.722858 27461 net.cpp:394] relu1_1 <- conv1_1
I1202 02:21:40.722862 27461 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:21:40.722875 27461 net.cpp:96] Setting up relu1_1
I1202 02:21:40.722882 27461 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:21:40.722884 27461 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:21:40.722889 27461 net.cpp:67] Creating Layer conv1_2
I1202 02:21:40.722892 27461 net.cpp:394] conv1_2 <- conv1_1
I1202 02:21:40.722898 27461 net.cpp:356] conv1_2 -> conv1_2
I1202 02:21:40.722903 27461 net.cpp:96] Setting up conv1_2
I1202 02:21:40.723912 27461 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:21:40.723924 27461 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:21:40.723929 27461 net.cpp:67] Creating Layer relu1_2
I1202 02:21:40.723932 27461 net.cpp:394] relu1_2 <- conv1_2
I1202 02:21:40.723937 27461 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:21:40.723942 27461 net.cpp:96] Setting up relu1_2
I1202 02:21:40.723947 27461 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:21:40.723949 27461 layer_factory.hpp:78] Creating layer pool1
I1202 02:21:40.723954 27461 net.cpp:67] Creating Layer pool1
I1202 02:21:40.723958 27461 net.cpp:394] pool1 <- conv1_2
I1202 02:21:40.723961 27461 net.cpp:356] pool1 -> pool1
I1202 02:21:40.723966 27461 net.cpp:96] Setting up pool1
I1202 02:21:40.723973 27461 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:21:40.723975 27461 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:21:40.723980 27461 net.cpp:67] Creating Layer conv2_1
I1202 02:21:40.723984 27461 net.cpp:394] conv2_1 <- pool1
I1202 02:21:40.723989 27461 net.cpp:356] conv2_1 -> conv2_1
I1202 02:21:40.723992 27461 net.cpp:96] Setting up conv2_1
I1202 02:21:40.725993 27461 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:21:40.726006 27461 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:21:40.726012 27461 net.cpp:67] Creating Layer relu2_1
I1202 02:21:40.726016 27461 net.cpp:394] relu2_1 <- conv2_1
I1202 02:21:40.726019 27461 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:21:40.726024 27461 net.cpp:96] Setting up relu2_1
I1202 02:21:40.726029 27461 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:21:40.726032 27461 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:21:40.726037 27461 net.cpp:67] Creating Layer conv2_2
I1202 02:21:40.726039 27461 net.cpp:394] conv2_2 <- conv2_1
I1202 02:21:40.726044 27461 net.cpp:356] conv2_2 -> conv2_2
I1202 02:21:40.726050 27461 net.cpp:96] Setting up conv2_2
I1202 02:21:40.729706 27461 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:21:40.729715 27461 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:21:40.729720 27461 net.cpp:67] Creating Layer relu2_2
I1202 02:21:40.729723 27461 net.cpp:394] relu2_2 <- conv2_2
I1202 02:21:40.729728 27461 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:21:40.729732 27461 net.cpp:96] Setting up relu2_2
I1202 02:21:40.729737 27461 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:21:40.729740 27461 layer_factory.hpp:78] Creating layer pool2
I1202 02:21:40.729744 27461 net.cpp:67] Creating Layer pool2
I1202 02:21:40.729748 27461 net.cpp:394] pool2 <- conv2_2
I1202 02:21:40.729751 27461 net.cpp:356] pool2 -> pool2
I1202 02:21:40.729755 27461 net.cpp:96] Setting up pool2
I1202 02:21:40.729761 27461 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:21:40.729764 27461 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:21:40.729769 27461 net.cpp:67] Creating Layer conv3_1
I1202 02:21:40.729773 27461 net.cpp:394] conv3_1 <- pool2
I1202 02:21:40.729776 27461 net.cpp:356] conv3_1 -> conv3_1
I1202 02:21:40.729781 27461 net.cpp:96] Setting up conv3_1
I1202 02:21:40.737027 27461 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:21:40.737040 27461 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:21:40.737046 27461 net.cpp:67] Creating Layer relu3_1
I1202 02:21:40.737048 27461 net.cpp:394] relu3_1 <- conv3_1
I1202 02:21:40.737053 27461 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:21:40.737057 27461 net.cpp:96] Setting up relu3_1
I1202 02:21:40.737062 27461 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:21:40.737066 27461 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:21:40.737076 27461 net.cpp:67] Creating Layer conv3_2
I1202 02:21:40.737079 27461 net.cpp:394] conv3_2 <- conv3_1
I1202 02:21:40.737084 27461 net.cpp:356] conv3_2 -> conv3_2
I1202 02:21:40.737089 27461 net.cpp:96] Setting up conv3_2
I1202 02:21:40.751723 27461 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:21:40.751745 27461 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:21:40.751754 27461 net.cpp:67] Creating Layer relu3_2
I1202 02:21:40.751757 27461 net.cpp:394] relu3_2 <- conv3_2
I1202 02:21:40.751763 27461 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:21:40.751770 27461 net.cpp:96] Setting up relu3_2
I1202 02:21:40.751775 27461 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:21:40.751780 27461 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:21:40.751790 27461 net.cpp:67] Creating Layer conv3_3
I1202 02:21:40.751792 27461 net.cpp:394] conv3_3 <- conv3_2
I1202 02:21:40.751798 27461 net.cpp:356] conv3_3 -> conv3_3
I1202 02:21:40.751804 27461 net.cpp:96] Setting up conv3_3
I1202 02:21:40.766566 27461 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:21:40.766582 27461 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:21:40.766588 27461 net.cpp:67] Creating Layer relu3_3
I1202 02:21:40.766592 27461 net.cpp:394] relu3_3 <- conv3_3
I1202 02:21:40.766598 27461 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:21:40.766604 27461 net.cpp:96] Setting up relu3_3
I1202 02:21:40.766609 27461 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:21:40.766613 27461 layer_factory.hpp:78] Creating layer pool3
I1202 02:21:40.766618 27461 net.cpp:67] Creating Layer pool3
I1202 02:21:40.766620 27461 net.cpp:394] pool3 <- conv3_3
I1202 02:21:40.766625 27461 net.cpp:356] pool3 -> pool3
I1202 02:21:40.766630 27461 net.cpp:96] Setting up pool3
I1202 02:21:40.766638 27461 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:21:40.766640 27461 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:21:40.766646 27461 net.cpp:67] Creating Layer conv4_1
I1202 02:21:40.766649 27461 net.cpp:394] conv4_1 <- pool3
I1202 02:21:40.766655 27461 net.cpp:356] conv4_1 -> conv4_1
I1202 02:21:40.766660 27461 net.cpp:96] Setting up conv4_1
I1202 02:21:40.795963 27461 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:21:40.795986 27461 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:21:40.795994 27461 net.cpp:67] Creating Layer relu4_1
I1202 02:21:40.796000 27461 net.cpp:394] relu4_1 <- conv4_1
I1202 02:21:40.796006 27461 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:21:40.796013 27461 net.cpp:96] Setting up relu4_1
I1202 02:21:40.796020 27461 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:21:40.796022 27461 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:21:40.796028 27461 net.cpp:67] Creating Layer conv4_2
I1202 02:21:40.796031 27461 net.cpp:394] conv4_2 <- conv4_1
I1202 02:21:40.796036 27461 net.cpp:356] conv4_2 -> conv4_2
I1202 02:21:40.796041 27461 net.cpp:96] Setting up conv4_2
I1202 02:21:40.853832 27461 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:21:40.853865 27461 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:21:40.853873 27461 net.cpp:67] Creating Layer relu4_2
I1202 02:21:40.853878 27461 net.cpp:394] relu4_2 <- conv4_2
I1202 02:21:40.853884 27461 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:21:40.853890 27461 net.cpp:96] Setting up relu4_2
I1202 02:21:40.853896 27461 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:21:40.853899 27461 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:21:40.853906 27461 net.cpp:67] Creating Layer conv4_3
I1202 02:21:40.853910 27461 net.cpp:394] conv4_3 <- conv4_2
I1202 02:21:40.853914 27461 net.cpp:356] conv4_3 -> conv4_3
I1202 02:21:40.853924 27461 net.cpp:96] Setting up conv4_3
I1202 02:21:40.911792 27461 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:21:40.911816 27461 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:21:40.911824 27461 net.cpp:67] Creating Layer relu4_3
I1202 02:21:40.911828 27461 net.cpp:394] relu4_3 <- conv4_3
I1202 02:21:40.911835 27461 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:21:40.911851 27461 net.cpp:96] Setting up relu4_3
I1202 02:21:40.911857 27461 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:21:40.911860 27461 layer_factory.hpp:78] Creating layer pool4
I1202 02:21:40.911869 27461 net.cpp:67] Creating Layer pool4
I1202 02:21:40.911871 27461 net.cpp:394] pool4 <- conv4_3
I1202 02:21:40.911876 27461 net.cpp:356] pool4 -> pool4
I1202 02:21:40.911882 27461 net.cpp:96] Setting up pool4
I1202 02:21:40.911890 27461 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:21:40.911892 27461 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:21:40.911900 27461 net.cpp:67] Creating Layer conv5_1
I1202 02:21:40.911903 27461 net.cpp:394] conv5_1 <- pool4
I1202 02:21:40.911908 27461 net.cpp:356] conv5_1 -> conv5_1
I1202 02:21:40.911913 27461 net.cpp:96] Setting up conv5_1
I1202 02:21:40.969518 27461 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:21:40.969543 27461 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:21:40.969550 27461 net.cpp:67] Creating Layer relu5_1
I1202 02:21:40.969555 27461 net.cpp:394] relu5_1 <- conv5_1
I1202 02:21:40.969562 27461 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:21:40.969568 27461 net.cpp:96] Setting up relu5_1
I1202 02:21:40.969573 27461 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:21:40.969575 27461 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:21:40.969588 27461 net.cpp:67] Creating Layer conv5_2
I1202 02:21:40.969591 27461 net.cpp:394] conv5_2 <- conv5_1
I1202 02:21:40.969598 27461 net.cpp:356] conv5_2 -> conv5_2
I1202 02:21:40.969604 27461 net.cpp:96] Setting up conv5_2
I1202 02:21:41.027433 27461 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:21:41.027464 27461 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:21:41.027474 27461 net.cpp:67] Creating Layer relu5_2
I1202 02:21:41.027478 27461 net.cpp:394] relu5_2 <- conv5_2
I1202 02:21:41.027485 27461 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:21:41.027492 27461 net.cpp:96] Setting up relu5_2
I1202 02:21:41.027497 27461 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:21:41.027499 27461 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:21:41.027506 27461 net.cpp:67] Creating Layer conv5_3
I1202 02:21:41.027509 27461 net.cpp:394] conv5_3 <- conv5_2
I1202 02:21:41.027514 27461 net.cpp:356] conv5_3 -> conv5_3
I1202 02:21:41.027520 27461 net.cpp:96] Setting up conv5_3
I1202 02:21:41.085259 27461 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:21:41.085285 27461 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:21:41.085295 27461 net.cpp:67] Creating Layer relu5_3
I1202 02:21:41.085299 27461 net.cpp:394] relu5_3 <- conv5_3
I1202 02:21:41.085306 27461 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:21:41.085314 27461 net.cpp:96] Setting up relu5_3
I1202 02:21:41.085319 27461 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:21:41.085322 27461 layer_factory.hpp:78] Creating layer pool5
I1202 02:21:41.085332 27461 net.cpp:67] Creating Layer pool5
I1202 02:21:41.085335 27461 net.cpp:394] pool5 <- conv5_3
I1202 02:21:41.085340 27461 net.cpp:356] pool5 -> pool5
I1202 02:21:41.085345 27461 net.cpp:96] Setting up pool5
I1202 02:21:41.085352 27461 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:21:41.085356 27461 layer_factory.hpp:78] Creating layer fc6
I1202 02:21:41.085363 27461 net.cpp:67] Creating Layer fc6
I1202 02:21:41.085366 27461 net.cpp:394] fc6 <- pool5
I1202 02:21:41.085371 27461 net.cpp:356] fc6 -> fc6
I1202 02:21:41.085376 27461 net.cpp:96] Setting up fc6
I1202 02:21:43.584095 27461 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:21:43.584121 27461 layer_factory.hpp:78] Creating layer relu6
I1202 02:21:43.584130 27461 net.cpp:67] Creating Layer relu6
I1202 02:21:43.584134 27461 net.cpp:394] relu6 <- fc6
I1202 02:21:43.584141 27461 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:21:43.584148 27461 net.cpp:96] Setting up relu6
I1202 02:21:43.584162 27461 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:21:43.584166 27461 layer_factory.hpp:78] Creating layer drop6
I1202 02:21:43.584182 27461 net.cpp:67] Creating Layer drop6
I1202 02:21:43.584184 27461 net.cpp:394] drop6 <- fc6
I1202 02:21:43.584190 27461 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:21:43.584195 27461 net.cpp:96] Setting up drop6
I1202 02:21:43.584198 27461 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:21:43.584202 27461 layer_factory.hpp:78] Creating layer fc7
I1202 02:21:43.584206 27461 net.cpp:67] Creating Layer fc7
I1202 02:21:43.584209 27461 net.cpp:394] fc7 <- fc6
I1202 02:21:43.584214 27461 net.cpp:356] fc7 -> fc7
I1202 02:21:43.584220 27461 net.cpp:96] Setting up fc7
I1202 02:21:43.992770 27461 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:21:43.992797 27461 layer_factory.hpp:78] Creating layer relu7
I1202 02:21:43.992805 27461 net.cpp:67] Creating Layer relu7
I1202 02:21:43.992810 27461 net.cpp:394] relu7 <- fc7
I1202 02:21:43.992818 27461 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:21:43.992825 27461 net.cpp:96] Setting up relu7
I1202 02:21:43.992840 27461 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:21:43.992842 27461 layer_factory.hpp:78] Creating layer drop7
I1202 02:21:43.992847 27461 net.cpp:67] Creating Layer drop7
I1202 02:21:43.992851 27461 net.cpp:394] drop7 <- fc7
I1202 02:21:43.992854 27461 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:21:43.992859 27461 net.cpp:96] Setting up drop7
I1202 02:21:43.992862 27461 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:21:43.992866 27461 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:21:43.992872 27461 net.cpp:67] Creating Layer fc8_2
I1202 02:21:43.992876 27461 net.cpp:394] fc8_2 <- fc7
I1202 02:21:43.992879 27461 net.cpp:356] fc8_2 -> fc8_2
I1202 02:21:43.992887 27461 net.cpp:96] Setting up fc8_2
I1202 02:21:43.993110 27461 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:21:43.993119 27461 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:21:43.993124 27461 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:21:43.993127 27461 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:21:43.993132 27461 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:21:43.993137 27461 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:21:43.993144 27461 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:21:43.993147 27461 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:21:43.993149 27461 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:21:43.993152 27461 layer_factory.hpp:78] Creating layer loss
I1202 02:21:43.993158 27461 net.cpp:67] Creating Layer loss
I1202 02:21:43.993161 27461 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:21:43.993165 27461 net.cpp:394] loss <- label_data_1_split_0
I1202 02:21:43.993170 27461 net.cpp:356] loss -> (automatic)
I1202 02:21:43.993175 27461 net.cpp:96] Setting up loss
I1202 02:21:43.993185 27461 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:21:43.993188 27461 net.cpp:109]     with loss weight 1
I1202 02:21:43.993202 27461 layer_factory.hpp:78] Creating layer accuracy
I1202 02:21:43.993209 27461 net.cpp:67] Creating Layer accuracy
I1202 02:21:43.993212 27461 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:21:43.993216 27461 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:21:43.993222 27461 net.cpp:356] accuracy -> accuracy
I1202 02:21:43.993232 27461 net.cpp:96] Setting up accuracy
I1202 02:21:43.993242 27461 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:21:43.993247 27461 net.cpp:172] accuracy does not need backward computation.
I1202 02:21:43.993249 27461 net.cpp:170] loss needs backward computation.
I1202 02:21:43.993252 27461 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:21:43.993255 27461 net.cpp:170] fc8_2 needs backward computation.
I1202 02:21:43.993258 27461 net.cpp:170] drop7 needs backward computation.
I1202 02:21:43.993262 27461 net.cpp:170] relu7 needs backward computation.
I1202 02:21:43.993263 27461 net.cpp:170] fc7 needs backward computation.
I1202 02:21:43.993266 27461 net.cpp:170] drop6 needs backward computation.
I1202 02:21:43.993268 27461 net.cpp:170] relu6 needs backward computation.
I1202 02:21:43.993278 27461 net.cpp:170] fc6 needs backward computation.
I1202 02:21:43.993281 27461 net.cpp:170] pool5 needs backward computation.
I1202 02:21:43.993284 27461 net.cpp:170] relu5_3 needs backward computation.
I1202 02:21:43.993288 27461 net.cpp:170] conv5_3 needs backward computation.
I1202 02:21:43.993290 27461 net.cpp:170] relu5_2 needs backward computation.
I1202 02:21:43.993294 27461 net.cpp:170] conv5_2 needs backward computation.
I1202 02:21:43.993296 27461 net.cpp:170] relu5_1 needs backward computation.
I1202 02:21:43.993299 27461 net.cpp:170] conv5_1 needs backward computation.
I1202 02:21:43.993302 27461 net.cpp:170] pool4 needs backward computation.
I1202 02:21:43.993305 27461 net.cpp:170] relu4_3 needs backward computation.
I1202 02:21:43.993307 27461 net.cpp:170] conv4_3 needs backward computation.
I1202 02:21:43.993310 27461 net.cpp:170] relu4_2 needs backward computation.
I1202 02:21:43.993314 27461 net.cpp:170] conv4_2 needs backward computation.
I1202 02:21:43.993316 27461 net.cpp:170] relu4_1 needs backward computation.
I1202 02:21:43.993319 27461 net.cpp:170] conv4_1 needs backward computation.
I1202 02:21:43.993321 27461 net.cpp:170] pool3 needs backward computation.
I1202 02:21:43.993324 27461 net.cpp:170] relu3_3 needs backward computation.
I1202 02:21:43.993326 27461 net.cpp:170] conv3_3 needs backward computation.
I1202 02:21:43.993330 27461 net.cpp:170] relu3_2 needs backward computation.
I1202 02:21:43.993332 27461 net.cpp:170] conv3_2 needs backward computation.
I1202 02:21:43.993335 27461 net.cpp:170] relu3_1 needs backward computation.
I1202 02:21:43.993337 27461 net.cpp:170] conv3_1 needs backward computation.
I1202 02:21:43.993340 27461 net.cpp:170] pool2 needs backward computation.
I1202 02:21:43.993343 27461 net.cpp:170] relu2_2 needs backward computation.
I1202 02:21:43.993345 27461 net.cpp:170] conv2_2 needs backward computation.
I1202 02:21:43.993348 27461 net.cpp:170] relu2_1 needs backward computation.
I1202 02:21:43.993351 27461 net.cpp:170] conv2_1 needs backward computation.
I1202 02:21:43.993355 27461 net.cpp:170] pool1 needs backward computation.
I1202 02:21:43.993356 27461 net.cpp:170] relu1_2 needs backward computation.
I1202 02:21:43.993360 27461 net.cpp:170] conv1_2 needs backward computation.
I1202 02:21:43.993362 27461 net.cpp:170] relu1_1 needs backward computation.
I1202 02:21:43.993365 27461 net.cpp:170] conv1_1 needs backward computation.
I1202 02:21:43.993367 27461 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:21:43.993371 27461 net.cpp:172] data does not need backward computation.
I1202 02:21:43.993372 27461 net.cpp:208] This network produces output accuracy
I1202 02:21:43.993392 27461 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:21:43.993401 27461 net.cpp:219] Network initialization done.
I1202 02:21:43.993403 27461 net.cpp:220] Memory required for data: 921616692
I1202 02:21:43.993502 27461 solver.cpp:41] Solver scaffolding done.
I1202 02:21:43.993509 27461 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_16000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:21:47.356858 27461 solver.cpp:160] Solving small
I1202 02:21:47.356884 27461 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:21:47.356931 27461 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:23:11.725844 27461 solver.cpp:305] Test loss: 0.427272
I1202 02:23:11.725926 27461 solver.cpp:318] mean_score = test_score[0] { = 3099} / test_score[1] { = 3570 }
I1202 02:23:11.725935 27461 solver.cpp:319]            = 0.868067
I1202 02:23:11.725944 27461 solver.cpp:328]     Test net output #0: accuracy = 0.868067
I1202 02:23:11.725949 27461 solver.cpp:318] mean_score = test_score[2] { = 221} / test_score[3] { = 398 }
I1202 02:23:11.725953 27461 solver.cpp:319]            = 0.555276
I1202 02:23:11.725960 27461 solver.cpp:328]     Test net output #1: accuracy = 0.555276
I1202 02:23:11.725970 27461 solver.cpp:332]     Test net output #2: accuracy = 0.836694
I1202 02:23:11.725975 27461 solver.cpp:334]     Test net output #3: accuracy = 0.711672
I1202 02:23:12.421725 27461 solver.cpp:209] Iteration 0, loss = 0.101684
I1202 02:23:12.421753 27461 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:23:14.762373 27461 solver.cpp:209] Iteration 1, loss = 0.249323
I1202 02:23:14.762403 27461 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:23:16.760035 27461 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:23:20.694792 27461 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:23:25.241274 27461 solver.cpp:246] Iteration 2, loss = 0.245311
I1202 02:23:25.241310 27461 solver.cpp:251] Optimization Done.
I1202 02:23:25.241317 27461 caffe.cpp:121] Optimization Done.
I1202 02:23:25.376495 28007 caffe.cpp:99] Use GPU with device ID 0
I1202 02:23:25.555706 28007 caffe.cpp:107] Starting Optimization
I1202 02:23:25.555804 28007 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:23:25.555826 28007 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:23:25.556632 28007 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:23:25.556663 28007 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:23:25.556852 28007 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:23:25.556977 28007 layer_factory.hpp:78] Creating layer data
I1202 02:23:25.556999 28007 net.cpp:67] Creating Layer data
I1202 02:23:25.557005 28007 net.cpp:356] data -> data
I1202 02:23:25.557024 28007 net.cpp:356] data -> label
I1202 02:23:25.557032 28007 net.cpp:96] Setting up data
I1202 02:23:25.557037 28007 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:23:25.572125 28007 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:23:25.582846 28007 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:23:25.585701 28007 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:23:25.585727 28007 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:23:25.585733 28007 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:23:25.585749 28007 net.cpp:67] Creating Layer conv1_1
I1202 02:23:25.585754 28007 net.cpp:394] conv1_1 <- data
I1202 02:23:25.585767 28007 net.cpp:356] conv1_1 -> conv1_1
I1202 02:23:25.585777 28007 net.cpp:96] Setting up conv1_1
I1202 02:23:25.730624 28007 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:23:25.730659 28007 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:23:25.730669 28007 net.cpp:67] Creating Layer relu1_1
I1202 02:23:25.730674 28007 net.cpp:394] relu1_1 <- conv1_1
I1202 02:23:25.730681 28007 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:23:25.730689 28007 net.cpp:96] Setting up relu1_1
I1202 02:23:25.730698 28007 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:23:25.730701 28007 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:23:25.730710 28007 net.cpp:67] Creating Layer conv1_2
I1202 02:23:25.730712 28007 net.cpp:394] conv1_2 <- conv1_1
I1202 02:23:25.730716 28007 net.cpp:356] conv1_2 -> conv1_2
I1202 02:23:25.730723 28007 net.cpp:96] Setting up conv1_2
I1202 02:23:25.731858 28007 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:23:25.731873 28007 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:23:25.731878 28007 net.cpp:67] Creating Layer relu1_2
I1202 02:23:25.731881 28007 net.cpp:394] relu1_2 <- conv1_2
I1202 02:23:25.731886 28007 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:23:25.731890 28007 net.cpp:96] Setting up relu1_2
I1202 02:23:25.731896 28007 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:23:25.731900 28007 layer_factory.hpp:78] Creating layer pool1
I1202 02:23:25.731909 28007 net.cpp:67] Creating Layer pool1
I1202 02:23:25.731912 28007 net.cpp:394] pool1 <- conv1_2
I1202 02:23:25.731916 28007 net.cpp:356] pool1 -> pool1
I1202 02:23:25.731922 28007 net.cpp:96] Setting up pool1
I1202 02:23:25.731940 28007 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:23:25.731943 28007 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:23:25.731950 28007 net.cpp:67] Creating Layer conv2_1
I1202 02:23:25.731953 28007 net.cpp:394] conv2_1 <- pool1
I1202 02:23:25.731957 28007 net.cpp:356] conv2_1 -> conv2_1
I1202 02:23:25.731963 28007 net.cpp:96] Setting up conv2_1
I1202 02:23:25.733875 28007 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:23:25.733889 28007 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:23:25.733894 28007 net.cpp:67] Creating Layer relu2_1
I1202 02:23:25.733898 28007 net.cpp:394] relu2_1 <- conv2_1
I1202 02:23:25.733902 28007 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:23:25.733906 28007 net.cpp:96] Setting up relu2_1
I1202 02:23:25.733912 28007 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:23:25.733916 28007 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:23:25.733922 28007 net.cpp:67] Creating Layer conv2_2
I1202 02:23:25.733925 28007 net.cpp:394] conv2_2 <- conv2_1
I1202 02:23:25.733930 28007 net.cpp:356] conv2_2 -> conv2_2
I1202 02:23:25.733935 28007 net.cpp:96] Setting up conv2_2
I1202 02:23:25.737699 28007 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:23:25.737712 28007 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:23:25.737717 28007 net.cpp:67] Creating Layer relu2_2
I1202 02:23:25.737721 28007 net.cpp:394] relu2_2 <- conv2_2
I1202 02:23:25.737725 28007 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:23:25.737730 28007 net.cpp:96] Setting up relu2_2
I1202 02:23:25.737735 28007 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:23:25.737746 28007 layer_factory.hpp:78] Creating layer pool2
I1202 02:23:25.737751 28007 net.cpp:67] Creating Layer pool2
I1202 02:23:25.737754 28007 net.cpp:394] pool2 <- conv2_2
I1202 02:23:25.737761 28007 net.cpp:356] pool2 -> pool2
I1202 02:23:25.737766 28007 net.cpp:96] Setting up pool2
I1202 02:23:25.737771 28007 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:23:25.737774 28007 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:23:25.737781 28007 net.cpp:67] Creating Layer conv3_1
I1202 02:23:25.737784 28007 net.cpp:394] conv3_1 <- pool2
I1202 02:23:25.737788 28007 net.cpp:356] conv3_1 -> conv3_1
I1202 02:23:25.737794 28007 net.cpp:96] Setting up conv3_1
I1202 02:23:25.745196 28007 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:23:25.745213 28007 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:23:25.745218 28007 net.cpp:67] Creating Layer relu3_1
I1202 02:23:25.745221 28007 net.cpp:394] relu3_1 <- conv3_1
I1202 02:23:25.745225 28007 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:23:25.745230 28007 net.cpp:96] Setting up relu3_1
I1202 02:23:25.745236 28007 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:23:25.745239 28007 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:23:25.745244 28007 net.cpp:67] Creating Layer conv3_2
I1202 02:23:25.745247 28007 net.cpp:394] conv3_2 <- conv3_1
I1202 02:23:25.745254 28007 net.cpp:356] conv3_2 -> conv3_2
I1202 02:23:25.745259 28007 net.cpp:96] Setting up conv3_2
I1202 02:23:25.760208 28007 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:23:25.760231 28007 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:23:25.760241 28007 net.cpp:67] Creating Layer relu3_2
I1202 02:23:25.760246 28007 net.cpp:394] relu3_2 <- conv3_2
I1202 02:23:25.760253 28007 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:23:25.760259 28007 net.cpp:96] Setting up relu3_2
I1202 02:23:25.760265 28007 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:23:25.760268 28007 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:23:25.760277 28007 net.cpp:67] Creating Layer conv3_3
I1202 02:23:25.760284 28007 net.cpp:394] conv3_3 <- conv3_2
I1202 02:23:25.760293 28007 net.cpp:356] conv3_3 -> conv3_3
I1202 02:23:25.760304 28007 net.cpp:96] Setting up conv3_3
I1202 02:23:25.775077 28007 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:23:25.775096 28007 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:23:25.775111 28007 net.cpp:67] Creating Layer relu3_3
I1202 02:23:25.775117 28007 net.cpp:394] relu3_3 <- conv3_3
I1202 02:23:25.775127 28007 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:23:25.775136 28007 net.cpp:96] Setting up relu3_3
I1202 02:23:25.775146 28007 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:23:25.775152 28007 layer_factory.hpp:78] Creating layer pool3
I1202 02:23:25.775164 28007 net.cpp:67] Creating Layer pool3
I1202 02:23:25.775171 28007 net.cpp:394] pool3 <- conv3_3
I1202 02:23:25.775180 28007 net.cpp:356] pool3 -> pool3
I1202 02:23:25.775194 28007 net.cpp:96] Setting up pool3
I1202 02:23:25.775219 28007 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:23:25.775228 28007 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:23:25.775238 28007 net.cpp:67] Creating Layer conv4_1
I1202 02:23:25.775245 28007 net.cpp:394] conv4_1 <- pool3
I1202 02:23:25.775261 28007 net.cpp:356] conv4_1 -> conv4_1
I1202 02:23:25.775274 28007 net.cpp:96] Setting up conv4_1
I1202 02:23:25.804354 28007 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:23:25.804383 28007 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:23:25.804394 28007 net.cpp:67] Creating Layer relu4_1
I1202 02:23:25.804400 28007 net.cpp:394] relu4_1 <- conv4_1
I1202 02:23:25.804414 28007 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:23:25.804425 28007 net.cpp:96] Setting up relu4_1
I1202 02:23:25.804435 28007 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:23:25.804441 28007 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:23:25.804451 28007 net.cpp:67] Creating Layer conv4_2
I1202 02:23:25.804457 28007 net.cpp:394] conv4_2 <- conv4_1
I1202 02:23:25.804483 28007 net.cpp:356] conv4_2 -> conv4_2
I1202 02:23:25.804497 28007 net.cpp:96] Setting up conv4_2
I1202 02:23:25.862344 28007 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:23:25.862377 28007 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:23:25.862390 28007 net.cpp:67] Creating Layer relu4_2
I1202 02:23:25.862397 28007 net.cpp:394] relu4_2 <- conv4_2
I1202 02:23:25.862408 28007 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:23:25.862419 28007 net.cpp:96] Setting up relu4_2
I1202 02:23:25.862428 28007 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:23:25.862435 28007 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:23:25.862448 28007 net.cpp:67] Creating Layer conv4_3
I1202 02:23:25.862458 28007 net.cpp:394] conv4_3 <- conv4_2
I1202 02:23:25.862468 28007 net.cpp:356] conv4_3 -> conv4_3
I1202 02:23:25.862479 28007 net.cpp:96] Setting up conv4_3
I1202 02:23:25.920212 28007 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:23:25.920238 28007 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:23:25.920249 28007 net.cpp:67] Creating Layer relu4_3
I1202 02:23:25.920256 28007 net.cpp:394] relu4_3 <- conv4_3
I1202 02:23:25.920269 28007 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:23:25.920279 28007 net.cpp:96] Setting up relu4_3
I1202 02:23:25.920290 28007 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:23:25.920297 28007 layer_factory.hpp:78] Creating layer pool4
I1202 02:23:25.920306 28007 net.cpp:67] Creating Layer pool4
I1202 02:23:25.920311 28007 net.cpp:394] pool4 <- conv4_3
I1202 02:23:25.920321 28007 net.cpp:356] pool4 -> pool4
I1202 02:23:25.920331 28007 net.cpp:96] Setting up pool4
I1202 02:23:25.920343 28007 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:23:25.920356 28007 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:23:25.920370 28007 net.cpp:67] Creating Layer conv5_1
I1202 02:23:25.920389 28007 net.cpp:394] conv5_1 <- pool4
I1202 02:23:25.920403 28007 net.cpp:356] conv5_1 -> conv5_1
I1202 02:23:25.920421 28007 net.cpp:96] Setting up conv5_1
I1202 02:23:25.978498 28007 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:23:25.978528 28007 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:23:25.978539 28007 net.cpp:67] Creating Layer relu5_1
I1202 02:23:25.978546 28007 net.cpp:394] relu5_1 <- conv5_1
I1202 02:23:25.978562 28007 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:23:25.978574 28007 net.cpp:96] Setting up relu5_1
I1202 02:23:25.978585 28007 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:23:25.978592 28007 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:23:25.978603 28007 net.cpp:67] Creating Layer conv5_2
I1202 02:23:25.978615 28007 net.cpp:394] conv5_2 <- conv5_1
I1202 02:23:25.978628 28007 net.cpp:356] conv5_2 -> conv5_2
I1202 02:23:25.978642 28007 net.cpp:96] Setting up conv5_2
I1202 02:23:26.036675 28007 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:23:26.036706 28007 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:23:26.036718 28007 net.cpp:67] Creating Layer relu5_2
I1202 02:23:26.036725 28007 net.cpp:394] relu5_2 <- conv5_2
I1202 02:23:26.036736 28007 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:23:26.036751 28007 net.cpp:96] Setting up relu5_2
I1202 02:23:26.036761 28007 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:23:26.036770 28007 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:23:26.036782 28007 net.cpp:67] Creating Layer conv5_3
I1202 02:23:26.036794 28007 net.cpp:394] conv5_3 <- conv5_2
I1202 02:23:26.036808 28007 net.cpp:356] conv5_3 -> conv5_3
I1202 02:23:26.036821 28007 net.cpp:96] Setting up conv5_3
I1202 02:23:26.094769 28007 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:23:26.094799 28007 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:23:26.094810 28007 net.cpp:67] Creating Layer relu5_3
I1202 02:23:26.094817 28007 net.cpp:394] relu5_3 <- conv5_3
I1202 02:23:26.094830 28007 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:23:26.094841 28007 net.cpp:96] Setting up relu5_3
I1202 02:23:26.094851 28007 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:23:26.094869 28007 layer_factory.hpp:78] Creating layer pool5
I1202 02:23:26.094880 28007 net.cpp:67] Creating Layer pool5
I1202 02:23:26.094887 28007 net.cpp:394] pool5 <- conv5_3
I1202 02:23:26.094897 28007 net.cpp:356] pool5 -> pool5
I1202 02:23:26.094913 28007 net.cpp:96] Setting up pool5
I1202 02:23:26.094930 28007 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:23:26.094939 28007 layer_factory.hpp:78] Creating layer fc6
I1202 02:23:26.094969 28007 net.cpp:67] Creating Layer fc6
I1202 02:23:26.094979 28007 net.cpp:394] fc6 <- pool5
I1202 02:23:26.094990 28007 net.cpp:356] fc6 -> fc6
I1202 02:23:26.095008 28007 net.cpp:96] Setting up fc6
I1202 02:23:28.600041 28007 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:23:28.600074 28007 layer_factory.hpp:78] Creating layer relu6
I1202 02:23:28.600087 28007 net.cpp:67] Creating Layer relu6
I1202 02:23:28.600095 28007 net.cpp:394] relu6 <- fc6
I1202 02:23:28.600106 28007 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:23:28.600116 28007 net.cpp:96] Setting up relu6
I1202 02:23:28.600136 28007 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:23:28.600145 28007 layer_factory.hpp:78] Creating layer drop6
I1202 02:23:28.600157 28007 net.cpp:67] Creating Layer drop6
I1202 02:23:28.600167 28007 net.cpp:394] drop6 <- fc6
I1202 02:23:28.600174 28007 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:23:28.600183 28007 net.cpp:96] Setting up drop6
I1202 02:23:28.600189 28007 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:23:28.600195 28007 layer_factory.hpp:78] Creating layer fc7
I1202 02:23:28.600220 28007 net.cpp:67] Creating Layer fc7
I1202 02:23:28.600229 28007 net.cpp:394] fc7 <- fc6
I1202 02:23:28.600239 28007 net.cpp:356] fc7 -> fc7
I1202 02:23:28.600249 28007 net.cpp:96] Setting up fc7
I1202 02:23:29.008844 28007 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:23:29.008877 28007 layer_factory.hpp:78] Creating layer relu7
I1202 02:23:29.008888 28007 net.cpp:67] Creating Layer relu7
I1202 02:23:29.008895 28007 net.cpp:394] relu7 <- fc7
I1202 02:23:29.008905 28007 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:23:29.008916 28007 net.cpp:96] Setting up relu7
I1202 02:23:29.008935 28007 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:23:29.008944 28007 layer_factory.hpp:78] Creating layer drop7
I1202 02:23:29.008954 28007 net.cpp:67] Creating Layer drop7
I1202 02:23:29.008960 28007 net.cpp:394] drop7 <- fc7
I1202 02:23:29.008975 28007 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:23:29.008994 28007 net.cpp:96] Setting up drop7
I1202 02:23:29.009002 28007 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:23:29.009008 28007 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:23:29.009018 28007 net.cpp:67] Creating Layer fc8_2
I1202 02:23:29.009023 28007 net.cpp:394] fc8_2 <- fc7
I1202 02:23:29.009042 28007 net.cpp:356] fc8_2 -> fc8_2
I1202 02:23:29.009055 28007 net.cpp:96] Setting up fc8_2
I1202 02:23:29.009290 28007 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:23:29.009302 28007 layer_factory.hpp:78] Creating layer loss
I1202 02:23:29.009315 28007 net.cpp:67] Creating Layer loss
I1202 02:23:29.009321 28007 net.cpp:394] loss <- fc8_2
I1202 02:23:29.009328 28007 net.cpp:394] loss <- label
I1202 02:23:29.009342 28007 net.cpp:356] loss -> (automatic)
I1202 02:23:29.009352 28007 net.cpp:96] Setting up loss
I1202 02:23:29.009367 28007 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:23:29.009376 28007 net.cpp:109]     with loss weight 1
I1202 02:23:29.009412 28007 net.cpp:170] loss needs backward computation.
I1202 02:23:29.009418 28007 net.cpp:170] fc8_2 needs backward computation.
I1202 02:23:29.009423 28007 net.cpp:170] drop7 needs backward computation.
I1202 02:23:29.009433 28007 net.cpp:170] relu7 needs backward computation.
I1202 02:23:29.009438 28007 net.cpp:170] fc7 needs backward computation.
I1202 02:23:29.009443 28007 net.cpp:170] drop6 needs backward computation.
I1202 02:23:29.009449 28007 net.cpp:170] relu6 needs backward computation.
I1202 02:23:29.009454 28007 net.cpp:170] fc6 needs backward computation.
I1202 02:23:29.009469 28007 net.cpp:170] pool5 needs backward computation.
I1202 02:23:29.009476 28007 net.cpp:170] relu5_3 needs backward computation.
I1202 02:23:29.009481 28007 net.cpp:170] conv5_3 needs backward computation.
I1202 02:23:29.009487 28007 net.cpp:170] relu5_2 needs backward computation.
I1202 02:23:29.009493 28007 net.cpp:170] conv5_2 needs backward computation.
I1202 02:23:29.009500 28007 net.cpp:170] relu5_1 needs backward computation.
I1202 02:23:29.009505 28007 net.cpp:170] conv5_1 needs backward computation.
I1202 02:23:29.009510 28007 net.cpp:170] pool4 needs backward computation.
I1202 02:23:29.009516 28007 net.cpp:170] relu4_3 needs backward computation.
I1202 02:23:29.009522 28007 net.cpp:170] conv4_3 needs backward computation.
I1202 02:23:29.009527 28007 net.cpp:170] relu4_2 needs backward computation.
I1202 02:23:29.009583 28007 net.cpp:170] conv4_2 needs backward computation.
I1202 02:23:29.009605 28007 net.cpp:170] relu4_1 needs backward computation.
I1202 02:23:29.009613 28007 net.cpp:170] conv4_1 needs backward computation.
I1202 02:23:29.009618 28007 net.cpp:170] pool3 needs backward computation.
I1202 02:23:29.009624 28007 net.cpp:170] relu3_3 needs backward computation.
I1202 02:23:29.009629 28007 net.cpp:170] conv3_3 needs backward computation.
I1202 02:23:29.009635 28007 net.cpp:170] relu3_2 needs backward computation.
I1202 02:23:29.009646 28007 net.cpp:170] conv3_2 needs backward computation.
I1202 02:23:29.009652 28007 net.cpp:170] relu3_1 needs backward computation.
I1202 02:23:29.009657 28007 net.cpp:170] conv3_1 needs backward computation.
I1202 02:23:29.009663 28007 net.cpp:170] pool2 needs backward computation.
I1202 02:23:29.009670 28007 net.cpp:170] relu2_2 needs backward computation.
I1202 02:23:29.009675 28007 net.cpp:170] conv2_2 needs backward computation.
I1202 02:23:29.009680 28007 net.cpp:170] relu2_1 needs backward computation.
I1202 02:23:29.009686 28007 net.cpp:170] conv2_1 needs backward computation.
I1202 02:23:29.009698 28007 net.cpp:170] pool1 needs backward computation.
I1202 02:23:29.009704 28007 net.cpp:170] relu1_2 needs backward computation.
I1202 02:23:29.009709 28007 net.cpp:170] conv1_2 needs backward computation.
I1202 02:23:29.009716 28007 net.cpp:170] relu1_1 needs backward computation.
I1202 02:23:29.009721 28007 net.cpp:170] conv1_1 needs backward computation.
I1202 02:23:29.009727 28007 net.cpp:172] data does not need backward computation.
I1202 02:23:29.009755 28007 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:23:29.009768 28007 net.cpp:219] Network initialization done.
I1202 02:23:29.009774 28007 net.cpp:220] Memory required for data: 3686465924
I1202 02:23:29.010624 28007 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:23:29.010678 28007 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:23:29.010900 28007 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:23:29.011144 28007 layer_factory.hpp:78] Creating layer data
I1202 02:23:29.011160 28007 net.cpp:67] Creating Layer data
I1202 02:23:29.011168 28007 net.cpp:356] data -> data
I1202 02:23:29.011180 28007 net.cpp:356] data -> label
I1202 02:23:29.011191 28007 net.cpp:96] Setting up data
I1202 02:23:29.011198 28007 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:23:29.013646 28007 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:23:29.020721 28007 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:23:29.021621 28007 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:23:29.021633 28007 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:23:29.021641 28007 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:23:29.021657 28007 net.cpp:67] Creating Layer label_data_1_split
I1202 02:23:29.021664 28007 net.cpp:394] label_data_1_split <- label
I1202 02:23:29.021675 28007 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:23:29.021694 28007 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:23:29.021708 28007 net.cpp:96] Setting up label_data_1_split
I1202 02:23:29.021719 28007 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:23:29.021726 28007 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:23:29.021739 28007 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:23:29.021751 28007 net.cpp:67] Creating Layer conv1_1
I1202 02:23:29.021759 28007 net.cpp:394] conv1_1 <- data
I1202 02:23:29.021770 28007 net.cpp:356] conv1_1 -> conv1_1
I1202 02:23:29.021780 28007 net.cpp:96] Setting up conv1_1
I1202 02:23:29.021947 28007 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:23:29.021966 28007 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:23:29.021975 28007 net.cpp:67] Creating Layer relu1_1
I1202 02:23:29.021981 28007 net.cpp:394] relu1_1 <- conv1_1
I1202 02:23:29.021991 28007 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:23:29.022009 28007 net.cpp:96] Setting up relu1_1
I1202 02:23:29.022019 28007 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:23:29.022033 28007 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:23:29.022044 28007 net.cpp:67] Creating Layer conv1_2
I1202 02:23:29.022050 28007 net.cpp:394] conv1_2 <- conv1_1
I1202 02:23:29.022059 28007 net.cpp:356] conv1_2 -> conv1_2
I1202 02:23:29.022069 28007 net.cpp:96] Setting up conv1_2
I1202 02:23:29.023089 28007 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:23:29.023107 28007 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:23:29.023115 28007 net.cpp:67] Creating Layer relu1_2
I1202 02:23:29.023123 28007 net.cpp:394] relu1_2 <- conv1_2
I1202 02:23:29.023131 28007 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:23:29.023140 28007 net.cpp:96] Setting up relu1_2
I1202 02:23:29.023149 28007 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:23:29.023157 28007 layer_factory.hpp:78] Creating layer pool1
I1202 02:23:29.023167 28007 net.cpp:67] Creating Layer pool1
I1202 02:23:29.023174 28007 net.cpp:394] pool1 <- conv1_2
I1202 02:23:29.023181 28007 net.cpp:356] pool1 -> pool1
I1202 02:23:29.023190 28007 net.cpp:96] Setting up pool1
I1202 02:23:29.023210 28007 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:23:29.023216 28007 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:23:29.023226 28007 net.cpp:67] Creating Layer conv2_1
I1202 02:23:29.023231 28007 net.cpp:394] conv2_1 <- pool1
I1202 02:23:29.023241 28007 net.cpp:356] conv2_1 -> conv2_1
I1202 02:23:29.023257 28007 net.cpp:96] Setting up conv2_1
I1202 02:23:29.025270 28007 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:23:29.025287 28007 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:23:29.025298 28007 net.cpp:67] Creating Layer relu2_1
I1202 02:23:29.025305 28007 net.cpp:394] relu2_1 <- conv2_1
I1202 02:23:29.025313 28007 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:23:29.025322 28007 net.cpp:96] Setting up relu2_1
I1202 02:23:29.025331 28007 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:23:29.025337 28007 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:23:29.025347 28007 net.cpp:67] Creating Layer conv2_2
I1202 02:23:29.025353 28007 net.cpp:394] conv2_2 <- conv2_1
I1202 02:23:29.025362 28007 net.cpp:356] conv2_2 -> conv2_2
I1202 02:23:29.025373 28007 net.cpp:96] Setting up conv2_2
I1202 02:23:29.029039 28007 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:23:29.029053 28007 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:23:29.029062 28007 net.cpp:67] Creating Layer relu2_2
I1202 02:23:29.029068 28007 net.cpp:394] relu2_2 <- conv2_2
I1202 02:23:29.029078 28007 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:23:29.029086 28007 net.cpp:96] Setting up relu2_2
I1202 02:23:29.029095 28007 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:23:29.029101 28007 layer_factory.hpp:78] Creating layer pool2
I1202 02:23:29.029110 28007 net.cpp:67] Creating Layer pool2
I1202 02:23:29.029116 28007 net.cpp:394] pool2 <- conv2_2
I1202 02:23:29.029124 28007 net.cpp:356] pool2 -> pool2
I1202 02:23:29.029134 28007 net.cpp:96] Setting up pool2
I1202 02:23:29.029144 28007 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:23:29.029160 28007 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:23:29.029170 28007 net.cpp:67] Creating Layer conv3_1
I1202 02:23:29.029176 28007 net.cpp:394] conv3_1 <- pool2
I1202 02:23:29.029186 28007 net.cpp:356] conv3_1 -> conv3_1
I1202 02:23:29.029202 28007 net.cpp:96] Setting up conv3_1
I1202 02:23:29.036452 28007 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:23:29.036468 28007 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:23:29.036478 28007 net.cpp:67] Creating Layer relu3_1
I1202 02:23:29.036484 28007 net.cpp:394] relu3_1 <- conv3_1
I1202 02:23:29.036492 28007 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:23:29.036501 28007 net.cpp:96] Setting up relu3_1
I1202 02:23:29.036511 28007 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:23:29.036517 28007 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:23:29.036536 28007 net.cpp:67] Creating Layer conv3_2
I1202 02:23:29.036547 28007 net.cpp:394] conv3_2 <- conv3_1
I1202 02:23:29.036557 28007 net.cpp:356] conv3_2 -> conv3_2
I1202 02:23:29.036576 28007 net.cpp:96] Setting up conv3_2
I1202 02:23:29.051203 28007 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:23:29.051228 28007 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:23:29.051239 28007 net.cpp:67] Creating Layer relu3_2
I1202 02:23:29.051246 28007 net.cpp:394] relu3_2 <- conv3_2
I1202 02:23:29.051255 28007 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:23:29.051265 28007 net.cpp:96] Setting up relu3_2
I1202 02:23:29.051275 28007 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:23:29.051282 28007 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:23:29.051298 28007 net.cpp:67] Creating Layer conv3_3
I1202 02:23:29.051309 28007 net.cpp:394] conv3_3 <- conv3_2
I1202 02:23:29.051319 28007 net.cpp:356] conv3_3 -> conv3_3
I1202 02:23:29.051329 28007 net.cpp:96] Setting up conv3_3
I1202 02:23:29.066117 28007 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:23:29.066136 28007 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:23:29.066148 28007 net.cpp:67] Creating Layer relu3_3
I1202 02:23:29.066155 28007 net.cpp:394] relu3_3 <- conv3_3
I1202 02:23:29.066164 28007 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:23:29.066174 28007 net.cpp:96] Setting up relu3_3
I1202 02:23:29.066185 28007 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:23:29.066191 28007 layer_factory.hpp:78] Creating layer pool3
I1202 02:23:29.066203 28007 net.cpp:67] Creating Layer pool3
I1202 02:23:29.066210 28007 net.cpp:394] pool3 <- conv3_3
I1202 02:23:29.066220 28007 net.cpp:356] pool3 -> pool3
I1202 02:23:29.066229 28007 net.cpp:96] Setting up pool3
I1202 02:23:29.066256 28007 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:23:29.066262 28007 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:23:29.066272 28007 net.cpp:67] Creating Layer conv4_1
I1202 02:23:29.066278 28007 net.cpp:394] conv4_1 <- pool3
I1202 02:23:29.066290 28007 net.cpp:356] conv4_1 -> conv4_1
I1202 02:23:29.066310 28007 net.cpp:96] Setting up conv4_1
I1202 02:23:29.095410 28007 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:23:29.095437 28007 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:23:29.095449 28007 net.cpp:67] Creating Layer relu4_1
I1202 02:23:29.095458 28007 net.cpp:394] relu4_1 <- conv4_1
I1202 02:23:29.095476 28007 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:23:29.095487 28007 net.cpp:96] Setting up relu4_1
I1202 02:23:29.095497 28007 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:23:29.095504 28007 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:23:29.095517 28007 net.cpp:67] Creating Layer conv4_2
I1202 02:23:29.095523 28007 net.cpp:394] conv4_2 <- conv4_1
I1202 02:23:29.095533 28007 net.cpp:356] conv4_2 -> conv4_2
I1202 02:23:29.095543 28007 net.cpp:96] Setting up conv4_2
I1202 02:23:29.153414 28007 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:23:29.153447 28007 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:23:29.153461 28007 net.cpp:67] Creating Layer relu4_2
I1202 02:23:29.153468 28007 net.cpp:394] relu4_2 <- conv4_2
I1202 02:23:29.153478 28007 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:23:29.153489 28007 net.cpp:96] Setting up relu4_2
I1202 02:23:29.153499 28007 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:23:29.153512 28007 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:23:29.153522 28007 net.cpp:67] Creating Layer conv4_3
I1202 02:23:29.153528 28007 net.cpp:394] conv4_3 <- conv4_2
I1202 02:23:29.153540 28007 net.cpp:356] conv4_3 -> conv4_3
I1202 02:23:29.153556 28007 net.cpp:96] Setting up conv4_3
I1202 02:23:29.211249 28007 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:23:29.211278 28007 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:23:29.211292 28007 net.cpp:67] Creating Layer relu4_3
I1202 02:23:29.211299 28007 net.cpp:394] relu4_3 <- conv4_3
I1202 02:23:29.211308 28007 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:23:29.211329 28007 net.cpp:96] Setting up relu4_3
I1202 02:23:29.211339 28007 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:23:29.211349 28007 layer_factory.hpp:78] Creating layer pool4
I1202 02:23:29.211359 28007 net.cpp:67] Creating Layer pool4
I1202 02:23:29.211365 28007 net.cpp:394] pool4 <- conv4_3
I1202 02:23:29.211376 28007 net.cpp:356] pool4 -> pool4
I1202 02:23:29.211390 28007 net.cpp:96] Setting up pool4
I1202 02:23:29.211413 28007 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:23:29.211421 28007 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:23:29.211431 28007 net.cpp:67] Creating Layer conv5_1
I1202 02:23:29.211437 28007 net.cpp:394] conv5_1 <- pool4
I1202 02:23:29.211457 28007 net.cpp:356] conv5_1 -> conv5_1
I1202 02:23:29.211473 28007 net.cpp:96] Setting up conv5_1
I1202 02:23:29.269369 28007 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:23:29.269398 28007 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:23:29.269409 28007 net.cpp:67] Creating Layer relu5_1
I1202 02:23:29.269417 28007 net.cpp:394] relu5_1 <- conv5_1
I1202 02:23:29.269425 28007 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:23:29.269436 28007 net.cpp:96] Setting up relu5_1
I1202 02:23:29.269446 28007 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:23:29.269453 28007 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:23:29.269464 28007 net.cpp:67] Creating Layer conv5_2
I1202 02:23:29.269470 28007 net.cpp:394] conv5_2 <- conv5_1
I1202 02:23:29.269480 28007 net.cpp:356] conv5_2 -> conv5_2
I1202 02:23:29.269491 28007 net.cpp:96] Setting up conv5_2
I1202 02:23:29.327164 28007 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:23:29.327193 28007 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:23:29.327204 28007 net.cpp:67] Creating Layer relu5_2
I1202 02:23:29.327211 28007 net.cpp:394] relu5_2 <- conv5_2
I1202 02:23:29.327224 28007 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:23:29.327234 28007 net.cpp:96] Setting up relu5_2
I1202 02:23:29.327244 28007 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:23:29.327251 28007 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:23:29.327261 28007 net.cpp:67] Creating Layer conv5_3
I1202 02:23:29.327267 28007 net.cpp:394] conv5_3 <- conv5_2
I1202 02:23:29.327280 28007 net.cpp:356] conv5_3 -> conv5_3
I1202 02:23:29.327296 28007 net.cpp:96] Setting up conv5_3
I1202 02:23:29.385335 28007 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:23:29.385365 28007 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:23:29.385375 28007 net.cpp:67] Creating Layer relu5_3
I1202 02:23:29.385382 28007 net.cpp:394] relu5_3 <- conv5_3
I1202 02:23:29.385396 28007 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:23:29.385407 28007 net.cpp:96] Setting up relu5_3
I1202 02:23:29.385417 28007 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:23:29.385423 28007 layer_factory.hpp:78] Creating layer pool5
I1202 02:23:29.385442 28007 net.cpp:67] Creating Layer pool5
I1202 02:23:29.385452 28007 net.cpp:394] pool5 <- conv5_3
I1202 02:23:29.385462 28007 net.cpp:356] pool5 -> pool5
I1202 02:23:29.385471 28007 net.cpp:96] Setting up pool5
I1202 02:23:29.385486 28007 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:23:29.385503 28007 layer_factory.hpp:78] Creating layer fc6
I1202 02:23:29.385512 28007 net.cpp:67] Creating Layer fc6
I1202 02:23:29.385519 28007 net.cpp:394] fc6 <- pool5
I1202 02:23:29.385531 28007 net.cpp:356] fc6 -> fc6
I1202 02:23:29.385547 28007 net.cpp:96] Setting up fc6
I1202 02:23:31.884949 28007 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:23:31.884984 28007 layer_factory.hpp:78] Creating layer relu6
I1202 02:23:31.884996 28007 net.cpp:67] Creating Layer relu6
I1202 02:23:31.885004 28007 net.cpp:394] relu6 <- fc6
I1202 02:23:31.885015 28007 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:23:31.885025 28007 net.cpp:96] Setting up relu6
I1202 02:23:31.885046 28007 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:23:31.885056 28007 layer_factory.hpp:78] Creating layer drop6
I1202 02:23:31.885078 28007 net.cpp:67] Creating Layer drop6
I1202 02:23:31.885089 28007 net.cpp:394] drop6 <- fc6
I1202 02:23:31.885098 28007 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:23:31.885107 28007 net.cpp:96] Setting up drop6
I1202 02:23:31.885118 28007 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:23:31.885123 28007 layer_factory.hpp:78] Creating layer fc7
I1202 02:23:31.885148 28007 net.cpp:67] Creating Layer fc7
I1202 02:23:31.885155 28007 net.cpp:394] fc7 <- fc6
I1202 02:23:31.885165 28007 net.cpp:356] fc7 -> fc7
I1202 02:23:31.885176 28007 net.cpp:96] Setting up fc7
I1202 02:23:32.293548 28007 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:23:32.293581 28007 layer_factory.hpp:78] Creating layer relu7
I1202 02:23:32.293593 28007 net.cpp:67] Creating Layer relu7
I1202 02:23:32.293601 28007 net.cpp:394] relu7 <- fc7
I1202 02:23:32.293609 28007 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:23:32.293619 28007 net.cpp:96] Setting up relu7
I1202 02:23:32.293638 28007 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:23:32.293645 28007 layer_factory.hpp:78] Creating layer drop7
I1202 02:23:32.293654 28007 net.cpp:67] Creating Layer drop7
I1202 02:23:32.293660 28007 net.cpp:394] drop7 <- fc7
I1202 02:23:32.293673 28007 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:23:32.293686 28007 net.cpp:96] Setting up drop7
I1202 02:23:32.293694 28007 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:23:32.293699 28007 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:23:32.293707 28007 net.cpp:67] Creating Layer fc8_2
I1202 02:23:32.293714 28007 net.cpp:394] fc8_2 <- fc7
I1202 02:23:32.293725 28007 net.cpp:356] fc8_2 -> fc8_2
I1202 02:23:32.293735 28007 net.cpp:96] Setting up fc8_2
I1202 02:23:32.293974 28007 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:23:32.293987 28007 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:23:32.293995 28007 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:23:32.294001 28007 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:23:32.294013 28007 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:23:32.294024 28007 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:23:32.294034 28007 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:23:32.294041 28007 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:23:32.294046 28007 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:23:32.294052 28007 layer_factory.hpp:78] Creating layer loss
I1202 02:23:32.294062 28007 net.cpp:67] Creating Layer loss
I1202 02:23:32.294070 28007 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:23:32.294076 28007 net.cpp:394] loss <- label_data_1_split_0
I1202 02:23:32.294085 28007 net.cpp:356] loss -> (automatic)
I1202 02:23:32.294093 28007 net.cpp:96] Setting up loss
I1202 02:23:32.294103 28007 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:23:32.294109 28007 net.cpp:109]     with loss weight 1
I1202 02:23:32.294127 28007 layer_factory.hpp:78] Creating layer accuracy
I1202 02:23:32.294139 28007 net.cpp:67] Creating Layer accuracy
I1202 02:23:32.294147 28007 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:23:32.294153 28007 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:23:32.294162 28007 net.cpp:356] accuracy -> accuracy
I1202 02:23:32.294172 28007 net.cpp:96] Setting up accuracy
I1202 02:23:32.294184 28007 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:23:32.294190 28007 net.cpp:172] accuracy does not need backward computation.
I1202 02:23:32.294195 28007 net.cpp:170] loss needs backward computation.
I1202 02:23:32.294201 28007 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:23:32.294208 28007 net.cpp:170] fc8_2 needs backward computation.
I1202 02:23:32.294212 28007 net.cpp:170] drop7 needs backward computation.
I1202 02:23:32.294219 28007 net.cpp:170] relu7 needs backward computation.
I1202 02:23:32.294224 28007 net.cpp:170] fc7 needs backward computation.
I1202 02:23:32.294229 28007 net.cpp:170] drop6 needs backward computation.
I1202 02:23:32.294234 28007 net.cpp:170] relu6 needs backward computation.
I1202 02:23:32.294248 28007 net.cpp:170] fc6 needs backward computation.
I1202 02:23:32.294255 28007 net.cpp:170] pool5 needs backward computation.
I1202 02:23:32.294311 28007 net.cpp:170] relu5_3 needs backward computation.
I1202 02:23:32.294317 28007 net.cpp:170] conv5_3 needs backward computation.
I1202 02:23:32.294323 28007 net.cpp:170] relu5_2 needs backward computation.
I1202 02:23:32.294349 28007 net.cpp:170] conv5_2 needs backward computation.
I1202 02:23:32.294356 28007 net.cpp:170] relu5_1 needs backward computation.
I1202 02:23:32.294361 28007 net.cpp:170] conv5_1 needs backward computation.
I1202 02:23:32.294368 28007 net.cpp:170] pool4 needs backward computation.
I1202 02:23:32.294373 28007 net.cpp:170] relu4_3 needs backward computation.
I1202 02:23:32.294400 28007 net.cpp:170] conv4_3 needs backward computation.
I1202 02:23:32.294407 28007 net.cpp:170] relu4_2 needs backward computation.
I1202 02:23:32.294412 28007 net.cpp:170] conv4_2 needs backward computation.
I1202 02:23:32.294419 28007 net.cpp:170] relu4_1 needs backward computation.
I1202 02:23:32.294425 28007 net.cpp:170] conv4_1 needs backward computation.
I1202 02:23:32.294436 28007 net.cpp:170] pool3 needs backward computation.
I1202 02:23:32.294442 28007 net.cpp:170] relu3_3 needs backward computation.
I1202 02:23:32.294447 28007 net.cpp:170] conv3_3 needs backward computation.
I1202 02:23:32.294453 28007 net.cpp:170] relu3_2 needs backward computation.
I1202 02:23:32.294459 28007 net.cpp:170] conv3_2 needs backward computation.
I1202 02:23:32.294466 28007 net.cpp:170] relu3_1 needs backward computation.
I1202 02:23:32.294471 28007 net.cpp:170] conv3_1 needs backward computation.
I1202 02:23:32.294482 28007 net.cpp:170] pool2 needs backward computation.
I1202 02:23:32.294492 28007 net.cpp:170] relu2_2 needs backward computation.
I1202 02:23:32.294497 28007 net.cpp:170] conv2_2 needs backward computation.
I1202 02:23:32.294503 28007 net.cpp:170] relu2_1 needs backward computation.
I1202 02:23:32.294509 28007 net.cpp:170] conv2_1 needs backward computation.
I1202 02:23:32.294515 28007 net.cpp:170] pool1 needs backward computation.
I1202 02:23:32.294520 28007 net.cpp:170] relu1_2 needs backward computation.
I1202 02:23:32.294525 28007 net.cpp:170] conv1_2 needs backward computation.
I1202 02:23:32.294531 28007 net.cpp:170] relu1_1 needs backward computation.
I1202 02:23:32.294536 28007 net.cpp:170] conv1_1 needs backward computation.
I1202 02:23:32.294543 28007 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:23:32.294548 28007 net.cpp:172] data does not need backward computation.
I1202 02:23:32.294553 28007 net.cpp:208] This network produces output accuracy
I1202 02:23:32.294585 28007 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:23:32.294598 28007 net.cpp:219] Network initialization done.
I1202 02:23:32.294605 28007 net.cpp:220] Memory required for data: 921616692
I1202 02:23:32.294715 28007 solver.cpp:41] Solver scaffolding done.
I1202 02:23:32.294723 28007 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_18000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:23:35.644840 28007 solver.cpp:160] Solving small
I1202 02:23:35.644866 28007 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:23:35.644912 28007 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:25:00.317941 28007 solver.cpp:305] Test loss: 0.365574
I1202 02:25:00.318022 28007 solver.cpp:318] mean_score = test_score[0] { = 3340} / test_score[1] { = 3570 }
I1202 02:25:00.318030 28007 solver.cpp:319]            = 0.935574
I1202 02:25:00.318039 28007 solver.cpp:328]     Test net output #0: accuracy = 0.935574
I1202 02:25:00.318044 28007 solver.cpp:318] mean_score = test_score[2] { = 148} / test_score[3] { = 398 }
I1202 02:25:00.318049 28007 solver.cpp:319]            = 0.371859
I1202 02:25:00.318053 28007 solver.cpp:328]     Test net output #1: accuracy = 0.371859
I1202 02:25:00.318063 28007 solver.cpp:332]     Test net output #2: accuracy = 0.879032
I1202 02:25:00.318068 28007 solver.cpp:334]     Test net output #3: accuracy = 0.653717
I1202 02:25:01.014756 28007 solver.cpp:209] Iteration 0, loss = 0.0332649
I1202 02:25:01.014787 28007 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:25:03.369863 28007 solver.cpp:209] Iteration 1, loss = 0.137237
I1202 02:25:03.369891 28007 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:25:05.385532 28007 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:25:09.324270 28007 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:25:13.333400 28007 solver.cpp:246] Iteration 2, loss = 0.105929
I1202 02:25:13.333431 28007 solver.cpp:251] Optimization Done.
I1202 02:25:13.333436 28007 caffe.cpp:121] Optimization Done.
I1202 02:25:13.472013 28583 caffe.cpp:99] Use GPU with device ID 0
I1202 02:25:13.654345 28583 caffe.cpp:107] Starting Optimization
I1202 02:25:13.654443 28583 solver.cpp:32] Initializing solver from parameters: 
test_iter: 496
test_interval: 100
base_lr: 5e-05
display: 1
max_iter: 2
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 2000
snapshot_prefix: "task/scrape_blue/none/fine_"
solver_mode: GPU
test_compute_loss: true
net: "task/scrape_blue/train_val.prototxt"
I1202 02:25:13.654466 28583 solver.cpp:67] Creating training net from net file: task/scrape_blue/train_val.prototxt
I1202 02:25:13.655254 28583 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1202 02:25:13.655284 28583 net.cpp:275] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1202 02:25:13.655520 28583 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt"
    batch_size: 32
    new_height: 256
    new_width: 256
  }
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
state {
  phase: TRAIN
}
I1202 02:25:13.655644 28583 layer_factory.hpp:78] Creating layer data
I1202 02:25:13.655666 28583 net.cpp:67] Creating Layer data
I1202 02:25:13.655673 28583 net.cpp:356] data -> data
I1202 02:25:13.655704 28583 net.cpp:356] data -> label
I1202 02:25:13.655712 28583 net.cpp:96] Setting up data
I1202 02:25:13.655717 28583 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/train.txt
I1202 02:25:13.669999 28583 image_data_layer.cpp:49] A total of 40401 images.
I1202 02:25:13.679677 28583 image_data_layer.cpp:78] output data size: 32,3,224,224
I1202 02:25:13.682461 28583 net.cpp:103] Top shape: 32 3 224 224 (4816896)
I1202 02:25:13.682485 28583 net.cpp:103] Top shape: 32 1 1 1 (32)
I1202 02:25:13.682492 28583 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:25:13.682507 28583 net.cpp:67] Creating Layer conv1_1
I1202 02:25:13.682510 28583 net.cpp:394] conv1_1 <- data
I1202 02:25:13.682523 28583 net.cpp:356] conv1_1 -> conv1_1
I1202 02:25:13.682534 28583 net.cpp:96] Setting up conv1_1
I1202 02:25:13.826581 28583 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:25:13.826617 28583 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:25:13.826627 28583 net.cpp:67] Creating Layer relu1_1
I1202 02:25:13.826632 28583 net.cpp:394] relu1_1 <- conv1_1
I1202 02:25:13.826638 28583 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:25:13.826645 28583 net.cpp:96] Setting up relu1_1
I1202 02:25:13.826655 28583 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:25:13.826658 28583 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:25:13.826665 28583 net.cpp:67] Creating Layer conv1_2
I1202 02:25:13.826668 28583 net.cpp:394] conv1_2 <- conv1_1
I1202 02:25:13.826673 28583 net.cpp:356] conv1_2 -> conv1_2
I1202 02:25:13.826680 28583 net.cpp:96] Setting up conv1_2
I1202 02:25:13.827754 28583 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:25:13.827767 28583 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:25:13.827774 28583 net.cpp:67] Creating Layer relu1_2
I1202 02:25:13.827776 28583 net.cpp:394] relu1_2 <- conv1_2
I1202 02:25:13.827781 28583 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:25:13.827785 28583 net.cpp:96] Setting up relu1_2
I1202 02:25:13.827791 28583 net.cpp:103] Top shape: 32 64 224 224 (102760448)
I1202 02:25:13.827795 28583 layer_factory.hpp:78] Creating layer pool1
I1202 02:25:13.827803 28583 net.cpp:67] Creating Layer pool1
I1202 02:25:13.827806 28583 net.cpp:394] pool1 <- conv1_2
I1202 02:25:13.827811 28583 net.cpp:356] pool1 -> pool1
I1202 02:25:13.827816 28583 net.cpp:96] Setting up pool1
I1202 02:25:13.827833 28583 net.cpp:103] Top shape: 32 64 112 112 (25690112)
I1202 02:25:13.827837 28583 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:25:13.827844 28583 net.cpp:67] Creating Layer conv2_1
I1202 02:25:13.827847 28583 net.cpp:394] conv2_1 <- pool1
I1202 02:25:13.827852 28583 net.cpp:356] conv2_1 -> conv2_1
I1202 02:25:13.827857 28583 net.cpp:96] Setting up conv2_1
I1202 02:25:13.829784 28583 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:25:13.829797 28583 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:25:13.829802 28583 net.cpp:67] Creating Layer relu2_1
I1202 02:25:13.829805 28583 net.cpp:394] relu2_1 <- conv2_1
I1202 02:25:13.829810 28583 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:25:13.829814 28583 net.cpp:96] Setting up relu2_1
I1202 02:25:13.829819 28583 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:25:13.829823 28583 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:25:13.829829 28583 net.cpp:67] Creating Layer conv2_2
I1202 02:25:13.829833 28583 net.cpp:394] conv2_2 <- conv2_1
I1202 02:25:13.829838 28583 net.cpp:356] conv2_2 -> conv2_2
I1202 02:25:13.829843 28583 net.cpp:96] Setting up conv2_2
I1202 02:25:13.833603 28583 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:25:13.833616 28583 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:25:13.833621 28583 net.cpp:67] Creating Layer relu2_2
I1202 02:25:13.833624 28583 net.cpp:394] relu2_2 <- conv2_2
I1202 02:25:13.833629 28583 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:25:13.833633 28583 net.cpp:96] Setting up relu2_2
I1202 02:25:13.833638 28583 net.cpp:103] Top shape: 32 128 112 112 (51380224)
I1202 02:25:13.833650 28583 layer_factory.hpp:78] Creating layer pool2
I1202 02:25:13.833657 28583 net.cpp:67] Creating Layer pool2
I1202 02:25:13.833659 28583 net.cpp:394] pool2 <- conv2_2
I1202 02:25:13.833664 28583 net.cpp:356] pool2 -> pool2
I1202 02:25:13.833669 28583 net.cpp:96] Setting up pool2
I1202 02:25:13.833675 28583 net.cpp:103] Top shape: 32 128 56 56 (12845056)
I1202 02:25:13.833678 28583 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:25:13.833684 28583 net.cpp:67] Creating Layer conv3_1
I1202 02:25:13.833688 28583 net.cpp:394] conv3_1 <- pool2
I1202 02:25:13.833691 28583 net.cpp:356] conv3_1 -> conv3_1
I1202 02:25:13.833698 28583 net.cpp:96] Setting up conv3_1
I1202 02:25:13.841087 28583 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:25:13.841101 28583 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:25:13.841106 28583 net.cpp:67] Creating Layer relu3_1
I1202 02:25:13.841110 28583 net.cpp:394] relu3_1 <- conv3_1
I1202 02:25:13.841114 28583 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:25:13.841120 28583 net.cpp:96] Setting up relu3_1
I1202 02:25:13.841125 28583 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:25:13.841127 28583 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:25:13.841132 28583 net.cpp:67] Creating Layer conv3_2
I1202 02:25:13.841135 28583 net.cpp:394] conv3_2 <- conv3_1
I1202 02:25:13.841141 28583 net.cpp:356] conv3_2 -> conv3_2
I1202 02:25:13.841146 28583 net.cpp:96] Setting up conv3_2
I1202 02:25:13.855818 28583 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:25:13.855839 28583 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:25:13.855851 28583 net.cpp:67] Creating Layer relu3_2
I1202 02:25:13.855856 28583 net.cpp:394] relu3_2 <- conv3_2
I1202 02:25:13.855865 28583 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:25:13.855871 28583 net.cpp:96] Setting up relu3_2
I1202 02:25:13.855877 28583 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:25:13.855880 28583 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:25:13.855887 28583 net.cpp:67] Creating Layer conv3_3
I1202 02:25:13.855890 28583 net.cpp:394] conv3_3 <- conv3_2
I1202 02:25:13.855895 28583 net.cpp:356] conv3_3 -> conv3_3
I1202 02:25:13.855901 28583 net.cpp:96] Setting up conv3_3
I1202 02:25:13.870640 28583 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:25:13.870657 28583 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:25:13.870668 28583 net.cpp:67] Creating Layer relu3_3
I1202 02:25:13.870671 28583 net.cpp:394] relu3_3 <- conv3_3
I1202 02:25:13.870676 28583 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:25:13.870682 28583 net.cpp:96] Setting up relu3_3
I1202 02:25:13.870687 28583 net.cpp:103] Top shape: 32 256 56 56 (25690112)
I1202 02:25:13.870690 28583 layer_factory.hpp:78] Creating layer pool3
I1202 02:25:13.870697 28583 net.cpp:67] Creating Layer pool3
I1202 02:25:13.870699 28583 net.cpp:394] pool3 <- conv3_3
I1202 02:25:13.870704 28583 net.cpp:356] pool3 -> pool3
I1202 02:25:13.870709 28583 net.cpp:96] Setting up pool3
I1202 02:25:13.870717 28583 net.cpp:103] Top shape: 32 256 28 28 (6422528)
I1202 02:25:13.870720 28583 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:25:13.870726 28583 net.cpp:67] Creating Layer conv4_1
I1202 02:25:13.870729 28583 net.cpp:394] conv4_1 <- pool3
I1202 02:25:13.870733 28583 net.cpp:356] conv4_1 -> conv4_1
I1202 02:25:13.870738 28583 net.cpp:96] Setting up conv4_1
I1202 02:25:13.899878 28583 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:25:13.899900 28583 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:25:13.899909 28583 net.cpp:67] Creating Layer relu4_1
I1202 02:25:13.899914 28583 net.cpp:394] relu4_1 <- conv4_1
I1202 02:25:13.899921 28583 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:25:13.899927 28583 net.cpp:96] Setting up relu4_1
I1202 02:25:13.899934 28583 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:25:13.899936 28583 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:25:13.899942 28583 net.cpp:67] Creating Layer conv4_2
I1202 02:25:13.899945 28583 net.cpp:394] conv4_2 <- conv4_1
I1202 02:25:13.899960 28583 net.cpp:356] conv4_2 -> conv4_2
I1202 02:25:13.899966 28583 net.cpp:96] Setting up conv4_2
I1202 02:25:13.957933 28583 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:25:13.957962 28583 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:25:13.957969 28583 net.cpp:67] Creating Layer relu4_2
I1202 02:25:13.957974 28583 net.cpp:394] relu4_2 <- conv4_2
I1202 02:25:13.957980 28583 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:25:13.957988 28583 net.cpp:96] Setting up relu4_2
I1202 02:25:13.957993 28583 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:25:13.957996 28583 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:25:13.958004 28583 net.cpp:67] Creating Layer conv4_3
I1202 02:25:13.958009 28583 net.cpp:394] conv4_3 <- conv4_2
I1202 02:25:13.958012 28583 net.cpp:356] conv4_3 -> conv4_3
I1202 02:25:13.958019 28583 net.cpp:96] Setting up conv4_3
I1202 02:25:14.015751 28583 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:25:14.015775 28583 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:25:14.015782 28583 net.cpp:67] Creating Layer relu4_3
I1202 02:25:14.015789 28583 net.cpp:394] relu4_3 <- conv4_3
I1202 02:25:14.015795 28583 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:25:14.015802 28583 net.cpp:96] Setting up relu4_3
I1202 02:25:14.015808 28583 net.cpp:103] Top shape: 32 512 28 28 (12845056)
I1202 02:25:14.015811 28583 layer_factory.hpp:78] Creating layer pool4
I1202 02:25:14.015817 28583 net.cpp:67] Creating Layer pool4
I1202 02:25:14.015820 28583 net.cpp:394] pool4 <- conv4_3
I1202 02:25:14.015825 28583 net.cpp:356] pool4 -> pool4
I1202 02:25:14.015830 28583 net.cpp:96] Setting up pool4
I1202 02:25:14.015837 28583 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:25:14.015841 28583 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:25:14.015849 28583 net.cpp:67] Creating Layer conv5_1
I1202 02:25:14.015852 28583 net.cpp:394] conv5_1 <- pool4
I1202 02:25:14.015858 28583 net.cpp:356] conv5_1 -> conv5_1
I1202 02:25:14.015866 28583 net.cpp:96] Setting up conv5_1
I1202 02:25:14.073930 28583 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:25:14.073956 28583 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:25:14.073962 28583 net.cpp:67] Creating Layer relu5_1
I1202 02:25:14.073967 28583 net.cpp:394] relu5_1 <- conv5_1
I1202 02:25:14.073981 28583 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:25:14.073987 28583 net.cpp:96] Setting up relu5_1
I1202 02:25:14.073993 28583 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:25:14.073997 28583 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:25:14.074002 28583 net.cpp:67] Creating Layer conv5_2
I1202 02:25:14.074005 28583 net.cpp:394] conv5_2 <- conv5_1
I1202 02:25:14.074012 28583 net.cpp:356] conv5_2 -> conv5_2
I1202 02:25:14.074018 28583 net.cpp:96] Setting up conv5_2
I1202 02:25:14.131705 28583 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:25:14.131729 28583 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:25:14.131737 28583 net.cpp:67] Creating Layer relu5_2
I1202 02:25:14.131742 28583 net.cpp:394] relu5_2 <- conv5_2
I1202 02:25:14.131749 28583 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:25:14.131757 28583 net.cpp:96] Setting up relu5_2
I1202 02:25:14.131762 28583 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:25:14.131765 28583 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:25:14.131772 28583 net.cpp:67] Creating Layer conv5_3
I1202 02:25:14.131774 28583 net.cpp:394] conv5_3 <- conv5_2
I1202 02:25:14.131778 28583 net.cpp:356] conv5_3 -> conv5_3
I1202 02:25:14.131784 28583 net.cpp:96] Setting up conv5_3
I1202 02:25:14.189416 28583 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:25:14.189442 28583 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:25:14.189450 28583 net.cpp:67] Creating Layer relu5_3
I1202 02:25:14.189455 28583 net.cpp:394] relu5_3 <- conv5_3
I1202 02:25:14.189462 28583 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:25:14.189468 28583 net.cpp:96] Setting up relu5_3
I1202 02:25:14.189474 28583 net.cpp:103] Top shape: 32 512 14 14 (3211264)
I1202 02:25:14.189487 28583 layer_factory.hpp:78] Creating layer pool5
I1202 02:25:14.189493 28583 net.cpp:67] Creating Layer pool5
I1202 02:25:14.189496 28583 net.cpp:394] pool5 <- conv5_3
I1202 02:25:14.189502 28583 net.cpp:356] pool5 -> pool5
I1202 02:25:14.189508 28583 net.cpp:96] Setting up pool5
I1202 02:25:14.189515 28583 net.cpp:103] Top shape: 32 512 7 7 (802816)
I1202 02:25:14.189519 28583 layer_factory.hpp:78] Creating layer fc6
I1202 02:25:14.189532 28583 net.cpp:67] Creating Layer fc6
I1202 02:25:14.189534 28583 net.cpp:394] fc6 <- pool5
I1202 02:25:14.189543 28583 net.cpp:356] fc6 -> fc6
I1202 02:25:14.189548 28583 net.cpp:96] Setting up fc6
I1202 02:25:16.687780 28583 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:25:16.687811 28583 layer_factory.hpp:78] Creating layer relu6
I1202 02:25:16.687821 28583 net.cpp:67] Creating Layer relu6
I1202 02:25:16.687825 28583 net.cpp:394] relu6 <- fc6
I1202 02:25:16.687832 28583 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:25:16.687839 28583 net.cpp:96] Setting up relu6
I1202 02:25:16.687855 28583 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:25:16.687858 28583 layer_factory.hpp:78] Creating layer drop6
I1202 02:25:16.687865 28583 net.cpp:67] Creating Layer drop6
I1202 02:25:16.687868 28583 net.cpp:394] drop6 <- fc6
I1202 02:25:16.687875 28583 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:25:16.687880 28583 net.cpp:96] Setting up drop6
I1202 02:25:16.687883 28583 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:25:16.687886 28583 layer_factory.hpp:78] Creating layer fc7
I1202 02:25:16.687892 28583 net.cpp:67] Creating Layer fc7
I1202 02:25:16.687896 28583 net.cpp:394] fc7 <- fc6
I1202 02:25:16.687899 28583 net.cpp:356] fc7 -> fc7
I1202 02:25:16.687906 28583 net.cpp:96] Setting up fc7
I1202 02:25:17.096541 28583 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:25:17.096570 28583 layer_factory.hpp:78] Creating layer relu7
I1202 02:25:17.096578 28583 net.cpp:67] Creating Layer relu7
I1202 02:25:17.096583 28583 net.cpp:394] relu7 <- fc7
I1202 02:25:17.096590 28583 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:25:17.096596 28583 net.cpp:96] Setting up relu7
I1202 02:25:17.096611 28583 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:25:17.096614 28583 layer_factory.hpp:78] Creating layer drop7
I1202 02:25:17.096621 28583 net.cpp:67] Creating Layer drop7
I1202 02:25:17.096624 28583 net.cpp:394] drop7 <- fc7
I1202 02:25:17.096628 28583 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:25:17.096633 28583 net.cpp:96] Setting up drop7
I1202 02:25:17.096637 28583 net.cpp:103] Top shape: 32 4096 1 1 (131072)
I1202 02:25:17.096640 28583 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:25:17.096645 28583 net.cpp:67] Creating Layer fc8_2
I1202 02:25:17.096649 28583 net.cpp:394] fc8_2 <- fc7
I1202 02:25:17.096653 28583 net.cpp:356] fc8_2 -> fc8_2
I1202 02:25:17.096659 28583 net.cpp:96] Setting up fc8_2
I1202 02:25:17.096880 28583 net.cpp:103] Top shape: 32 2 1 1 (64)
I1202 02:25:17.096889 28583 layer_factory.hpp:78] Creating layer loss
I1202 02:25:17.096895 28583 net.cpp:67] Creating Layer loss
I1202 02:25:17.096899 28583 net.cpp:394] loss <- fc8_2
I1202 02:25:17.096902 28583 net.cpp:394] loss <- label
I1202 02:25:17.096910 28583 net.cpp:356] loss -> (automatic)
I1202 02:25:17.096915 28583 net.cpp:96] Setting up loss
I1202 02:25:17.096926 28583 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:25:17.096930 28583 net.cpp:109]     with loss weight 1
I1202 02:25:17.096964 28583 net.cpp:170] loss needs backward computation.
I1202 02:25:17.096968 28583 net.cpp:170] fc8_2 needs backward computation.
I1202 02:25:17.096971 28583 net.cpp:170] drop7 needs backward computation.
I1202 02:25:17.096973 28583 net.cpp:170] relu7 needs backward computation.
I1202 02:25:17.096976 28583 net.cpp:170] fc7 needs backward computation.
I1202 02:25:17.096979 28583 net.cpp:170] drop6 needs backward computation.
I1202 02:25:17.096982 28583 net.cpp:170] relu6 needs backward computation.
I1202 02:25:17.096984 28583 net.cpp:170] fc6 needs backward computation.
I1202 02:25:17.096997 28583 net.cpp:170] pool5 needs backward computation.
I1202 02:25:17.097004 28583 net.cpp:170] relu5_3 needs backward computation.
I1202 02:25:17.097007 28583 net.cpp:170] conv5_3 needs backward computation.
I1202 02:25:17.097010 28583 net.cpp:170] relu5_2 needs backward computation.
I1202 02:25:17.097013 28583 net.cpp:170] conv5_2 needs backward computation.
I1202 02:25:17.097017 28583 net.cpp:170] relu5_1 needs backward computation.
I1202 02:25:17.097018 28583 net.cpp:170] conv5_1 needs backward computation.
I1202 02:25:17.097023 28583 net.cpp:170] pool4 needs backward computation.
I1202 02:25:17.097025 28583 net.cpp:170] relu4_3 needs backward computation.
I1202 02:25:17.097028 28583 net.cpp:170] conv4_3 needs backward computation.
I1202 02:25:17.097031 28583 net.cpp:170] relu4_2 needs backward computation.
I1202 02:25:17.097034 28583 net.cpp:170] conv4_2 needs backward computation.
I1202 02:25:17.097038 28583 net.cpp:170] relu4_1 needs backward computation.
I1202 02:25:17.097039 28583 net.cpp:170] conv4_1 needs backward computation.
I1202 02:25:17.097043 28583 net.cpp:170] pool3 needs backward computation.
I1202 02:25:17.097045 28583 net.cpp:170] relu3_3 needs backward computation.
I1202 02:25:17.097048 28583 net.cpp:170] conv3_3 needs backward computation.
I1202 02:25:17.097051 28583 net.cpp:170] relu3_2 needs backward computation.
I1202 02:25:17.097054 28583 net.cpp:170] conv3_2 needs backward computation.
I1202 02:25:17.097057 28583 net.cpp:170] relu3_1 needs backward computation.
I1202 02:25:17.097059 28583 net.cpp:170] conv3_1 needs backward computation.
I1202 02:25:17.097062 28583 net.cpp:170] pool2 needs backward computation.
I1202 02:25:17.097065 28583 net.cpp:170] relu2_2 needs backward computation.
I1202 02:25:17.097069 28583 net.cpp:170] conv2_2 needs backward computation.
I1202 02:25:17.097071 28583 net.cpp:170] relu2_1 needs backward computation.
I1202 02:25:17.097074 28583 net.cpp:170] conv2_1 needs backward computation.
I1202 02:25:17.097076 28583 net.cpp:170] pool1 needs backward computation.
I1202 02:25:17.097079 28583 net.cpp:170] relu1_2 needs backward computation.
I1202 02:25:17.097082 28583 net.cpp:170] conv1_2 needs backward computation.
I1202 02:25:17.097085 28583 net.cpp:170] relu1_1 needs backward computation.
I1202 02:25:17.097087 28583 net.cpp:170] conv1_1 needs backward computation.
I1202 02:25:17.097090 28583 net.cpp:172] data does not need backward computation.
I1202 02:25:17.097108 28583 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:25:17.097115 28583 net.cpp:219] Network initialization done.
I1202 02:25:17.097118 28583 net.cpp:220] Memory required for data: 3686465924
I1202 02:25:17.097955 28583 solver.cpp:151] Creating test net (#0) specified by net file: task/scrape_blue/train_val.prototxt
I1202 02:25:17.097998 28583 net.cpp:275] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1202 02:25:17.098212 28583 net.cpp:39] Initializing net from parameters: 
name: "small"
layers {
  top: "data"
  top: "label"
  name: "data"
  type: IMAGE_DATA
  image_data_param {
    source: "/data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt"
    batch_size: 8
    new_height: 256
    new_width: 256
  }
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 86.752
    mean_value: 101.46
    mean_value: 104.6
  }
}
layers {
  bottom: "data"
  top: "conv1_1"
  name: "conv1_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_1"
  top: "conv1_1"
  name: "relu1_1"
  type: RELU
}
layers {
  bottom: "conv1_1"
  top: "conv1_2"
  name: "conv1_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv1_2"
  top: "conv1_2"
  name: "relu1_2"
  type: RELU
}
layers {
  bottom: "conv1_2"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "conv2_1"
  name: "conv2_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_1"
  top: "conv2_1"
  name: "relu2_1"
  type: RELU
}
layers {
  bottom: "conv2_1"
  top: "conv2_2"
  name: "conv2_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv2_2"
  top: "conv2_2"
  name: "relu2_2"
  type: RELU
}
layers {
  bottom: "conv2_2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool2"
  top: "conv3_1"
  name: "conv3_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_1"
  top: "conv3_1"
  name: "relu3_1"
  type: RELU
}
layers {
  bottom: "conv3_1"
  top: "conv3_2"
  name: "conv3_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_2"
  top: "conv3_2"
  name: "relu3_2"
  type: RELU
}
layers {
  bottom: "conv3_2"
  top: "conv3_3"
  name: "conv3_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv3_3"
  top: "conv3_3"
  name: "relu3_3"
  type: RELU
}
layers {
  bottom: "conv3_3"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool3"
  top: "conv4_1"
  name: "conv4_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_1"
  top: "conv4_1"
  name: "relu4_1"
  type: RELU
}
layers {
  bottom: "conv4_1"
  top: "conv4_2"
  name: "conv4_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_2"
  top: "conv4_2"
  name: "relu4_2"
  type: RELU
}
layers {
  bottom: "conv4_2"
  top: "conv4_3"
  name: "conv4_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv4_3"
  top: "conv4_3"
  name: "relu4_3"
  type: RELU
}
layers {
  bottom: "conv4_3"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool4"
  top: "conv5_1"
  name: "conv5_1"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_1"
  top: "conv5_1"
  name: "relu5_1"
  type: RELU
}
layers {
  bottom: "conv5_1"
  top: "conv5_2"
  name: "conv5_2"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_2"
  top: "conv5_2"
  name: "relu5_2"
  type: RELU
}
layers {
  bottom: "conv5_2"
  top: "conv5_3"
  name: "conv5_3"
  type: CONVOLUTION
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "conv5_3"
  top: "conv5_3"
  name: "relu5_3"
  type: RELU
}
layers {
  bottom: "conv5_3"
  top: "pool5"
  name: "pool5"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layers {
  bottom: "pool5"
  top: "fc6"
  name: "fc6"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "relu6"
  type: RELU
}
layers {
  bottom: "fc6"
  top: "fc6"
  name: "drop6"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc6"
  top: "fc7"
  name: "fc7"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "relu7"
  type: RELU
}
layers {
  bottom: "fc7"
  top: "fc7"
  name: "drop7"
  type: DROPOUT
  dropout_param {
    dropout_ratio: 0.5
  }
}
layers {
  bottom: "fc7"
  top: "fc8_2"
  name: "fc8_2"
  type: INNER_PRODUCT
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  name: "loss"
  type: SOFTMAX_LOSS
}
layers {
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  name: "accuracy"
  type: PER_CLASS_ACCURACY
  include {
    phase: TEST
  }
}
state {
  phase: TEST
}
I1202 02:25:17.098353 28583 layer_factory.hpp:78] Creating layer data
I1202 02:25:17.098363 28583 net.cpp:67] Creating Layer data
I1202 02:25:17.098367 28583 net.cpp:356] data -> data
I1202 02:25:17.098376 28583 net.cpp:356] data -> label
I1202 02:25:17.098381 28583 net.cpp:96] Setting up data
I1202 02:25:17.098384 28583 image_data_layer.cpp:34] Opening file /data/ad6813/devCaffe/caffe/data/scrape_blue/val.txt
I1202 02:25:17.099984 28583 image_data_layer.cpp:49] A total of 3963 images.
I1202 02:25:17.107059 28583 image_data_layer.cpp:78] output data size: 8,3,224,224
I1202 02:25:17.107718 28583 net.cpp:103] Top shape: 8 3 224 224 (1204224)
I1202 02:25:17.107743 28583 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:25:17.107748 28583 layer_factory.hpp:78] Creating layer label_data_1_split
I1202 02:25:17.107759 28583 net.cpp:67] Creating Layer label_data_1_split
I1202 02:25:17.107764 28583 net.cpp:394] label_data_1_split <- label
I1202 02:25:17.107770 28583 net.cpp:356] label_data_1_split -> label_data_1_split_0
I1202 02:25:17.107779 28583 net.cpp:356] label_data_1_split -> label_data_1_split_1
I1202 02:25:17.107784 28583 net.cpp:96] Setting up label_data_1_split
I1202 02:25:17.107789 28583 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:25:17.107791 28583 net.cpp:103] Top shape: 8 1 1 1 (8)
I1202 02:25:17.107795 28583 layer_factory.hpp:78] Creating layer conv1_1
I1202 02:25:17.107800 28583 net.cpp:67] Creating Layer conv1_1
I1202 02:25:17.107805 28583 net.cpp:394] conv1_1 <- data
I1202 02:25:17.107810 28583 net.cpp:356] conv1_1 -> conv1_1
I1202 02:25:17.107815 28583 net.cpp:96] Setting up conv1_1
I1202 02:25:17.107976 28583 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:25:17.107990 28583 layer_factory.hpp:78] Creating layer relu1_1
I1202 02:25:17.107995 28583 net.cpp:67] Creating Layer relu1_1
I1202 02:25:17.107998 28583 net.cpp:394] relu1_1 <- conv1_1
I1202 02:25:17.108002 28583 net.cpp:345] relu1_1 -> conv1_1 (in-place)
I1202 02:25:17.108014 28583 net.cpp:96] Setting up relu1_1
I1202 02:25:17.108021 28583 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:25:17.108023 28583 layer_factory.hpp:78] Creating layer conv1_2
I1202 02:25:17.108028 28583 net.cpp:67] Creating Layer conv1_2
I1202 02:25:17.108031 28583 net.cpp:394] conv1_2 <- conv1_1
I1202 02:25:17.108036 28583 net.cpp:356] conv1_2 -> conv1_2
I1202 02:25:17.108042 28583 net.cpp:96] Setting up conv1_2
I1202 02:25:17.109037 28583 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:25:17.109050 28583 layer_factory.hpp:78] Creating layer relu1_2
I1202 02:25:17.109055 28583 net.cpp:67] Creating Layer relu1_2
I1202 02:25:17.109057 28583 net.cpp:394] relu1_2 <- conv1_2
I1202 02:25:17.109062 28583 net.cpp:345] relu1_2 -> conv1_2 (in-place)
I1202 02:25:17.109067 28583 net.cpp:96] Setting up relu1_2
I1202 02:25:17.109071 28583 net.cpp:103] Top shape: 8 64 224 224 (25690112)
I1202 02:25:17.109074 28583 layer_factory.hpp:78] Creating layer pool1
I1202 02:25:17.109081 28583 net.cpp:67] Creating Layer pool1
I1202 02:25:17.109082 28583 net.cpp:394] pool1 <- conv1_2
I1202 02:25:17.109086 28583 net.cpp:356] pool1 -> pool1
I1202 02:25:17.109091 28583 net.cpp:96] Setting up pool1
I1202 02:25:17.109098 28583 net.cpp:103] Top shape: 8 64 112 112 (6422528)
I1202 02:25:17.109102 28583 layer_factory.hpp:78] Creating layer conv2_1
I1202 02:25:17.109107 28583 net.cpp:67] Creating Layer conv2_1
I1202 02:25:17.109109 28583 net.cpp:394] conv2_1 <- pool1
I1202 02:25:17.109113 28583 net.cpp:356] conv2_1 -> conv2_1
I1202 02:25:17.109118 28583 net.cpp:96] Setting up conv2_1
I1202 02:25:17.111121 28583 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:25:17.111135 28583 layer_factory.hpp:78] Creating layer relu2_1
I1202 02:25:17.111140 28583 net.cpp:67] Creating Layer relu2_1
I1202 02:25:17.111145 28583 net.cpp:394] relu2_1 <- conv2_1
I1202 02:25:17.111148 28583 net.cpp:345] relu2_1 -> conv2_1 (in-place)
I1202 02:25:17.111153 28583 net.cpp:96] Setting up relu2_1
I1202 02:25:17.111158 28583 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:25:17.111161 28583 layer_factory.hpp:78] Creating layer conv2_2
I1202 02:25:17.111166 28583 net.cpp:67] Creating Layer conv2_2
I1202 02:25:17.111170 28583 net.cpp:394] conv2_2 <- conv2_1
I1202 02:25:17.111174 28583 net.cpp:356] conv2_2 -> conv2_2
I1202 02:25:17.111179 28583 net.cpp:96] Setting up conv2_2
I1202 02:25:17.114838 28583 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:25:17.114850 28583 layer_factory.hpp:78] Creating layer relu2_2
I1202 02:25:17.114856 28583 net.cpp:67] Creating Layer relu2_2
I1202 02:25:17.114858 28583 net.cpp:394] relu2_2 <- conv2_2
I1202 02:25:17.114862 28583 net.cpp:345] relu2_2 -> conv2_2 (in-place)
I1202 02:25:17.114867 28583 net.cpp:96] Setting up relu2_2
I1202 02:25:17.114872 28583 net.cpp:103] Top shape: 8 128 112 112 (12845056)
I1202 02:25:17.114876 28583 layer_factory.hpp:78] Creating layer pool2
I1202 02:25:17.114881 28583 net.cpp:67] Creating Layer pool2
I1202 02:25:17.114882 28583 net.cpp:394] pool2 <- conv2_2
I1202 02:25:17.114886 28583 net.cpp:356] pool2 -> pool2
I1202 02:25:17.114892 28583 net.cpp:96] Setting up pool2
I1202 02:25:17.114897 28583 net.cpp:103] Top shape: 8 128 56 56 (3211264)
I1202 02:25:17.114900 28583 layer_factory.hpp:78] Creating layer conv3_1
I1202 02:25:17.114905 28583 net.cpp:67] Creating Layer conv3_1
I1202 02:25:17.114907 28583 net.cpp:394] conv3_1 <- pool2
I1202 02:25:17.114912 28583 net.cpp:356] conv3_1 -> conv3_1
I1202 02:25:17.114923 28583 net.cpp:96] Setting up conv3_1
I1202 02:25:17.122158 28583 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:25:17.122171 28583 layer_factory.hpp:78] Creating layer relu3_1
I1202 02:25:17.122177 28583 net.cpp:67] Creating Layer relu3_1
I1202 02:25:17.122180 28583 net.cpp:394] relu3_1 <- conv3_1
I1202 02:25:17.122184 28583 net.cpp:345] relu3_1 -> conv3_1 (in-place)
I1202 02:25:17.122189 28583 net.cpp:96] Setting up relu3_1
I1202 02:25:17.122195 28583 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:25:17.122197 28583 layer_factory.hpp:78] Creating layer conv3_2
I1202 02:25:17.122210 28583 net.cpp:67] Creating Layer conv3_2
I1202 02:25:17.122212 28583 net.cpp:394] conv3_2 <- conv3_1
I1202 02:25:17.122217 28583 net.cpp:356] conv3_2 -> conv3_2
I1202 02:25:17.122222 28583 net.cpp:96] Setting up conv3_2
I1202 02:25:17.136858 28583 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:25:17.136881 28583 layer_factory.hpp:78] Creating layer relu3_2
I1202 02:25:17.136889 28583 net.cpp:67] Creating Layer relu3_2
I1202 02:25:17.136893 28583 net.cpp:394] relu3_2 <- conv3_2
I1202 02:25:17.136899 28583 net.cpp:345] relu3_2 -> conv3_2 (in-place)
I1202 02:25:17.136905 28583 net.cpp:96] Setting up relu3_2
I1202 02:25:17.136910 28583 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:25:17.136914 28583 layer_factory.hpp:78] Creating layer conv3_3
I1202 02:25:17.136924 28583 net.cpp:67] Creating Layer conv3_3
I1202 02:25:17.136927 28583 net.cpp:394] conv3_3 <- conv3_2
I1202 02:25:17.136931 28583 net.cpp:356] conv3_3 -> conv3_3
I1202 02:25:17.136937 28583 net.cpp:96] Setting up conv3_3
I1202 02:25:17.151450 28583 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:25:17.151471 28583 layer_factory.hpp:78] Creating layer relu3_3
I1202 02:25:17.151479 28583 net.cpp:67] Creating Layer relu3_3
I1202 02:25:17.151482 28583 net.cpp:394] relu3_3 <- conv3_3
I1202 02:25:17.151489 28583 net.cpp:345] relu3_3 -> conv3_3 (in-place)
I1202 02:25:17.151494 28583 net.cpp:96] Setting up relu3_3
I1202 02:25:17.151499 28583 net.cpp:103] Top shape: 8 256 56 56 (6422528)
I1202 02:25:17.151502 28583 layer_factory.hpp:78] Creating layer pool3
I1202 02:25:17.151509 28583 net.cpp:67] Creating Layer pool3
I1202 02:25:17.151511 28583 net.cpp:394] pool3 <- conv3_3
I1202 02:25:17.151516 28583 net.cpp:356] pool3 -> pool3
I1202 02:25:17.151521 28583 net.cpp:96] Setting up pool3
I1202 02:25:17.151530 28583 net.cpp:103] Top shape: 8 256 28 28 (1605632)
I1202 02:25:17.151532 28583 layer_factory.hpp:78] Creating layer conv4_1
I1202 02:25:17.151538 28583 net.cpp:67] Creating Layer conv4_1
I1202 02:25:17.151541 28583 net.cpp:394] conv4_1 <- pool3
I1202 02:25:17.151546 28583 net.cpp:356] conv4_1 -> conv4_1
I1202 02:25:17.151551 28583 net.cpp:96] Setting up conv4_1
I1202 02:25:17.180888 28583 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:25:17.180915 28583 layer_factory.hpp:78] Creating layer relu4_1
I1202 02:25:17.180927 28583 net.cpp:67] Creating Layer relu4_1
I1202 02:25:17.180932 28583 net.cpp:394] relu4_1 <- conv4_1
I1202 02:25:17.180938 28583 net.cpp:345] relu4_1 -> conv4_1 (in-place)
I1202 02:25:17.180945 28583 net.cpp:96] Setting up relu4_1
I1202 02:25:17.180951 28583 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:25:17.180954 28583 layer_factory.hpp:78] Creating layer conv4_2
I1202 02:25:17.180963 28583 net.cpp:67] Creating Layer conv4_2
I1202 02:25:17.180965 28583 net.cpp:394] conv4_2 <- conv4_1
I1202 02:25:17.180970 28583 net.cpp:356] conv4_2 -> conv4_2
I1202 02:25:17.180976 28583 net.cpp:96] Setting up conv4_2
I1202 02:25:17.238926 28583 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:25:17.238955 28583 layer_factory.hpp:78] Creating layer relu4_2
I1202 02:25:17.238963 28583 net.cpp:67] Creating Layer relu4_2
I1202 02:25:17.238968 28583 net.cpp:394] relu4_2 <- conv4_2
I1202 02:25:17.238975 28583 net.cpp:345] relu4_2 -> conv4_2 (in-place)
I1202 02:25:17.238981 28583 net.cpp:96] Setting up relu4_2
I1202 02:25:17.238986 28583 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:25:17.238989 28583 layer_factory.hpp:78] Creating layer conv4_3
I1202 02:25:17.238996 28583 net.cpp:67] Creating Layer conv4_3
I1202 02:25:17.238998 28583 net.cpp:394] conv4_3 <- conv4_2
I1202 02:25:17.239006 28583 net.cpp:356] conv4_3 -> conv4_3
I1202 02:25:17.239014 28583 net.cpp:96] Setting up conv4_3
I1202 02:25:17.296648 28583 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:25:17.296674 28583 layer_factory.hpp:78] Creating layer relu4_3
I1202 02:25:17.296681 28583 net.cpp:67] Creating Layer relu4_3
I1202 02:25:17.296685 28583 net.cpp:394] relu4_3 <- conv4_3
I1202 02:25:17.296691 28583 net.cpp:345] relu4_3 -> conv4_3 (in-place)
I1202 02:25:17.296708 28583 net.cpp:96] Setting up relu4_3
I1202 02:25:17.296715 28583 net.cpp:103] Top shape: 8 512 28 28 (3211264)
I1202 02:25:17.296717 28583 layer_factory.hpp:78] Creating layer pool4
I1202 02:25:17.296722 28583 net.cpp:67] Creating Layer pool4
I1202 02:25:17.296725 28583 net.cpp:394] pool4 <- conv4_3
I1202 02:25:17.296731 28583 net.cpp:356] pool4 -> pool4
I1202 02:25:17.296737 28583 net.cpp:96] Setting up pool4
I1202 02:25:17.296746 28583 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:25:17.296748 28583 layer_factory.hpp:78] Creating layer conv5_1
I1202 02:25:17.296756 28583 net.cpp:67] Creating Layer conv5_1
I1202 02:25:17.296758 28583 net.cpp:394] conv5_1 <- pool4
I1202 02:25:17.296762 28583 net.cpp:356] conv5_1 -> conv5_1
I1202 02:25:17.296768 28583 net.cpp:96] Setting up conv5_1
I1202 02:25:17.354707 28583 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:25:17.354732 28583 layer_factory.hpp:78] Creating layer relu5_1
I1202 02:25:17.354738 28583 net.cpp:67] Creating Layer relu5_1
I1202 02:25:17.354743 28583 net.cpp:394] relu5_1 <- conv5_1
I1202 02:25:17.354749 28583 net.cpp:345] relu5_1 -> conv5_1 (in-place)
I1202 02:25:17.354755 28583 net.cpp:96] Setting up relu5_1
I1202 02:25:17.354761 28583 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:25:17.354764 28583 layer_factory.hpp:78] Creating layer conv5_2
I1202 02:25:17.354771 28583 net.cpp:67] Creating Layer conv5_2
I1202 02:25:17.354774 28583 net.cpp:394] conv5_2 <- conv5_1
I1202 02:25:17.354779 28583 net.cpp:356] conv5_2 -> conv5_2
I1202 02:25:17.354784 28583 net.cpp:96] Setting up conv5_2
I1202 02:25:17.412499 28583 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:25:17.412525 28583 layer_factory.hpp:78] Creating layer relu5_2
I1202 02:25:17.412533 28583 net.cpp:67] Creating Layer relu5_2
I1202 02:25:17.412538 28583 net.cpp:394] relu5_2 <- conv5_2
I1202 02:25:17.412546 28583 net.cpp:345] relu5_2 -> conv5_2 (in-place)
I1202 02:25:17.412552 28583 net.cpp:96] Setting up relu5_2
I1202 02:25:17.412559 28583 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:25:17.412561 28583 layer_factory.hpp:78] Creating layer conv5_3
I1202 02:25:17.412569 28583 net.cpp:67] Creating Layer conv5_3
I1202 02:25:17.412571 28583 net.cpp:394] conv5_3 <- conv5_2
I1202 02:25:17.412575 28583 net.cpp:356] conv5_3 -> conv5_3
I1202 02:25:17.412582 28583 net.cpp:96] Setting up conv5_3
I1202 02:25:17.470563 28583 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:25:17.470588 28583 layer_factory.hpp:78] Creating layer relu5_3
I1202 02:25:17.470597 28583 net.cpp:67] Creating Layer relu5_3
I1202 02:25:17.470600 28583 net.cpp:394] relu5_3 <- conv5_3
I1202 02:25:17.470609 28583 net.cpp:345] relu5_3 -> conv5_3 (in-place)
I1202 02:25:17.470616 28583 net.cpp:96] Setting up relu5_3
I1202 02:25:17.470623 28583 net.cpp:103] Top shape: 8 512 14 14 (802816)
I1202 02:25:17.470625 28583 layer_factory.hpp:78] Creating layer pool5
I1202 02:25:17.470636 28583 net.cpp:67] Creating Layer pool5
I1202 02:25:17.470639 28583 net.cpp:394] pool5 <- conv5_3
I1202 02:25:17.470644 28583 net.cpp:356] pool5 -> pool5
I1202 02:25:17.470649 28583 net.cpp:96] Setting up pool5
I1202 02:25:17.470657 28583 net.cpp:103] Top shape: 8 512 7 7 (200704)
I1202 02:25:17.470660 28583 layer_factory.hpp:78] Creating layer fc6
I1202 02:25:17.470666 28583 net.cpp:67] Creating Layer fc6
I1202 02:25:17.470669 28583 net.cpp:394] fc6 <- pool5
I1202 02:25:17.470674 28583 net.cpp:356] fc6 -> fc6
I1202 02:25:17.470680 28583 net.cpp:96] Setting up fc6
I1202 02:25:19.970191 28583 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:25:19.970219 28583 layer_factory.hpp:78] Creating layer relu6
I1202 02:25:19.970230 28583 net.cpp:67] Creating Layer relu6
I1202 02:25:19.970237 28583 net.cpp:394] relu6 <- fc6
I1202 02:25:19.970243 28583 net.cpp:345] relu6 -> fc6 (in-place)
I1202 02:25:19.970250 28583 net.cpp:96] Setting up relu6
I1202 02:25:19.970264 28583 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:25:19.970268 28583 layer_factory.hpp:78] Creating layer drop6
I1202 02:25:19.970283 28583 net.cpp:67] Creating Layer drop6
I1202 02:25:19.970286 28583 net.cpp:394] drop6 <- fc6
I1202 02:25:19.970291 28583 net.cpp:345] drop6 -> fc6 (in-place)
I1202 02:25:19.970296 28583 net.cpp:96] Setting up drop6
I1202 02:25:19.970300 28583 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:25:19.970304 28583 layer_factory.hpp:78] Creating layer fc7
I1202 02:25:19.970309 28583 net.cpp:67] Creating Layer fc7
I1202 02:25:19.970312 28583 net.cpp:394] fc7 <- fc6
I1202 02:25:19.970316 28583 net.cpp:356] fc7 -> fc7
I1202 02:25:19.970322 28583 net.cpp:96] Setting up fc7
I1202 02:25:20.379375 28583 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:25:20.379402 28583 layer_factory.hpp:78] Creating layer relu7
I1202 02:25:20.379410 28583 net.cpp:67] Creating Layer relu7
I1202 02:25:20.379416 28583 net.cpp:394] relu7 <- fc7
I1202 02:25:20.379423 28583 net.cpp:345] relu7 -> fc7 (in-place)
I1202 02:25:20.379429 28583 net.cpp:96] Setting up relu7
I1202 02:25:20.379443 28583 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:25:20.379447 28583 layer_factory.hpp:78] Creating layer drop7
I1202 02:25:20.379454 28583 net.cpp:67] Creating Layer drop7
I1202 02:25:20.379457 28583 net.cpp:394] drop7 <- fc7
I1202 02:25:20.379465 28583 net.cpp:345] drop7 -> fc7 (in-place)
I1202 02:25:20.379470 28583 net.cpp:96] Setting up drop7
I1202 02:25:20.379474 28583 net.cpp:103] Top shape: 8 4096 1 1 (32768)
I1202 02:25:20.379477 28583 layer_factory.hpp:78] Creating layer fc8_2
I1202 02:25:20.379482 28583 net.cpp:67] Creating Layer fc8_2
I1202 02:25:20.379485 28583 net.cpp:394] fc8_2 <- fc7
I1202 02:25:20.379492 28583 net.cpp:356] fc8_2 -> fc8_2
I1202 02:25:20.379498 28583 net.cpp:96] Setting up fc8_2
I1202 02:25:20.379706 28583 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:25:20.379714 28583 layer_factory.hpp:78] Creating layer fc8_2_fc8_2_0_split
I1202 02:25:20.379719 28583 net.cpp:67] Creating Layer fc8_2_fc8_2_0_split
I1202 02:25:20.379722 28583 net.cpp:394] fc8_2_fc8_2_0_split <- fc8_2
I1202 02:25:20.379729 28583 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1202 02:25:20.379736 28583 net.cpp:356] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1202 02:25:20.379745 28583 net.cpp:96] Setting up fc8_2_fc8_2_0_split
I1202 02:25:20.379748 28583 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:25:20.379750 28583 net.cpp:103] Top shape: 8 2 1 1 (16)
I1202 02:25:20.379753 28583 layer_factory.hpp:78] Creating layer loss
I1202 02:25:20.379760 28583 net.cpp:67] Creating Layer loss
I1202 02:25:20.379763 28583 net.cpp:394] loss <- fc8_2_fc8_2_0_split_0
I1202 02:25:20.379767 28583 net.cpp:394] loss <- label_data_1_split_0
I1202 02:25:20.379771 28583 net.cpp:356] loss -> (automatic)
I1202 02:25:20.379776 28583 net.cpp:96] Setting up loss
I1202 02:25:20.379781 28583 net.cpp:103] Top shape: 1 1 1 1 (1)
I1202 02:25:20.379788 28583 net.cpp:109]     with loss weight 1
I1202 02:25:20.379802 28583 layer_factory.hpp:78] Creating layer accuracy
I1202 02:25:20.379808 28583 net.cpp:67] Creating Layer accuracy
I1202 02:25:20.379812 28583 net.cpp:394] accuracy <- fc8_2_fc8_2_0_split_1
I1202 02:25:20.379815 28583 net.cpp:394] accuracy <- label_data_1_split_1
I1202 02:25:20.379820 28583 net.cpp:356] accuracy -> accuracy
I1202 02:25:20.379825 28583 net.cpp:96] Setting up accuracy
I1202 02:25:20.379834 28583 net.cpp:103] Top shape: 1 1 1 4 (4)
I1202 02:25:20.379839 28583 net.cpp:172] accuracy does not need backward computation.
I1202 02:25:20.379842 28583 net.cpp:170] loss needs backward computation.
I1202 02:25:20.379845 28583 net.cpp:170] fc8_2_fc8_2_0_split needs backward computation.
I1202 02:25:20.379848 28583 net.cpp:170] fc8_2 needs backward computation.
I1202 02:25:20.379850 28583 net.cpp:170] drop7 needs backward computation.
I1202 02:25:20.379853 28583 net.cpp:170] relu7 needs backward computation.
I1202 02:25:20.379856 28583 net.cpp:170] fc7 needs backward computation.
I1202 02:25:20.379858 28583 net.cpp:170] drop6 needs backward computation.
I1202 02:25:20.379861 28583 net.cpp:170] relu6 needs backward computation.
I1202 02:25:20.379873 28583 net.cpp:170] fc6 needs backward computation.
I1202 02:25:20.379875 28583 net.cpp:170] pool5 needs backward computation.
I1202 02:25:20.379879 28583 net.cpp:170] relu5_3 needs backward computation.
I1202 02:25:20.379883 28583 net.cpp:170] conv5_3 needs backward computation.
I1202 02:25:20.379885 28583 net.cpp:170] relu5_2 needs backward computation.
I1202 02:25:20.379887 28583 net.cpp:170] conv5_2 needs backward computation.
I1202 02:25:20.379891 28583 net.cpp:170] relu5_1 needs backward computation.
I1202 02:25:20.379894 28583 net.cpp:170] conv5_1 needs backward computation.
I1202 02:25:20.379896 28583 net.cpp:170] pool4 needs backward computation.
I1202 02:25:20.379899 28583 net.cpp:170] relu4_3 needs backward computation.
I1202 02:25:20.379902 28583 net.cpp:170] conv4_3 needs backward computation.
I1202 02:25:20.379905 28583 net.cpp:170] relu4_2 needs backward computation.
I1202 02:25:20.379909 28583 net.cpp:170] conv4_2 needs backward computation.
I1202 02:25:20.379911 28583 net.cpp:170] relu4_1 needs backward computation.
I1202 02:25:20.379914 28583 net.cpp:170] conv4_1 needs backward computation.
I1202 02:25:20.379917 28583 net.cpp:170] pool3 needs backward computation.
I1202 02:25:20.379922 28583 net.cpp:170] relu3_3 needs backward computation.
I1202 02:25:20.379925 28583 net.cpp:170] conv3_3 needs backward computation.
I1202 02:25:20.379928 28583 net.cpp:170] relu3_2 needs backward computation.
I1202 02:25:20.379930 28583 net.cpp:170] conv3_2 needs backward computation.
I1202 02:25:20.379933 28583 net.cpp:170] relu3_1 needs backward computation.
I1202 02:25:20.379936 28583 net.cpp:170] conv3_1 needs backward computation.
I1202 02:25:20.379940 28583 net.cpp:170] pool2 needs backward computation.
I1202 02:25:20.379942 28583 net.cpp:170] relu2_2 needs backward computation.
I1202 02:25:20.379945 28583 net.cpp:170] conv2_2 needs backward computation.
I1202 02:25:20.379948 28583 net.cpp:170] relu2_1 needs backward computation.
I1202 02:25:20.379951 28583 net.cpp:170] conv2_1 needs backward computation.
I1202 02:25:20.379953 28583 net.cpp:170] pool1 needs backward computation.
I1202 02:25:20.379956 28583 net.cpp:170] relu1_2 needs backward computation.
I1202 02:25:20.379959 28583 net.cpp:170] conv1_2 needs backward computation.
I1202 02:25:20.379962 28583 net.cpp:170] relu1_1 needs backward computation.
I1202 02:25:20.379964 28583 net.cpp:170] conv1_1 needs backward computation.
I1202 02:25:20.379967 28583 net.cpp:172] label_data_1_split does not need backward computation.
I1202 02:25:20.379971 28583 net.cpp:172] data does not need backward computation.
I1202 02:25:20.379973 28583 net.cpp:208] This network produces output accuracy
I1202 02:25:20.379993 28583 net.cpp:467] Collecting Learning Rate and Weight Decay.
I1202 02:25:20.380002 28583 net.cpp:219] Network initialization done.
I1202 02:25:20.380004 28583 net.cpp:220] Memory required for data: 921616692
I1202 02:25:20.380105 28583 solver.cpp:41] Solver scaffolding done.
I1202 02:25:20.380110 28583 caffe.cpp:115] Finetuning from task/scrape_blue/none/fine__iter_20000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 1073741824 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537077502
I1202 02:25:23.710986 28583 solver.cpp:160] Solving small
I1202 02:25:23.711017 28583 solver.cpp:161] Learning Rate Policy: fixed
I1202 02:25:23.711065 28583 solver.cpp:264] Iteration 0, Testing net (#0)
I1202 02:26:48.566130 28583 solver.cpp:305] Test loss: 0.472378
I1202 02:26:48.566184 28583 solver.cpp:318] mean_score = test_score[0] { = 3027} / test_score[1] { = 3570 }
I1202 02:26:48.566191 28583 solver.cpp:319]            = 0.847899
I1202 02:26:48.566200 28583 solver.cpp:328]     Test net output #0: accuracy = 0.847899
I1202 02:26:48.566205 28583 solver.cpp:318] mean_score = test_score[2] { = 238} / test_score[3] { = 398 }
I1202 02:26:48.566210 28583 solver.cpp:319]            = 0.59799
I1202 02:26:48.566213 28583 solver.cpp:328]     Test net output #1: accuracy = 0.59799
I1202 02:26:48.566223 28583 solver.cpp:332]     Test net output #2: accuracy = 0.822833
I1202 02:26:48.566228 28583 solver.cpp:334]     Test net output #3: accuracy = 0.722945
I1202 02:26:49.253439 28583 solver.cpp:209] Iteration 0, loss = 0.153047
I1202 02:26:49.253469 28583 solver.cpp:464] Iteration 0, lr = 5e-05
I1202 02:26:51.572732 28583 solver.cpp:209] Iteration 1, loss = 0.0657978
I1202 02:26:51.572762 28583 solver.cpp:464] Iteration 1, lr = 5e-05
I1202 02:26:53.557678 28583 solver.cpp:353] Snapshotting to task/scrape_blue/none/fine__iter_2.caffemodel
I1202 02:26:57.395997 28583 solver.cpp:361] Snapshotting solver state to task/scrape_blue/none/fine__iter_2.solverstate
I1202 02:27:01.451668 28583 solver.cpp:246] Iteration 2, loss = 0.298155
I1202 02:27:01.451699 28583 solver.cpp:251] Optimization Done.
I1202 02:27:01.451704 28583 caffe.cpp:121] Optimization Done.
